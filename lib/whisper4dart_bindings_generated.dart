// ignore_for_file: always_specify_types
// ignore_for_file: camel_case_types
// ignore_for_file: non_constant_identifier_names

// AUTO GENERATED FILE, DO NOT EDIT.
//
// Generated by `package:ffigen`.
// ignore_for_file: type=lint
import 'dart:ffi' as ffi;

/// Bindings for `src/whisper4dart.h`.
///
/// Regenerate bindings with `flutter pub run ffigen --config ffigen.yaml`.
///
class WhisperDartBindings {
  /// Holds the symbol lookup function.
  final ffi.Pointer<T> Function<T extends ffi.NativeType>(String symbolName)
      _lookup;

  /// The symbols are looked up in [dynamicLibrary].
  WhisperDartBindings(ffi.DynamicLibrary dynamicLibrary)
      : _lookup = dynamicLibrary.lookup;

  /// The symbols are looked up with [lookup].
  WhisperDartBindings.fromLookup(
      ffi.Pointer<T> Function<T extends ffi.NativeType>(String symbolName)
          lookup)
      : _lookup = lookup;

  /// Various functions for loading a ggml whisper model.
  /// Allocate (almost) all memory needed for the model.
  /// Return NULL on failure
  ffi.Pointer<whisper_context> whisper_init_from_file_with_params(
    ffi.Pointer<ffi.Char> path_model,
    whisper_context_params params,
  ) {
    return _whisper_init_from_file_with_params(
      path_model,
      params,
    );
  }

  late final _whisper_init_from_file_with_paramsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<whisper_context> Function(ffi.Pointer<ffi.Char>,
              whisper_context_params)>>('whisper_init_from_file_with_params');
  late final _whisper_init_from_file_with_params =
      _whisper_init_from_file_with_paramsPtr.asFunction<
          ffi.Pointer<whisper_context> Function(
              ffi.Pointer<ffi.Char>, whisper_context_params)>();

  ffi.Pointer<whisper_context> whisper_init_from_buffer_with_params(
    ffi.Pointer<ffi.Void> buffer,
    int buffer_size,
    whisper_context_params params,
  ) {
    return _whisper_init_from_buffer_with_params(
      buffer,
      buffer_size,
      params,
    );
  }

  late final _whisper_init_from_buffer_with_paramsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<whisper_context> Function(ffi.Pointer<ffi.Void>, ffi.Size,
              whisper_context_params)>>('whisper_init_from_buffer_with_params');
  late final _whisper_init_from_buffer_with_params =
      _whisper_init_from_buffer_with_paramsPtr.asFunction<
          ffi.Pointer<whisper_context> Function(
              ffi.Pointer<ffi.Void>, int, whisper_context_params)>();

  ffi.Pointer<whisper_context> whisper_init_with_params(
    ffi.Pointer<whisper_model_loader> loader,
    whisper_context_params params,
  ) {
    return _whisper_init_with_params(
      loader,
      params,
    );
  }

  late final _whisper_init_with_paramsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<whisper_context> Function(
              ffi.Pointer<whisper_model_loader>,
              whisper_context_params)>>('whisper_init_with_params');
  late final _whisper_init_with_params =
      _whisper_init_with_paramsPtr.asFunction<
          ffi.Pointer<whisper_context> Function(
              ffi.Pointer<whisper_model_loader>, whisper_context_params)>();

  /// These are the same as the above, but the internal state of the context is not allocated automatically
  /// It is the responsibility of the caller to allocate the state using whisper_init_state() (#523)
  ffi.Pointer<whisper_context> whisper_init_from_file_with_params_no_state(
    ffi.Pointer<ffi.Char> path_model,
    whisper_context_params params,
  ) {
    return _whisper_init_from_file_with_params_no_state(
      path_model,
      params,
    );
  }

  late final _whisper_init_from_file_with_params_no_statePtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<whisper_context> Function(
                  ffi.Pointer<ffi.Char>, whisper_context_params)>>(
      'whisper_init_from_file_with_params_no_state');
  late final _whisper_init_from_file_with_params_no_state =
      _whisper_init_from_file_with_params_no_statePtr.asFunction<
          ffi.Pointer<whisper_context> Function(
              ffi.Pointer<ffi.Char>, whisper_context_params)>();

  ffi.Pointer<whisper_context> whisper_init_from_buffer_with_params_no_state(
    ffi.Pointer<ffi.Void> buffer,
    int buffer_size,
    whisper_context_params params,
  ) {
    return _whisper_init_from_buffer_with_params_no_state(
      buffer,
      buffer_size,
      params,
    );
  }

  late final _whisper_init_from_buffer_with_params_no_statePtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<whisper_context> Function(
                  ffi.Pointer<ffi.Void>, ffi.Size, whisper_context_params)>>(
      'whisper_init_from_buffer_with_params_no_state');
  late final _whisper_init_from_buffer_with_params_no_state =
      _whisper_init_from_buffer_with_params_no_statePtr.asFunction<
          ffi.Pointer<whisper_context> Function(
              ffi.Pointer<ffi.Void>, int, whisper_context_params)>();

  ffi.Pointer<whisper_context> whisper_init_with_params_no_state(
    ffi.Pointer<whisper_model_loader> loader,
    whisper_context_params params,
  ) {
    return _whisper_init_with_params_no_state(
      loader,
      params,
    );
  }

  late final _whisper_init_with_params_no_statePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<whisper_context> Function(
              ffi.Pointer<whisper_model_loader>,
              whisper_context_params)>>('whisper_init_with_params_no_state');
  late final _whisper_init_with_params_no_state =
      _whisper_init_with_params_no_statePtr.asFunction<
          ffi.Pointer<whisper_context> Function(
              ffi.Pointer<whisper_model_loader>, whisper_context_params)>();

  ffi.Pointer<whisper_context> whisper_init_from_file(
    ffi.Pointer<ffi.Char> path_model,
  ) {
    return _whisper_init_from_file(
      path_model,
    );
  }

  late final _whisper_init_from_filePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<whisper_context> Function(
              ffi.Pointer<ffi.Char>)>>('whisper_init_from_file');
  late final _whisper_init_from_file = _whisper_init_from_filePtr.asFunction<
      ffi.Pointer<whisper_context> Function(ffi.Pointer<ffi.Char>)>();

  ffi.Pointer<whisper_context> whisper_init_from_buffer(
    ffi.Pointer<ffi.Void> buffer,
    int buffer_size,
  ) {
    return _whisper_init_from_buffer(
      buffer,
      buffer_size,
    );
  }

  late final _whisper_init_from_bufferPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<whisper_context> Function(
              ffi.Pointer<ffi.Void>, ffi.Size)>>('whisper_init_from_buffer');
  late final _whisper_init_from_buffer =
      _whisper_init_from_bufferPtr.asFunction<
          ffi.Pointer<whisper_context> Function(ffi.Pointer<ffi.Void>, int)>();

  ffi.Pointer<whisper_context> whisper_init(
    ffi.Pointer<whisper_model_loader> loader,
  ) {
    return _whisper_init(
      loader,
    );
  }

  late final _whisper_initPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<whisper_context> Function(
              ffi.Pointer<whisper_model_loader>)>>('whisper_init');
  late final _whisper_init = _whisper_initPtr.asFunction<
      ffi.Pointer<whisper_context> Function(
          ffi.Pointer<whisper_model_loader>)>();

  ffi.Pointer<whisper_context> whisper_init_from_file_no_state(
    ffi.Pointer<ffi.Char> path_model,
  ) {
    return _whisper_init_from_file_no_state(
      path_model,
    );
  }

  late final _whisper_init_from_file_no_statePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<whisper_context> Function(
              ffi.Pointer<ffi.Char>)>>('whisper_init_from_file_no_state');
  late final _whisper_init_from_file_no_state =
      _whisper_init_from_file_no_statePtr.asFunction<
          ffi.Pointer<whisper_context> Function(ffi.Pointer<ffi.Char>)>();

  ffi.Pointer<whisper_context> whisper_init_from_buffer_no_state(
    ffi.Pointer<ffi.Void> buffer,
    int buffer_size,
  ) {
    return _whisper_init_from_buffer_no_state(
      buffer,
      buffer_size,
    );
  }

  late final _whisper_init_from_buffer_no_statePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<whisper_context> Function(ffi.Pointer<ffi.Void>,
              ffi.Size)>>('whisper_init_from_buffer_no_state');
  late final _whisper_init_from_buffer_no_state =
      _whisper_init_from_buffer_no_statePtr.asFunction<
          ffi.Pointer<whisper_context> Function(ffi.Pointer<ffi.Void>, int)>();

  ffi.Pointer<whisper_context> whisper_init_no_state(
    ffi.Pointer<whisper_model_loader> loader,
  ) {
    return _whisper_init_no_state(
      loader,
    );
  }

  late final _whisper_init_no_statePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<whisper_context> Function(
              ffi.Pointer<whisper_model_loader>)>>('whisper_init_no_state');
  late final _whisper_init_no_state = _whisper_init_no_statePtr.asFunction<
      ffi.Pointer<whisper_context> Function(
          ffi.Pointer<whisper_model_loader>)>();

  ffi.Pointer<whisper_state> whisper_init_state(
    ffi.Pointer<whisper_context> ctx,
  ) {
    return _whisper_init_state(
      ctx,
    );
  }

  late final _whisper_init_statePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<whisper_state> Function(
              ffi.Pointer<whisper_context>)>>('whisper_init_state');
  late final _whisper_init_state = _whisper_init_statePtr.asFunction<
      ffi.Pointer<whisper_state> Function(ffi.Pointer<whisper_context>)>();

  /// Given a context, enable use of OpenVINO for encode inference.
  /// model_path: Optional path to OpenVINO encoder IR model. If set to nullptr,
  /// the path will be generated from the ggml model path that was passed
  /// in to whisper_init_from_file. For example, if 'path_model' was
  /// "/path/to/ggml-base.en.bin", then OpenVINO IR model path will be
  /// assumed to be "/path/to/ggml-base.en-encoder-openvino.xml".
  /// device: OpenVINO device to run inference on ("CPU", "GPU", etc.)
  /// cache_dir: Optional cache directory that can speed up init time, especially for
  /// GPU, by caching compiled 'blobs' there.
  /// Set to nullptr if not used.
  /// Returns 0 on success. If OpenVINO is not enabled in build, this simply returns 1.
  int whisper_ctx_init_openvino_encoder_with_state(
    ffi.Pointer<whisper_context> ctx,
    ffi.Pointer<whisper_state> state,
    ffi.Pointer<ffi.Char> model_path,
    ffi.Pointer<ffi.Char> device,
    ffi.Pointer<ffi.Char> cache_dir,
  ) {
    return _whisper_ctx_init_openvino_encoder_with_state(
      ctx,
      state,
      model_path,
      device,
      cache_dir,
    );
  }

  late final _whisper_ctx_init_openvino_encoder_with_statePtr = _lookup<
          ffi.NativeFunction<
              ffi.Int Function(
                  ffi.Pointer<whisper_context>,
                  ffi.Pointer<whisper_state>,
                  ffi.Pointer<ffi.Char>,
                  ffi.Pointer<ffi.Char>,
                  ffi.Pointer<ffi.Char>)>>(
      'whisper_ctx_init_openvino_encoder_with_state');
  late final _whisper_ctx_init_openvino_encoder_with_state =
      _whisper_ctx_init_openvino_encoder_with_statePtr.asFunction<
          int Function(
              ffi.Pointer<whisper_context>,
              ffi.Pointer<whisper_state>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>)>();

  int whisper_ctx_init_openvino_encoder(
    ffi.Pointer<whisper_context> ctx,
    ffi.Pointer<ffi.Char> model_path,
    ffi.Pointer<ffi.Char> device,
    ffi.Pointer<ffi.Char> cache_dir,
  ) {
    return _whisper_ctx_init_openvino_encoder(
      ctx,
      model_path,
      device,
      cache_dir,
    );
  }

  late final _whisper_ctx_init_openvino_encoderPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<whisper_context>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>)>>('whisper_ctx_init_openvino_encoder');
  late final _whisper_ctx_init_openvino_encoder =
      _whisper_ctx_init_openvino_encoderPtr.asFunction<
          int Function(ffi.Pointer<whisper_context>, ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>)>();

  /// Frees all allocated memory
  void whisper_free(
    ffi.Pointer<whisper_context> ctx,
  ) {
    return _whisper_free(
      ctx,
    );
  }

  late final _whisper_freePtr = _lookup<
          ffi.NativeFunction<ffi.Void Function(ffi.Pointer<whisper_context>)>>(
      'whisper_free');
  late final _whisper_free = _whisper_freePtr
      .asFunction<void Function(ffi.Pointer<whisper_context>)>();

  void whisper_free_state(
    ffi.Pointer<whisper_state> state,
  ) {
    return _whisper_free_state(
      state,
    );
  }

  late final _whisper_free_statePtr = _lookup<
          ffi.NativeFunction<ffi.Void Function(ffi.Pointer<whisper_state>)>>(
      'whisper_free_state');
  late final _whisper_free_state = _whisper_free_statePtr
      .asFunction<void Function(ffi.Pointer<whisper_state>)>();

  void whisper_free_params(
    ffi.Pointer<whisper_full_params> params,
  ) {
    return _whisper_free_params(
      params,
    );
  }

  late final _whisper_free_paramsPtr = _lookup<
          ffi
          .NativeFunction<ffi.Void Function(ffi.Pointer<whisper_full_params>)>>(
      'whisper_free_params');
  late final _whisper_free_params = _whisper_free_paramsPtr
      .asFunction<void Function(ffi.Pointer<whisper_full_params>)>();

  void whisper_free_context_params(
    ffi.Pointer<whisper_context_params> params,
  ) {
    return _whisper_free_context_params(
      params,
    );
  }

  late final _whisper_free_context_paramsPtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(ffi.Pointer<whisper_context_params>)>>(
      'whisper_free_context_params');
  late final _whisper_free_context_params = _whisper_free_context_paramsPtr
      .asFunction<void Function(ffi.Pointer<whisper_context_params>)>();

  /// Convert RAW PCM audio to log mel spectrogram.
  /// The resulting spectrogram is stored inside the default state of the provided whisper context.
  /// Returns 0 on success
  int whisper_pcm_to_mel(
    ffi.Pointer<whisper_context> ctx,
    ffi.Pointer<ffi.Float> samples,
    int n_samples,
    int n_threads,
  ) {
    return _whisper_pcm_to_mel(
      ctx,
      samples,
      n_samples,
      n_threads,
    );
  }

  late final _whisper_pcm_to_melPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<whisper_context>, ffi.Pointer<ffi.Float>,
              ffi.Int, ffi.Int)>>('whisper_pcm_to_mel');
  late final _whisper_pcm_to_mel = _whisper_pcm_to_melPtr.asFunction<
      int Function(
          ffi.Pointer<whisper_context>, ffi.Pointer<ffi.Float>, int, int)>();

  int whisper_pcm_to_mel_with_state(
    ffi.Pointer<whisper_context> ctx,
    ffi.Pointer<whisper_state> state,
    ffi.Pointer<ffi.Float> samples,
    int n_samples,
    int n_threads,
  ) {
    return _whisper_pcm_to_mel_with_state(
      ctx,
      state,
      samples,
      n_samples,
      n_threads,
    );
  }

  late final _whisper_pcm_to_mel_with_statePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<whisper_context>,
              ffi.Pointer<whisper_state>,
              ffi.Pointer<ffi.Float>,
              ffi.Int,
              ffi.Int)>>('whisper_pcm_to_mel_with_state');
  late final _whisper_pcm_to_mel_with_state =
      _whisper_pcm_to_mel_with_statePtr.asFunction<
          int Function(ffi.Pointer<whisper_context>, ffi.Pointer<whisper_state>,
              ffi.Pointer<ffi.Float>, int, int)>();

  /// This can be used to set a custom log mel spectrogram inside the default state of the provided whisper context.
  /// Use this instead of whisper_pcm_to_mel() if you want to provide your own log mel spectrogram.
  /// n_mel must be 80
  /// Returns 0 on success
  int whisper_set_mel(
    ffi.Pointer<whisper_context> ctx,
    ffi.Pointer<ffi.Float> data,
    int n_len,
    int n_mel,
  ) {
    return _whisper_set_mel(
      ctx,
      data,
      n_len,
      n_mel,
    );
  }

  late final _whisper_set_melPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<whisper_context>, ffi.Pointer<ffi.Float>,
              ffi.Int, ffi.Int)>>('whisper_set_mel');
  late final _whisper_set_mel = _whisper_set_melPtr.asFunction<
      int Function(
          ffi.Pointer<whisper_context>, ffi.Pointer<ffi.Float>, int, int)>();

  int whisper_set_mel_with_state(
    ffi.Pointer<whisper_context> ctx,
    ffi.Pointer<whisper_state> state,
    ffi.Pointer<ffi.Float> data,
    int n_len,
    int n_mel,
  ) {
    return _whisper_set_mel_with_state(
      ctx,
      state,
      data,
      n_len,
      n_mel,
    );
  }

  late final _whisper_set_mel_with_statePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<whisper_context>,
              ffi.Pointer<whisper_state>,
              ffi.Pointer<ffi.Float>,
              ffi.Int,
              ffi.Int)>>('whisper_set_mel_with_state');
  late final _whisper_set_mel_with_state =
      _whisper_set_mel_with_statePtr.asFunction<
          int Function(ffi.Pointer<whisper_context>, ffi.Pointer<whisper_state>,
              ffi.Pointer<ffi.Float>, int, int)>();

  /// Run the Whisper encoder on the log mel spectrogram stored inside the default state in the provided whisper context.
  /// Make sure to call whisper_pcm_to_mel() or whisper_set_mel() first.
  /// offset can be used to specify the offset of the first frame in the spectrogram.
  /// Returns 0 on success
  int whisper_encode(
    ffi.Pointer<whisper_context> ctx,
    int offset,
    int n_threads,
  ) {
    return _whisper_encode(
      ctx,
      offset,
      n_threads,
    );
  }

  late final _whisper_encodePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<whisper_context>, ffi.Int,
              ffi.Int)>>('whisper_encode');
  late final _whisper_encode = _whisper_encodePtr
      .asFunction<int Function(ffi.Pointer<whisper_context>, int, int)>();

  int whisper_encode_with_state(
    ffi.Pointer<whisper_context> ctx,
    ffi.Pointer<whisper_state> state,
    int offset,
    int n_threads,
  ) {
    return _whisper_encode_with_state(
      ctx,
      state,
      offset,
      n_threads,
    );
  }

  late final _whisper_encode_with_statePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<whisper_context>,
              ffi.Pointer<whisper_state>,
              ffi.Int,
              ffi.Int)>>('whisper_encode_with_state');
  late final _whisper_encode_with_state =
      _whisper_encode_with_statePtr.asFunction<
          int Function(ffi.Pointer<whisper_context>, ffi.Pointer<whisper_state>,
              int, int)>();

  /// Run the Whisper decoder to obtain the logits and probabilities for the next token.
  /// Make sure to call whisper_encode() first.
  /// tokens + n_tokens is the provided context for the decoder.
  /// n_past is the number of tokens to use from previous decoder calls.
  /// Returns 0 on success
  /// TODO: add support for multiple decoders
  int whisper_decode(
    ffi.Pointer<whisper_context> ctx,
    ffi.Pointer<whisper_token> tokens,
    int n_tokens,
    int n_past,
    int n_threads,
  ) {
    return _whisper_decode(
      ctx,
      tokens,
      n_tokens,
      n_past,
      n_threads,
    );
  }

  late final _whisper_decodePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<whisper_context>,
              ffi.Pointer<whisper_token>,
              ffi.Int,
              ffi.Int,
              ffi.Int)>>('whisper_decode');
  late final _whisper_decode = _whisper_decodePtr.asFunction<
      int Function(ffi.Pointer<whisper_context>, ffi.Pointer<whisper_token>,
          int, int, int)>();

  int whisper_decode_with_state(
    ffi.Pointer<whisper_context> ctx,
    ffi.Pointer<whisper_state> state,
    ffi.Pointer<whisper_token> tokens,
    int n_tokens,
    int n_past,
    int n_threads,
  ) {
    return _whisper_decode_with_state(
      ctx,
      state,
      tokens,
      n_tokens,
      n_past,
      n_threads,
    );
  }

  late final _whisper_decode_with_statePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<whisper_context>,
              ffi.Pointer<whisper_state>,
              ffi.Pointer<whisper_token>,
              ffi.Int,
              ffi.Int,
              ffi.Int)>>('whisper_decode_with_state');
  late final _whisper_decode_with_state =
      _whisper_decode_with_statePtr.asFunction<
          int Function(ffi.Pointer<whisper_context>, ffi.Pointer<whisper_state>,
              ffi.Pointer<whisper_token>, int, int, int)>();

  /// Convert the provided text into tokens.
  /// The tokens pointer must be large enough to hold the resulting tokens.
  /// Returns the number of tokens on success, no more than n_max_tokens
  /// Returns a negative number on failure - the number of tokens that would have been returned
  /// TODO: not sure if correct
  int whisper_tokenize(
    ffi.Pointer<whisper_context> ctx,
    ffi.Pointer<ffi.Char> text,
    ffi.Pointer<whisper_token> tokens,
    int n_max_tokens,
  ) {
    return _whisper_tokenize(
      ctx,
      text,
      tokens,
      n_max_tokens,
    );
  }

  late final _whisper_tokenizePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<whisper_context>, ffi.Pointer<ffi.Char>,
              ffi.Pointer<whisper_token>, ffi.Int)>>('whisper_tokenize');
  late final _whisper_tokenize = _whisper_tokenizePtr.asFunction<
      int Function(ffi.Pointer<whisper_context>, ffi.Pointer<ffi.Char>,
          ffi.Pointer<whisper_token>, int)>();

  /// Return the number of tokens in the provided text
  /// Equivalent to: -whisper_tokenize(ctx, text, NULL, 0)
  int whisper_token_count(
    ffi.Pointer<whisper_context> ctx,
    ffi.Pointer<ffi.Char> text,
  ) {
    return _whisper_token_count(
      ctx,
      text,
    );
  }

  late final _whisper_token_countPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<whisper_context>,
              ffi.Pointer<ffi.Char>)>>('whisper_token_count');
  late final _whisper_token_count = _whisper_token_countPtr.asFunction<
      int Function(ffi.Pointer<whisper_context>, ffi.Pointer<ffi.Char>)>();

  /// Largest language id (i.e. number of available languages - 1)
  int whisper_lang_max_id() {
    return _whisper_lang_max_id();
  }

  late final _whisper_lang_max_idPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('whisper_lang_max_id');
  late final _whisper_lang_max_id =
      _whisper_lang_max_idPtr.asFunction<int Function()>();

  /// Return the id of the specified language, returns -1 if not found
  /// Examples:
  /// "de" -> 2
  /// "german" -> 2
  int whisper_lang_id(
    ffi.Pointer<ffi.Char> lang,
  ) {
    return _whisper_lang_id(
      lang,
    );
  }

  late final _whisper_lang_idPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<ffi.Char>)>>(
          'whisper_lang_id');
  late final _whisper_lang_id =
      _whisper_lang_idPtr.asFunction<int Function(ffi.Pointer<ffi.Char>)>();

  /// Return the short string of the specified language id (e.g. 2 -> "de"), returns nullptr if not found
  ffi.Pointer<ffi.Char> whisper_lang_str(
    int id,
  ) {
    return _whisper_lang_str(
      id,
    );
  }

  late final _whisper_lang_strPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Char> Function(ffi.Int)>>(
          'whisper_lang_str');
  late final _whisper_lang_str =
      _whisper_lang_strPtr.asFunction<ffi.Pointer<ffi.Char> Function(int)>();

  /// Return the short string of the specified language name (e.g. 2 -> "german"), returns nullptr if not found
  ffi.Pointer<ffi.Char> whisper_lang_str_full(
    int id,
  ) {
    return _whisper_lang_str_full(
      id,
    );
  }

  late final _whisper_lang_str_fullPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Char> Function(ffi.Int)>>(
          'whisper_lang_str_full');
  late final _whisper_lang_str_full = _whisper_lang_str_fullPtr
      .asFunction<ffi.Pointer<ffi.Char> Function(int)>();

  /// Use mel data at offset_ms to try and auto-detect the spoken language
  /// Make sure to call whisper_pcm_to_mel() or whisper_set_mel() first
  /// Returns the top language id or negative on failure
  /// If not null, fills the lang_probs array with the probabilities of all languages
  /// The array must be whisper_lang_max_id() + 1 in size
  /// ref: https://github.com/openai/whisper/blob/main/whisper/decoding.py#L18-L69
  int whisper_lang_auto_detect(
    ffi.Pointer<whisper_context> ctx,
    int offset_ms,
    int n_threads,
    ffi.Pointer<ffi.Float> lang_probs,
  ) {
    return _whisper_lang_auto_detect(
      ctx,
      offset_ms,
      n_threads,
      lang_probs,
    );
  }

  late final _whisper_lang_auto_detectPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<whisper_context>, ffi.Int, ffi.Int,
              ffi.Pointer<ffi.Float>)>>('whisper_lang_auto_detect');
  late final _whisper_lang_auto_detect =
      _whisper_lang_auto_detectPtr.asFunction<
          int Function(ffi.Pointer<whisper_context>, int, int,
              ffi.Pointer<ffi.Float>)>();

  int whisper_lang_auto_detect_with_state(
    ffi.Pointer<whisper_context> ctx,
    ffi.Pointer<whisper_state> state,
    int offset_ms,
    int n_threads,
    ffi.Pointer<ffi.Float> lang_probs,
  ) {
    return _whisper_lang_auto_detect_with_state(
      ctx,
      state,
      offset_ms,
      n_threads,
      lang_probs,
    );
  }

  late final _whisper_lang_auto_detect_with_statePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<whisper_context>,
              ffi.Pointer<whisper_state>,
              ffi.Int,
              ffi.Int,
              ffi.Pointer<ffi.Float>)>>('whisper_lang_auto_detect_with_state');
  late final _whisper_lang_auto_detect_with_state =
      _whisper_lang_auto_detect_with_statePtr.asFunction<
          int Function(ffi.Pointer<whisper_context>, ffi.Pointer<whisper_state>,
              int, int, ffi.Pointer<ffi.Float>)>();

  int whisper_n_len(
    ffi.Pointer<whisper_context> ctx,
  ) {
    return _whisper_n_len(
      ctx,
    );
  }

  late final _whisper_n_lenPtr = _lookup<
          ffi.NativeFunction<ffi.Int Function(ffi.Pointer<whisper_context>)>>(
      'whisper_n_len');
  late final _whisper_n_len = _whisper_n_lenPtr
      .asFunction<int Function(ffi.Pointer<whisper_context>)>();

  int whisper_n_len_from_state(
    ffi.Pointer<whisper_state> state,
  ) {
    return _whisper_n_len_from_state(
      state,
    );
  }

  late final _whisper_n_len_from_statePtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<whisper_state>)>>(
          'whisper_n_len_from_state');
  late final _whisper_n_len_from_state = _whisper_n_len_from_statePtr
      .asFunction<int Function(ffi.Pointer<whisper_state>)>();

  int whisper_n_vocab(
    ffi.Pointer<whisper_context> ctx,
  ) {
    return _whisper_n_vocab(
      ctx,
    );
  }

  late final _whisper_n_vocabPtr = _lookup<
          ffi.NativeFunction<ffi.Int Function(ffi.Pointer<whisper_context>)>>(
      'whisper_n_vocab');
  late final _whisper_n_vocab = _whisper_n_vocabPtr
      .asFunction<int Function(ffi.Pointer<whisper_context>)>();

  int whisper_n_text_ctx(
    ffi.Pointer<whisper_context> ctx,
  ) {
    return _whisper_n_text_ctx(
      ctx,
    );
  }

  late final _whisper_n_text_ctxPtr = _lookup<
          ffi.NativeFunction<ffi.Int Function(ffi.Pointer<whisper_context>)>>(
      'whisper_n_text_ctx');
  late final _whisper_n_text_ctx = _whisper_n_text_ctxPtr
      .asFunction<int Function(ffi.Pointer<whisper_context>)>();

  int whisper_n_audio_ctx(
    ffi.Pointer<whisper_context> ctx,
  ) {
    return _whisper_n_audio_ctx(
      ctx,
    );
  }

  late final _whisper_n_audio_ctxPtr = _lookup<
          ffi.NativeFunction<ffi.Int Function(ffi.Pointer<whisper_context>)>>(
      'whisper_n_audio_ctx');
  late final _whisper_n_audio_ctx = _whisper_n_audio_ctxPtr
      .asFunction<int Function(ffi.Pointer<whisper_context>)>();

  int whisper_is_multilingual(
    ffi.Pointer<whisper_context> ctx,
  ) {
    return _whisper_is_multilingual(
      ctx,
    );
  }

  late final _whisper_is_multilingualPtr = _lookup<
          ffi.NativeFunction<ffi.Int Function(ffi.Pointer<whisper_context>)>>(
      'whisper_is_multilingual');
  late final _whisper_is_multilingual = _whisper_is_multilingualPtr
      .asFunction<int Function(ffi.Pointer<whisper_context>)>();

  int whisper_model_n_vocab(
    ffi.Pointer<whisper_context> ctx,
  ) {
    return _whisper_model_n_vocab(
      ctx,
    );
  }

  late final _whisper_model_n_vocabPtr = _lookup<
          ffi.NativeFunction<ffi.Int Function(ffi.Pointer<whisper_context>)>>(
      'whisper_model_n_vocab');
  late final _whisper_model_n_vocab = _whisper_model_n_vocabPtr
      .asFunction<int Function(ffi.Pointer<whisper_context>)>();

  int whisper_model_n_audio_ctx(
    ffi.Pointer<whisper_context> ctx,
  ) {
    return _whisper_model_n_audio_ctx(
      ctx,
    );
  }

  late final _whisper_model_n_audio_ctxPtr = _lookup<
          ffi.NativeFunction<ffi.Int Function(ffi.Pointer<whisper_context>)>>(
      'whisper_model_n_audio_ctx');
  late final _whisper_model_n_audio_ctx = _whisper_model_n_audio_ctxPtr
      .asFunction<int Function(ffi.Pointer<whisper_context>)>();

  int whisper_model_n_audio_state(
    ffi.Pointer<whisper_context> ctx,
  ) {
    return _whisper_model_n_audio_state(
      ctx,
    );
  }

  late final _whisper_model_n_audio_statePtr = _lookup<
          ffi.NativeFunction<ffi.Int Function(ffi.Pointer<whisper_context>)>>(
      'whisper_model_n_audio_state');
  late final _whisper_model_n_audio_state = _whisper_model_n_audio_statePtr
      .asFunction<int Function(ffi.Pointer<whisper_context>)>();

  int whisper_model_n_audio_head(
    ffi.Pointer<whisper_context> ctx,
  ) {
    return _whisper_model_n_audio_head(
      ctx,
    );
  }

  late final _whisper_model_n_audio_headPtr = _lookup<
          ffi.NativeFunction<ffi.Int Function(ffi.Pointer<whisper_context>)>>(
      'whisper_model_n_audio_head');
  late final _whisper_model_n_audio_head = _whisper_model_n_audio_headPtr
      .asFunction<int Function(ffi.Pointer<whisper_context>)>();

  int whisper_model_n_audio_layer(
    ffi.Pointer<whisper_context> ctx,
  ) {
    return _whisper_model_n_audio_layer(
      ctx,
    );
  }

  late final _whisper_model_n_audio_layerPtr = _lookup<
          ffi.NativeFunction<ffi.Int Function(ffi.Pointer<whisper_context>)>>(
      'whisper_model_n_audio_layer');
  late final _whisper_model_n_audio_layer = _whisper_model_n_audio_layerPtr
      .asFunction<int Function(ffi.Pointer<whisper_context>)>();

  int whisper_model_n_text_ctx(
    ffi.Pointer<whisper_context> ctx,
  ) {
    return _whisper_model_n_text_ctx(
      ctx,
    );
  }

  late final _whisper_model_n_text_ctxPtr = _lookup<
          ffi.NativeFunction<ffi.Int Function(ffi.Pointer<whisper_context>)>>(
      'whisper_model_n_text_ctx');
  late final _whisper_model_n_text_ctx = _whisper_model_n_text_ctxPtr
      .asFunction<int Function(ffi.Pointer<whisper_context>)>();

  int whisper_model_n_text_state(
    ffi.Pointer<whisper_context> ctx,
  ) {
    return _whisper_model_n_text_state(
      ctx,
    );
  }

  late final _whisper_model_n_text_statePtr = _lookup<
          ffi.NativeFunction<ffi.Int Function(ffi.Pointer<whisper_context>)>>(
      'whisper_model_n_text_state');
  late final _whisper_model_n_text_state = _whisper_model_n_text_statePtr
      .asFunction<int Function(ffi.Pointer<whisper_context>)>();

  int whisper_model_n_text_head(
    ffi.Pointer<whisper_context> ctx,
  ) {
    return _whisper_model_n_text_head(
      ctx,
    );
  }

  late final _whisper_model_n_text_headPtr = _lookup<
          ffi.NativeFunction<ffi.Int Function(ffi.Pointer<whisper_context>)>>(
      'whisper_model_n_text_head');
  late final _whisper_model_n_text_head = _whisper_model_n_text_headPtr
      .asFunction<int Function(ffi.Pointer<whisper_context>)>();

  int whisper_model_n_text_layer(
    ffi.Pointer<whisper_context> ctx,
  ) {
    return _whisper_model_n_text_layer(
      ctx,
    );
  }

  late final _whisper_model_n_text_layerPtr = _lookup<
          ffi.NativeFunction<ffi.Int Function(ffi.Pointer<whisper_context>)>>(
      'whisper_model_n_text_layer');
  late final _whisper_model_n_text_layer = _whisper_model_n_text_layerPtr
      .asFunction<int Function(ffi.Pointer<whisper_context>)>();

  int whisper_model_n_mels(
    ffi.Pointer<whisper_context> ctx,
  ) {
    return _whisper_model_n_mels(
      ctx,
    );
  }

  late final _whisper_model_n_melsPtr = _lookup<
          ffi.NativeFunction<ffi.Int Function(ffi.Pointer<whisper_context>)>>(
      'whisper_model_n_mels');
  late final _whisper_model_n_mels = _whisper_model_n_melsPtr
      .asFunction<int Function(ffi.Pointer<whisper_context>)>();

  int whisper_model_ftype(
    ffi.Pointer<whisper_context> ctx,
  ) {
    return _whisper_model_ftype(
      ctx,
    );
  }

  late final _whisper_model_ftypePtr = _lookup<
          ffi.NativeFunction<ffi.Int Function(ffi.Pointer<whisper_context>)>>(
      'whisper_model_ftype');
  late final _whisper_model_ftype = _whisper_model_ftypePtr
      .asFunction<int Function(ffi.Pointer<whisper_context>)>();

  int whisper_model_type(
    ffi.Pointer<whisper_context> ctx,
  ) {
    return _whisper_model_type(
      ctx,
    );
  }

  late final _whisper_model_typePtr = _lookup<
          ffi.NativeFunction<ffi.Int Function(ffi.Pointer<whisper_context>)>>(
      'whisper_model_type');
  late final _whisper_model_type = _whisper_model_typePtr
      .asFunction<int Function(ffi.Pointer<whisper_context>)>();

  /// Token logits obtained from the last call to whisper_decode()
  /// The logits for the last token are stored in the last row
  /// Rows: n_tokens
  /// Cols: n_vocab
  ffi.Pointer<ffi.Float> whisper_get_logits(
    ffi.Pointer<whisper_context> ctx,
  ) {
    return _whisper_get_logits(
      ctx,
    );
  }

  late final _whisper_get_logitsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Float> Function(
              ffi.Pointer<whisper_context>)>>('whisper_get_logits');
  late final _whisper_get_logits = _whisper_get_logitsPtr.asFunction<
      ffi.Pointer<ffi.Float> Function(ffi.Pointer<whisper_context>)>();

  ffi.Pointer<ffi.Float> whisper_get_logits_from_state(
    ffi.Pointer<whisper_state> state,
  ) {
    return _whisper_get_logits_from_state(
      state,
    );
  }

  late final _whisper_get_logits_from_statePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Float> Function(
              ffi.Pointer<whisper_state>)>>('whisper_get_logits_from_state');
  late final _whisper_get_logits_from_state =
      _whisper_get_logits_from_statePtr.asFunction<
          ffi.Pointer<ffi.Float> Function(ffi.Pointer<whisper_state>)>();

  /// Token Id -> String. Uses the vocabulary in the provided context
  ffi.Pointer<ffi.Char> whisper_token_to_str(
    ffi.Pointer<whisper_context> ctx,
    int token,
  ) {
    return _whisper_token_to_str(
      ctx,
      token,
    );
  }

  late final _whisper_token_to_strPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(ffi.Pointer<whisper_context>,
              whisper_token)>>('whisper_token_to_str');
  late final _whisper_token_to_str = _whisper_token_to_strPtr.asFunction<
      ffi.Pointer<ffi.Char> Function(ffi.Pointer<whisper_context>, int)>();

  ffi.Pointer<ffi.Char> whisper_model_type_readable(
    ffi.Pointer<whisper_context> ctx,
  ) {
    return _whisper_model_type_readable(
      ctx,
    );
  }

  late final _whisper_model_type_readablePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<whisper_context>)>>('whisper_model_type_readable');
  late final _whisper_model_type_readable =
      _whisper_model_type_readablePtr.asFunction<
          ffi.Pointer<ffi.Char> Function(ffi.Pointer<whisper_context>)>();

  /// Special tokens
  int whisper_token_eot(
    ffi.Pointer<whisper_context> ctx,
  ) {
    return _whisper_token_eot(
      ctx,
    );
  }

  late final _whisper_token_eotPtr = _lookup<
      ffi.NativeFunction<
          whisper_token Function(
              ffi.Pointer<whisper_context>)>>('whisper_token_eot');
  late final _whisper_token_eot = _whisper_token_eotPtr
      .asFunction<int Function(ffi.Pointer<whisper_context>)>();

  int whisper_token_sot(
    ffi.Pointer<whisper_context> ctx,
  ) {
    return _whisper_token_sot(
      ctx,
    );
  }

  late final _whisper_token_sotPtr = _lookup<
      ffi.NativeFunction<
          whisper_token Function(
              ffi.Pointer<whisper_context>)>>('whisper_token_sot');
  late final _whisper_token_sot = _whisper_token_sotPtr
      .asFunction<int Function(ffi.Pointer<whisper_context>)>();

  int whisper_token_solm(
    ffi.Pointer<whisper_context> ctx,
  ) {
    return _whisper_token_solm(
      ctx,
    );
  }

  late final _whisper_token_solmPtr = _lookup<
      ffi.NativeFunction<
          whisper_token Function(
              ffi.Pointer<whisper_context>)>>('whisper_token_solm');
  late final _whisper_token_solm = _whisper_token_solmPtr
      .asFunction<int Function(ffi.Pointer<whisper_context>)>();

  int whisper_token_prev(
    ffi.Pointer<whisper_context> ctx,
  ) {
    return _whisper_token_prev(
      ctx,
    );
  }

  late final _whisper_token_prevPtr = _lookup<
      ffi.NativeFunction<
          whisper_token Function(
              ffi.Pointer<whisper_context>)>>('whisper_token_prev');
  late final _whisper_token_prev = _whisper_token_prevPtr
      .asFunction<int Function(ffi.Pointer<whisper_context>)>();

  int whisper_token_nosp(
    ffi.Pointer<whisper_context> ctx,
  ) {
    return _whisper_token_nosp(
      ctx,
    );
  }

  late final _whisper_token_nospPtr = _lookup<
      ffi.NativeFunction<
          whisper_token Function(
              ffi.Pointer<whisper_context>)>>('whisper_token_nosp');
  late final _whisper_token_nosp = _whisper_token_nospPtr
      .asFunction<int Function(ffi.Pointer<whisper_context>)>();

  int whisper_token_not(
    ffi.Pointer<whisper_context> ctx,
  ) {
    return _whisper_token_not(
      ctx,
    );
  }

  late final _whisper_token_notPtr = _lookup<
      ffi.NativeFunction<
          whisper_token Function(
              ffi.Pointer<whisper_context>)>>('whisper_token_not');
  late final _whisper_token_not = _whisper_token_notPtr
      .asFunction<int Function(ffi.Pointer<whisper_context>)>();

  int whisper_token_beg(
    ffi.Pointer<whisper_context> ctx,
  ) {
    return _whisper_token_beg(
      ctx,
    );
  }

  late final _whisper_token_begPtr = _lookup<
      ffi.NativeFunction<
          whisper_token Function(
              ffi.Pointer<whisper_context>)>>('whisper_token_beg');
  late final _whisper_token_beg = _whisper_token_begPtr
      .asFunction<int Function(ffi.Pointer<whisper_context>)>();

  int whisper_token_lang(
    ffi.Pointer<whisper_context> ctx,
    int lang_id,
  ) {
    return _whisper_token_lang(
      ctx,
      lang_id,
    );
  }

  late final _whisper_token_langPtr = _lookup<
      ffi.NativeFunction<
          whisper_token Function(
              ffi.Pointer<whisper_context>, ffi.Int)>>('whisper_token_lang');
  late final _whisper_token_lang = _whisper_token_langPtr
      .asFunction<int Function(ffi.Pointer<whisper_context>, int)>();

  /// Task tokens
  int whisper_token_translate(
    ffi.Pointer<whisper_context> ctx,
  ) {
    return _whisper_token_translate(
      ctx,
    );
  }

  late final _whisper_token_translatePtr = _lookup<
      ffi.NativeFunction<
          whisper_token Function(
              ffi.Pointer<whisper_context>)>>('whisper_token_translate');
  late final _whisper_token_translate = _whisper_token_translatePtr
      .asFunction<int Function(ffi.Pointer<whisper_context>)>();

  int whisper_token_transcribe(
    ffi.Pointer<whisper_context> ctx,
  ) {
    return _whisper_token_transcribe(
      ctx,
    );
  }

  late final _whisper_token_transcribePtr = _lookup<
      ffi.NativeFunction<
          whisper_token Function(
              ffi.Pointer<whisper_context>)>>('whisper_token_transcribe');
  late final _whisper_token_transcribe = _whisper_token_transcribePtr
      .asFunction<int Function(ffi.Pointer<whisper_context>)>();

  ffi.Pointer<whisper_timings> whisper_get_timings(
    ffi.Pointer<whisper_context> ctx,
  ) {
    return _whisper_get_timings(
      ctx,
    );
  }

  late final _whisper_get_timingsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<whisper_timings> Function(
              ffi.Pointer<whisper_context>)>>('whisper_get_timings');
  late final _whisper_get_timings = _whisper_get_timingsPtr.asFunction<
      ffi.Pointer<whisper_timings> Function(ffi.Pointer<whisper_context>)>();

  void whisper_print_timings(
    ffi.Pointer<whisper_context> ctx,
  ) {
    return _whisper_print_timings(
      ctx,
    );
  }

  late final _whisper_print_timingsPtr = _lookup<
          ffi.NativeFunction<ffi.Void Function(ffi.Pointer<whisper_context>)>>(
      'whisper_print_timings');
  late final _whisper_print_timings = _whisper_print_timingsPtr
      .asFunction<void Function(ffi.Pointer<whisper_context>)>();

  void whisper_reset_timings(
    ffi.Pointer<whisper_context> ctx,
  ) {
    return _whisper_reset_timings(
      ctx,
    );
  }

  late final _whisper_reset_timingsPtr = _lookup<
          ffi.NativeFunction<ffi.Void Function(ffi.Pointer<whisper_context>)>>(
      'whisper_reset_timings');
  late final _whisper_reset_timings = _whisper_reset_timingsPtr
      .asFunction<void Function(ffi.Pointer<whisper_context>)>();

  /// Print system information
  ffi.Pointer<ffi.Char> whisper_print_system_info() {
    return _whisper_print_system_info();
  }

  late final _whisper_print_system_infoPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Char> Function()>>(
          'whisper_print_system_info');
  late final _whisper_print_system_info = _whisper_print_system_infoPtr
      .asFunction<ffi.Pointer<ffi.Char> Function()>();

  /// NOTE: this function allocates memory, and it is the responsibility of the caller to free the pointer - see whisper_free_context_params & whisper_free_params()
  ffi.Pointer<whisper_context_params> whisper_context_default_params_by_ref() {
    return _whisper_context_default_params_by_ref();
  }

  late final _whisper_context_default_params_by_refPtr = _lookup<
          ffi.NativeFunction<ffi.Pointer<whisper_context_params> Function()>>(
      'whisper_context_default_params_by_ref');
  late final _whisper_context_default_params_by_ref =
      _whisper_context_default_params_by_refPtr
          .asFunction<ffi.Pointer<whisper_context_params> Function()>();

  whisper_context_params whisper_context_default_params() {
    return _whisper_context_default_params();
  }

  late final _whisper_context_default_paramsPtr =
      _lookup<ffi.NativeFunction<whisper_context_params Function()>>(
          'whisper_context_default_params');
  late final _whisper_context_default_params =
      _whisper_context_default_paramsPtr
          .asFunction<whisper_context_params Function()>();

  ffi.Pointer<whisper_full_params> whisper_full_default_params_by_ref(
    int strategy,
  ) {
    return _whisper_full_default_params_by_ref(
      strategy,
    );
  }

  late final _whisper_full_default_params_by_refPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<whisper_full_params> Function(
              ffi.Int32)>>('whisper_full_default_params_by_ref');
  late final _whisper_full_default_params_by_ref =
      _whisper_full_default_params_by_refPtr
          .asFunction<ffi.Pointer<whisper_full_params> Function(int)>();

  whisper_full_params whisper_full_default_params(
    int strategy,
  ) {
    return _whisper_full_default_params(
      strategy,
    );
  }

  late final _whisper_full_default_paramsPtr =
      _lookup<ffi.NativeFunction<whisper_full_params Function(ffi.Int32)>>(
          'whisper_full_default_params');
  late final _whisper_full_default_params = _whisper_full_default_paramsPtr
      .asFunction<whisper_full_params Function(int)>();

  /// Run the entire model: PCM -> log mel spectrogram -> encoder -> decoder -> text
  /// Not thread safe for same context
  /// Uses the specified decoding strategy to obtain the text.
  int whisper_full(
    ffi.Pointer<whisper_context> ctx,
    whisper_full_params params,
    ffi.Pointer<ffi.Float> samples,
    int n_samples,
  ) {
    return _whisper_full(
      ctx,
      params,
      samples,
      n_samples,
    );
  }

  late final _whisper_fullPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<whisper_context>, whisper_full_params,
              ffi.Pointer<ffi.Float>, ffi.Int)>>('whisper_full');
  late final _whisper_full = _whisper_fullPtr.asFunction<
      int Function(ffi.Pointer<whisper_context>, whisper_full_params,
          ffi.Pointer<ffi.Float>, int)>();

  int whisper_full_with_state(
    ffi.Pointer<whisper_context> ctx,
    ffi.Pointer<whisper_state> state,
    whisper_full_params params,
    ffi.Pointer<ffi.Float> samples,
    int n_samples,
  ) {
    return _whisper_full_with_state(
      ctx,
      state,
      params,
      samples,
      n_samples,
    );
  }

  late final _whisper_full_with_statePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<whisper_context>,
              ffi.Pointer<whisper_state>,
              whisper_full_params,
              ffi.Pointer<ffi.Float>,
              ffi.Int)>>('whisper_full_with_state');
  late final _whisper_full_with_state = _whisper_full_with_statePtr.asFunction<
      int Function(ffi.Pointer<whisper_context>, ffi.Pointer<whisper_state>,
          whisper_full_params, ffi.Pointer<ffi.Float>, int)>();

  /// Split the input audio in chunks and process each chunk separately using whisper_full_with_state()
  /// Result is stored in the default state of the context
  /// Not thread safe if executed in parallel on the same context.
  /// It seems this approach can offer some speedup in some cases.
  /// However, the transcription accuracy can be worse at the beginning and end of each chunk.
  int whisper_full_parallel(
    ffi.Pointer<whisper_context> ctx,
    whisper_full_params params,
    ffi.Pointer<ffi.Float> samples,
    int n_samples,
    int n_processors,
  ) {
    return _whisper_full_parallel(
      ctx,
      params,
      samples,
      n_samples,
      n_processors,
    );
  }

  late final _whisper_full_parallelPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<whisper_context>,
              whisper_full_params,
              ffi.Pointer<ffi.Float>,
              ffi.Int,
              ffi.Int)>>('whisper_full_parallel');
  late final _whisper_full_parallel = _whisper_full_parallelPtr.asFunction<
      int Function(ffi.Pointer<whisper_context>, whisper_full_params,
          ffi.Pointer<ffi.Float>, int, int)>();

  /// Number of generated text segments
  /// A segment can be a few words, a sentence, or even a paragraph.
  int whisper_full_n_segments(
    ffi.Pointer<whisper_context> ctx,
  ) {
    return _whisper_full_n_segments(
      ctx,
    );
  }

  late final _whisper_full_n_segmentsPtr = _lookup<
          ffi.NativeFunction<ffi.Int Function(ffi.Pointer<whisper_context>)>>(
      'whisper_full_n_segments');
  late final _whisper_full_n_segments = _whisper_full_n_segmentsPtr
      .asFunction<int Function(ffi.Pointer<whisper_context>)>();

  int whisper_full_n_segments_from_state(
    ffi.Pointer<whisper_state> state,
  ) {
    return _whisper_full_n_segments_from_state(
      state,
    );
  }

  late final _whisper_full_n_segments_from_statePtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<whisper_state>)>>(
          'whisper_full_n_segments_from_state');
  late final _whisper_full_n_segments_from_state =
      _whisper_full_n_segments_from_statePtr
          .asFunction<int Function(ffi.Pointer<whisper_state>)>();

  /// Language id associated with the context's default state
  int whisper_full_lang_id(
    ffi.Pointer<whisper_context> ctx,
  ) {
    return _whisper_full_lang_id(
      ctx,
    );
  }

  late final _whisper_full_lang_idPtr = _lookup<
          ffi.NativeFunction<ffi.Int Function(ffi.Pointer<whisper_context>)>>(
      'whisper_full_lang_id');
  late final _whisper_full_lang_id = _whisper_full_lang_idPtr
      .asFunction<int Function(ffi.Pointer<whisper_context>)>();

  /// Language id associated with the provided state
  int whisper_full_lang_id_from_state(
    ffi.Pointer<whisper_state> state,
  ) {
    return _whisper_full_lang_id_from_state(
      state,
    );
  }

  late final _whisper_full_lang_id_from_statePtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<whisper_state>)>>(
          'whisper_full_lang_id_from_state');
  late final _whisper_full_lang_id_from_state =
      _whisper_full_lang_id_from_statePtr
          .asFunction<int Function(ffi.Pointer<whisper_state>)>();

  /// Get the start and end time of the specified segment
  int whisper_full_get_segment_t0(
    ffi.Pointer<whisper_context> ctx,
    int i_segment,
  ) {
    return _whisper_full_get_segment_t0(
      ctx,
      i_segment,
    );
  }

  late final _whisper_full_get_segment_t0Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(ffi.Pointer<whisper_context>,
              ffi.Int)>>('whisper_full_get_segment_t0');
  late final _whisper_full_get_segment_t0 = _whisper_full_get_segment_t0Ptr
      .asFunction<int Function(ffi.Pointer<whisper_context>, int)>();

  int whisper_full_get_segment_t0_from_state(
    ffi.Pointer<whisper_state> state,
    int i_segment,
  ) {
    return _whisper_full_get_segment_t0_from_state(
      state,
      i_segment,
    );
  }

  late final _whisper_full_get_segment_t0_from_statePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(ffi.Pointer<whisper_state>,
              ffi.Int)>>('whisper_full_get_segment_t0_from_state');
  late final _whisper_full_get_segment_t0_from_state =
      _whisper_full_get_segment_t0_from_statePtr
          .asFunction<int Function(ffi.Pointer<whisper_state>, int)>();

  int whisper_full_get_segment_t1(
    ffi.Pointer<whisper_context> ctx,
    int i_segment,
  ) {
    return _whisper_full_get_segment_t1(
      ctx,
      i_segment,
    );
  }

  late final _whisper_full_get_segment_t1Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(ffi.Pointer<whisper_context>,
              ffi.Int)>>('whisper_full_get_segment_t1');
  late final _whisper_full_get_segment_t1 = _whisper_full_get_segment_t1Ptr
      .asFunction<int Function(ffi.Pointer<whisper_context>, int)>();

  int whisper_full_get_segment_t1_from_state(
    ffi.Pointer<whisper_state> state,
    int i_segment,
  ) {
    return _whisper_full_get_segment_t1_from_state(
      state,
      i_segment,
    );
  }

  late final _whisper_full_get_segment_t1_from_statePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(ffi.Pointer<whisper_state>,
              ffi.Int)>>('whisper_full_get_segment_t1_from_state');
  late final _whisper_full_get_segment_t1_from_state =
      _whisper_full_get_segment_t1_from_statePtr
          .asFunction<int Function(ffi.Pointer<whisper_state>, int)>();

  /// Get whether the next segment is predicted as a speaker turn
  bool whisper_full_get_segment_speaker_turn_next(
    ffi.Pointer<whisper_context> ctx,
    int i_segment,
  ) {
    return _whisper_full_get_segment_speaker_turn_next(
      ctx,
      i_segment,
    );
  }

  late final _whisper_full_get_segment_speaker_turn_nextPtr = _lookup<
      ffi.NativeFunction<
          ffi.Bool Function(ffi.Pointer<whisper_context>,
              ffi.Int)>>('whisper_full_get_segment_speaker_turn_next');
  late final _whisper_full_get_segment_speaker_turn_next =
      _whisper_full_get_segment_speaker_turn_nextPtr
          .asFunction<bool Function(ffi.Pointer<whisper_context>, int)>();

  bool whisper_full_get_segment_speaker_turn_next_from_state(
    ffi.Pointer<whisper_state> state,
    int i_segment,
  ) {
    return _whisper_full_get_segment_speaker_turn_next_from_state(
      state,
      i_segment,
    );
  }

  late final _whisper_full_get_segment_speaker_turn_next_from_statePtr =
      _lookup<
              ffi.NativeFunction<
                  ffi.Bool Function(ffi.Pointer<whisper_state>, ffi.Int)>>(
          'whisper_full_get_segment_speaker_turn_next_from_state');
  late final _whisper_full_get_segment_speaker_turn_next_from_state =
      _whisper_full_get_segment_speaker_turn_next_from_statePtr
          .asFunction<bool Function(ffi.Pointer<whisper_state>, int)>();

  /// Get the text of the specified segment
  ffi.Pointer<ffi.Char> whisper_full_get_segment_text(
    ffi.Pointer<whisper_context> ctx,
    int i_segment,
  ) {
    return _whisper_full_get_segment_text(
      ctx,
      i_segment,
    );
  }

  late final _whisper_full_get_segment_textPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(ffi.Pointer<whisper_context>,
              ffi.Int)>>('whisper_full_get_segment_text');
  late final _whisper_full_get_segment_text =
      _whisper_full_get_segment_textPtr.asFunction<
          ffi.Pointer<ffi.Char> Function(ffi.Pointer<whisper_context>, int)>();

  ffi.Pointer<ffi.Char> whisper_full_get_segment_text_from_state(
    ffi.Pointer<whisper_state> state,
    int i_segment,
  ) {
    return _whisper_full_get_segment_text_from_state(
      state,
      i_segment,
    );
  }

  late final _whisper_full_get_segment_text_from_statePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(ffi.Pointer<whisper_state>,
              ffi.Int)>>('whisper_full_get_segment_text_from_state');
  late final _whisper_full_get_segment_text_from_state =
      _whisper_full_get_segment_text_from_statePtr.asFunction<
          ffi.Pointer<ffi.Char> Function(ffi.Pointer<whisper_state>, int)>();

  /// Get number of tokens in the specified segment
  int whisper_full_n_tokens(
    ffi.Pointer<whisper_context> ctx,
    int i_segment,
  ) {
    return _whisper_full_n_tokens(
      ctx,
      i_segment,
    );
  }

  late final _whisper_full_n_tokensPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<whisper_context>, ffi.Int)>>('whisper_full_n_tokens');
  late final _whisper_full_n_tokens = _whisper_full_n_tokensPtr
      .asFunction<int Function(ffi.Pointer<whisper_context>, int)>();

  int whisper_full_n_tokens_from_state(
    ffi.Pointer<whisper_state> state,
    int i_segment,
  ) {
    return _whisper_full_n_tokens_from_state(
      state,
      i_segment,
    );
  }

  late final _whisper_full_n_tokens_from_statePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<whisper_state>,
              ffi.Int)>>('whisper_full_n_tokens_from_state');
  late final _whisper_full_n_tokens_from_state =
      _whisper_full_n_tokens_from_statePtr
          .asFunction<int Function(ffi.Pointer<whisper_state>, int)>();

  /// Get the token text of the specified token in the specified segment
  ffi.Pointer<ffi.Char> whisper_full_get_token_text(
    ffi.Pointer<whisper_context> ctx,
    int i_segment,
    int i_token,
  ) {
    return _whisper_full_get_token_text(
      ctx,
      i_segment,
      i_token,
    );
  }

  late final _whisper_full_get_token_textPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(ffi.Pointer<whisper_context>, ffi.Int,
              ffi.Int)>>('whisper_full_get_token_text');
  late final _whisper_full_get_token_text =
      _whisper_full_get_token_textPtr.asFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<whisper_context>, int, int)>();

  ffi.Pointer<ffi.Char> whisper_full_get_token_text_from_state(
    ffi.Pointer<whisper_context> ctx,
    ffi.Pointer<whisper_state> state,
    int i_segment,
    int i_token,
  ) {
    return _whisper_full_get_token_text_from_state(
      ctx,
      state,
      i_segment,
      i_token,
    );
  }

  late final _whisper_full_get_token_text_from_statePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<whisper_context>,
              ffi.Pointer<whisper_state>,
              ffi.Int,
              ffi.Int)>>('whisper_full_get_token_text_from_state');
  late final _whisper_full_get_token_text_from_state =
      _whisper_full_get_token_text_from_statePtr.asFunction<
          ffi.Pointer<ffi.Char> Function(ffi.Pointer<whisper_context>,
              ffi.Pointer<whisper_state>, int, int)>();

  int whisper_full_get_token_id(
    ffi.Pointer<whisper_context> ctx,
    int i_segment,
    int i_token,
  ) {
    return _whisper_full_get_token_id(
      ctx,
      i_segment,
      i_token,
    );
  }

  late final _whisper_full_get_token_idPtr = _lookup<
      ffi.NativeFunction<
          whisper_token Function(ffi.Pointer<whisper_context>, ffi.Int,
              ffi.Int)>>('whisper_full_get_token_id');
  late final _whisper_full_get_token_id = _whisper_full_get_token_idPtr
      .asFunction<int Function(ffi.Pointer<whisper_context>, int, int)>();

  int whisper_full_get_token_id_from_state(
    ffi.Pointer<whisper_state> state,
    int i_segment,
    int i_token,
  ) {
    return _whisper_full_get_token_id_from_state(
      state,
      i_segment,
      i_token,
    );
  }

  late final _whisper_full_get_token_id_from_statePtr = _lookup<
      ffi.NativeFunction<
          whisper_token Function(ffi.Pointer<whisper_state>, ffi.Int,
              ffi.Int)>>('whisper_full_get_token_id_from_state');
  late final _whisper_full_get_token_id_from_state =
      _whisper_full_get_token_id_from_statePtr
          .asFunction<int Function(ffi.Pointer<whisper_state>, int, int)>();

  /// Get token data for the specified token in the specified segment
  /// This contains probabilities, timestamps, etc.
  whisper_token_data whisper_full_get_token_data(
    ffi.Pointer<whisper_context> ctx,
    int i_segment,
    int i_token,
  ) {
    return _whisper_full_get_token_data(
      ctx,
      i_segment,
      i_token,
    );
  }

  late final _whisper_full_get_token_dataPtr = _lookup<
      ffi.NativeFunction<
          whisper_token_data Function(ffi.Pointer<whisper_context>, ffi.Int,
              ffi.Int)>>('whisper_full_get_token_data');
  late final _whisper_full_get_token_data =
      _whisper_full_get_token_dataPtr.asFunction<
          whisper_token_data Function(
              ffi.Pointer<whisper_context>, int, int)>();

  whisper_token_data whisper_full_get_token_data_from_state(
    ffi.Pointer<whisper_state> state,
    int i_segment,
    int i_token,
  ) {
    return _whisper_full_get_token_data_from_state(
      state,
      i_segment,
      i_token,
    );
  }

  late final _whisper_full_get_token_data_from_statePtr = _lookup<
      ffi.NativeFunction<
          whisper_token_data Function(ffi.Pointer<whisper_state>, ffi.Int,
              ffi.Int)>>('whisper_full_get_token_data_from_state');
  late final _whisper_full_get_token_data_from_state =
      _whisper_full_get_token_data_from_statePtr.asFunction<
          whisper_token_data Function(ffi.Pointer<whisper_state>, int, int)>();

  /// Get the probability of the specified token in the specified segment
  double whisper_full_get_token_p(
    ffi.Pointer<whisper_context> ctx,
    int i_segment,
    int i_token,
  ) {
    return _whisper_full_get_token_p(
      ctx,
      i_segment,
      i_token,
    );
  }

  late final _whisper_full_get_token_pPtr = _lookup<
      ffi.NativeFunction<
          ffi.Float Function(ffi.Pointer<whisper_context>, ffi.Int,
              ffi.Int)>>('whisper_full_get_token_p');
  late final _whisper_full_get_token_p = _whisper_full_get_token_pPtr
      .asFunction<double Function(ffi.Pointer<whisper_context>, int, int)>();

  double whisper_full_get_token_p_from_state(
    ffi.Pointer<whisper_state> state,
    int i_segment,
    int i_token,
  ) {
    return _whisper_full_get_token_p_from_state(
      state,
      i_segment,
      i_token,
    );
  }

  late final _whisper_full_get_token_p_from_statePtr = _lookup<
      ffi.NativeFunction<
          ffi.Float Function(ffi.Pointer<whisper_state>, ffi.Int,
              ffi.Int)>>('whisper_full_get_token_p_from_state');
  late final _whisper_full_get_token_p_from_state =
      _whisper_full_get_token_p_from_statePtr
          .asFunction<double Function(ffi.Pointer<whisper_state>, int, int)>();

  /// Temporary helpers needed for exposing ggml interface
  int whisper_bench_memcpy(
    int n_threads,
  ) {
    return _whisper_bench_memcpy(
      n_threads,
    );
  }

  late final _whisper_bench_memcpyPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Int)>>(
          'whisper_bench_memcpy');
  late final _whisper_bench_memcpy =
      _whisper_bench_memcpyPtr.asFunction<int Function(int)>();

  ffi.Pointer<ffi.Char> whisper_bench_memcpy_str(
    int n_threads,
  ) {
    return _whisper_bench_memcpy_str(
      n_threads,
    );
  }

  late final _whisper_bench_memcpy_strPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Char> Function(ffi.Int)>>(
          'whisper_bench_memcpy_str');
  late final _whisper_bench_memcpy_str = _whisper_bench_memcpy_strPtr
      .asFunction<ffi.Pointer<ffi.Char> Function(int)>();

  int whisper_bench_ggml_mul_mat(
    int n_threads,
  ) {
    return _whisper_bench_ggml_mul_mat(
      n_threads,
    );
  }

  late final _whisper_bench_ggml_mul_matPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Int)>>(
          'whisper_bench_ggml_mul_mat');
  late final _whisper_bench_ggml_mul_mat =
      _whisper_bench_ggml_mul_matPtr.asFunction<int Function(int)>();

  ffi.Pointer<ffi.Char> whisper_bench_ggml_mul_mat_str(
    int n_threads,
  ) {
    return _whisper_bench_ggml_mul_mat_str(
      n_threads,
    );
  }

  late final _whisper_bench_ggml_mul_mat_strPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Char> Function(ffi.Int)>>(
          'whisper_bench_ggml_mul_mat_str');
  late final _whisper_bench_ggml_mul_mat_str =
      _whisper_bench_ggml_mul_mat_strPtr
          .asFunction<ffi.Pointer<ffi.Char> Function(int)>();

  /// Control logging output; default behavior is to print to stderr
  void whisper_log_set(
    int log_callback,
    ffi.Pointer<ffi.Void> user_data,
  ) {
    return _whisper_log_set(
      log_callback,
      user_data,
    );
  }

  late final _whisper_log_setPtr = _lookup<
          ffi
          .NativeFunction<ffi.Void Function(ffi.Int, ffi.Pointer<ffi.Void>)>>(
      'whisper_log_set');
  late final _whisper_log_set = _whisper_log_setPtr
      .asFunction<void Function(int, ffi.Pointer<ffi.Void>)>();

  /// Get the no_speech probability for the specified segment
  double whisper_full_get_segment_no_speech_prob(
    ffi.Pointer<whisper_context> ctx,
    int i_segment,
  ) {
    return _whisper_full_get_segment_no_speech_prob(
      ctx,
      i_segment,
    );
  }

  late final _whisper_full_get_segment_no_speech_probPtr = _lookup<
      ffi.NativeFunction<
          ffi.Float Function(ffi.Pointer<whisper_context>,
              ffi.Int)>>('whisper_full_get_segment_no_speech_prob');
  late final _whisper_full_get_segment_no_speech_prob =
      _whisper_full_get_segment_no_speech_probPtr
          .asFunction<double Function(ffi.Pointer<whisper_context>, int)>();

  double whisper_full_get_segment_no_speech_prob_from_state(
    ffi.Pointer<whisper_state> state,
    int i_segment,
  ) {
    return _whisper_full_get_segment_no_speech_prob_from_state(
      state,
      i_segment,
    );
  }

  late final _whisper_full_get_segment_no_speech_prob_from_statePtr = _lookup<
      ffi.NativeFunction<
          ffi.Float Function(ffi.Pointer<whisper_state>,
              ffi.Int)>>('whisper_full_get_segment_no_speech_prob_from_state');
  late final _whisper_full_get_segment_no_speech_prob_from_state =
      _whisper_full_get_segment_no_speech_prob_from_statePtr
          .asFunction<double Function(ffi.Pointer<whisper_state>, int)>();

  void ggml_abort(
    ffi.Pointer<ffi.Char> file,
    int line,
    ffi.Pointer<ffi.Char> fmt,
  ) {
    return _ggml_abort(
      file,
      line,
      fmt,
    );
  }

  late final _ggml_abortPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Char>, ffi.Int,
              ffi.Pointer<ffi.Char>)>>('ggml_abort');
  late final _ggml_abort = _ggml_abortPtr.asFunction<
      void Function(ffi.Pointer<ffi.Char>, int, ffi.Pointer<ffi.Char>)>();

  /// get ggml_status name string
  ffi.Pointer<ffi.Char> ggml_status_to_string(
    int status,
  ) {
    return _ggml_status_to_string(
      status,
    );
  }

  late final _ggml_status_to_stringPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Char> Function(ffi.Int32)>>(
          'ggml_status_to_string');
  late final _ggml_status_to_string = _ggml_status_to_stringPtr
      .asFunction<ffi.Pointer<ffi.Char> Function(int)>();

  double ggml_fp16_to_fp32(
    int arg0,
  ) {
    return _ggml_fp16_to_fp32(
      arg0,
    );
  }

  late final _ggml_fp16_to_fp32Ptr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ggml_fp16_t)>>(
          'ggml_fp16_to_fp32');
  late final _ggml_fp16_to_fp32 =
      _ggml_fp16_to_fp32Ptr.asFunction<double Function(int)>();

  int ggml_fp32_to_fp16(
    double arg0,
  ) {
    return _ggml_fp32_to_fp16(
      arg0,
    );
  }

  late final _ggml_fp32_to_fp16Ptr =
      _lookup<ffi.NativeFunction<ggml_fp16_t Function(ffi.Float)>>(
          'ggml_fp32_to_fp16');
  late final _ggml_fp32_to_fp16 =
      _ggml_fp32_to_fp16Ptr.asFunction<int Function(double)>();

  void ggml_fp16_to_fp32_row(
    ffi.Pointer<ggml_fp16_t> arg0,
    ffi.Pointer<ffi.Float> arg1,
    int arg2,
  ) {
    return _ggml_fp16_to_fp32_row(
      arg0,
      arg1,
      arg2,
    );
  }

  late final _ggml_fp16_to_fp32_rowPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ggml_fp16_t>, ffi.Pointer<ffi.Float>,
              ffi.Int64)>>('ggml_fp16_to_fp32_row');
  late final _ggml_fp16_to_fp32_row = _ggml_fp16_to_fp32_rowPtr.asFunction<
      void Function(ffi.Pointer<ggml_fp16_t>, ffi.Pointer<ffi.Float>, int)>();

  void ggml_fp32_to_fp16_row(
    ffi.Pointer<ffi.Float> arg0,
    ffi.Pointer<ggml_fp16_t> arg1,
    int arg2,
  ) {
    return _ggml_fp32_to_fp16_row(
      arg0,
      arg1,
      arg2,
    );
  }

  late final _ggml_fp32_to_fp16_rowPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Float>, ffi.Pointer<ggml_fp16_t>,
              ffi.Int64)>>('ggml_fp32_to_fp16_row');
  late final _ggml_fp32_to_fp16_row = _ggml_fp32_to_fp16_rowPtr.asFunction<
      void Function(ffi.Pointer<ffi.Float>, ffi.Pointer<ggml_fp16_t>, int)>();

  ggml_bf16_t ggml_fp32_to_bf16(
    double arg0,
  ) {
    return _ggml_fp32_to_bf16(
      arg0,
    );
  }

  late final _ggml_fp32_to_bf16Ptr =
      _lookup<ffi.NativeFunction<ggml_bf16_t Function(ffi.Float)>>(
          'ggml_fp32_to_bf16');
  late final _ggml_fp32_to_bf16 =
      _ggml_fp32_to_bf16Ptr.asFunction<ggml_bf16_t Function(double)>();

  double ggml_bf16_to_fp32(
    ggml_bf16_t arg0,
  ) {
    return _ggml_bf16_to_fp32(
      arg0,
    );
  }

  late final _ggml_bf16_to_fp32Ptr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ggml_bf16_t)>>(
          'ggml_bf16_to_fp32');
  late final _ggml_bf16_to_fp32 =
      _ggml_bf16_to_fp32Ptr.asFunction<double Function(ggml_bf16_t)>();

  void ggml_bf16_to_fp32_row(
    ffi.Pointer<ggml_bf16_t> arg0,
    ffi.Pointer<ffi.Float> arg1,
    int arg2,
  ) {
    return _ggml_bf16_to_fp32_row(
      arg0,
      arg1,
      arg2,
    );
  }

  late final _ggml_bf16_to_fp32_rowPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ggml_bf16_t>, ffi.Pointer<ffi.Float>,
              ffi.Int64)>>('ggml_bf16_to_fp32_row');
  late final _ggml_bf16_to_fp32_row = _ggml_bf16_to_fp32_rowPtr.asFunction<
      void Function(ffi.Pointer<ggml_bf16_t>, ffi.Pointer<ffi.Float>, int)>();

  void ggml_fp32_to_bf16_row_ref(
    ffi.Pointer<ffi.Float> arg0,
    ffi.Pointer<ggml_bf16_t> arg1,
    int arg2,
  ) {
    return _ggml_fp32_to_bf16_row_ref(
      arg0,
      arg1,
      arg2,
    );
  }

  late final _ggml_fp32_to_bf16_row_refPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Float>, ffi.Pointer<ggml_bf16_t>,
              ffi.Int64)>>('ggml_fp32_to_bf16_row_ref');
  late final _ggml_fp32_to_bf16_row_ref =
      _ggml_fp32_to_bf16_row_refPtr.asFunction<
          void Function(
              ffi.Pointer<ffi.Float>, ffi.Pointer<ggml_bf16_t>, int)>();

  void ggml_fp32_to_bf16_row(
    ffi.Pointer<ffi.Float> arg0,
    ffi.Pointer<ggml_bf16_t> arg1,
    int arg2,
  ) {
    return _ggml_fp32_to_bf16_row(
      arg0,
      arg1,
      arg2,
    );
  }

  late final _ggml_fp32_to_bf16_rowPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Float>, ffi.Pointer<ggml_bf16_t>,
              ffi.Int64)>>('ggml_fp32_to_bf16_row');
  late final _ggml_fp32_to_bf16_row = _ggml_fp32_to_bf16_rowPtr.asFunction<
      void Function(ffi.Pointer<ffi.Float>, ffi.Pointer<ggml_bf16_t>, int)>();

  late final ffi.Pointer<ffi.Size> _GGML_TENSOR_SIZE =
      _lookup<ffi.Size>('GGML_TENSOR_SIZE');

  int get GGML_TENSOR_SIZE => _GGML_TENSOR_SIZE.value;

  set GGML_TENSOR_SIZE(int value) => _GGML_TENSOR_SIZE.value = value;

  bool ggml_guid_matches(
    ggml_guid_t guid_a,
    ggml_guid_t guid_b,
  ) {
    return _ggml_guid_matches(
      guid_a,
      guid_b,
    );
  }

  late final _ggml_guid_matchesPtr =
      _lookup<ffi.NativeFunction<ffi.Bool Function(ggml_guid_t, ggml_guid_t)>>(
          'ggml_guid_matches');
  late final _ggml_guid_matches = _ggml_guid_matchesPtr
      .asFunction<bool Function(ggml_guid_t, ggml_guid_t)>();

  /// misc
  void ggml_time_init() {
    return _ggml_time_init();
  }

  late final _ggml_time_initPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('ggml_time_init');
  late final _ggml_time_init = _ggml_time_initPtr.asFunction<void Function()>();

  int ggml_time_ms() {
    return _ggml_time_ms();
  }

  late final _ggml_time_msPtr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function()>>('ggml_time_ms');
  late final _ggml_time_ms = _ggml_time_msPtr.asFunction<int Function()>();

  int ggml_time_us() {
    return _ggml_time_us();
  }

  late final _ggml_time_usPtr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function()>>('ggml_time_us');
  late final _ggml_time_us = _ggml_time_usPtr.asFunction<int Function()>();

  int ggml_cycles() {
    return _ggml_cycles();
  }

  late final _ggml_cyclesPtr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function()>>('ggml_cycles');
  late final _ggml_cycles = _ggml_cyclesPtr.asFunction<int Function()>();

  int ggml_cycles_per_ms() {
    return _ggml_cycles_per_ms();
  }

  late final _ggml_cycles_per_msPtr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function()>>('ggml_cycles_per_ms');
  late final _ggml_cycles_per_ms =
      _ggml_cycles_per_msPtr.asFunction<int Function()>();

  /// accepts a UTF-8 path, even on Windows
  ffi.Pointer<FILE> ggml_fopen(
    ffi.Pointer<ffi.Char> fname,
    ffi.Pointer<ffi.Char> mode,
  ) {
    return _ggml_fopen(
      fname,
      mode,
    );
  }

  late final _ggml_fopenPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<FILE> Function(
              ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>)>>('ggml_fopen');
  late final _ggml_fopen = _ggml_fopenPtr.asFunction<
      ffi.Pointer<FILE> Function(
          ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>)>();

  void ggml_print_object(
    ffi.Pointer<ggml_object> obj,
  ) {
    return _ggml_print_object(
      obj,
    );
  }

  late final _ggml_print_objectPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ggml_object>)>>(
          'ggml_print_object');
  late final _ggml_print_object = _ggml_print_objectPtr
      .asFunction<void Function(ffi.Pointer<ggml_object>)>();

  void ggml_print_objects(
    ffi.Pointer<ggml_context> ctx,
  ) {
    return _ggml_print_objects(
      ctx,
    );
  }

  late final _ggml_print_objectsPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ggml_context>)>>(
          'ggml_print_objects');
  late final _ggml_print_objects = _ggml_print_objectsPtr
      .asFunction<void Function(ffi.Pointer<ggml_context>)>();

  int ggml_nelements(
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _ggml_nelements(
      tensor,
    );
  }

  late final _ggml_nelementsPtr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(ffi.Pointer<ggml_tensor>)>>(
          'ggml_nelements');
  late final _ggml_nelements =
      _ggml_nelementsPtr.asFunction<int Function(ffi.Pointer<ggml_tensor>)>();

  int ggml_nrows(
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _ggml_nrows(
      tensor,
    );
  }

  late final _ggml_nrowsPtr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(ffi.Pointer<ggml_tensor>)>>(
          'ggml_nrows');
  late final _ggml_nrows =
      _ggml_nrowsPtr.asFunction<int Function(ffi.Pointer<ggml_tensor>)>();

  int ggml_nbytes(
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _ggml_nbytes(
      tensor,
    );
  }

  late final _ggml_nbytesPtr =
      _lookup<ffi.NativeFunction<ffi.Size Function(ffi.Pointer<ggml_tensor>)>>(
          'ggml_nbytes');
  late final _ggml_nbytes =
      _ggml_nbytesPtr.asFunction<int Function(ffi.Pointer<ggml_tensor>)>();

  int ggml_nbytes_pad(
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _ggml_nbytes_pad(
      tensor,
    );
  }

  late final _ggml_nbytes_padPtr =
      _lookup<ffi.NativeFunction<ffi.Size Function(ffi.Pointer<ggml_tensor>)>>(
          'ggml_nbytes_pad');
  late final _ggml_nbytes_pad =
      _ggml_nbytes_padPtr.asFunction<int Function(ffi.Pointer<ggml_tensor>)>();

  int ggml_blck_size(
    int type,
  ) {
    return _ggml_blck_size(
      type,
    );
  }

  late final _ggml_blck_sizePtr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(ffi.Int32)>>(
          'ggml_blck_size');
  late final _ggml_blck_size =
      _ggml_blck_sizePtr.asFunction<int Function(int)>();

  int ggml_type_size(
    int type,
  ) {
    return _ggml_type_size(
      type,
    );
  }

  late final _ggml_type_sizePtr =
      _lookup<ffi.NativeFunction<ffi.Size Function(ffi.Int32)>>(
          'ggml_type_size');
  late final _ggml_type_size =
      _ggml_type_sizePtr.asFunction<int Function(int)>();

  int ggml_row_size(
    int type,
    int ne,
  ) {
    return _ggml_row_size(
      type,
      ne,
    );
  }

  late final _ggml_row_sizePtr =
      _lookup<ffi.NativeFunction<ffi.Size Function(ffi.Int32, ffi.Int64)>>(
          'ggml_row_size');
  late final _ggml_row_size =
      _ggml_row_sizePtr.asFunction<int Function(int, int)>();

  double ggml_type_sizef(
    int type,
  ) {
    return _ggml_type_sizef(
      type,
    );
  }

  late final _ggml_type_sizefPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Int32)>>(
          'ggml_type_sizef');
  late final _ggml_type_sizef =
      _ggml_type_sizefPtr.asFunction<double Function(int)>();

  ffi.Pointer<ffi.Char> ggml_type_name(
    int type,
  ) {
    return _ggml_type_name(
      type,
    );
  }

  late final _ggml_type_namePtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Char> Function(ffi.Int32)>>(
          'ggml_type_name');
  late final _ggml_type_name =
      _ggml_type_namePtr.asFunction<ffi.Pointer<ffi.Char> Function(int)>();

  ffi.Pointer<ffi.Char> ggml_op_name(
    int op,
  ) {
    return _ggml_op_name(
      op,
    );
  }

  late final _ggml_op_namePtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Char> Function(ffi.Int32)>>(
          'ggml_op_name');
  late final _ggml_op_name =
      _ggml_op_namePtr.asFunction<ffi.Pointer<ffi.Char> Function(int)>();

  ffi.Pointer<ffi.Char> ggml_op_symbol(
    int op,
  ) {
    return _ggml_op_symbol(
      op,
    );
  }

  late final _ggml_op_symbolPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Char> Function(ffi.Int32)>>(
          'ggml_op_symbol');
  late final _ggml_op_symbol =
      _ggml_op_symbolPtr.asFunction<ffi.Pointer<ffi.Char> Function(int)>();

  ffi.Pointer<ffi.Char> ggml_unary_op_name(
    int op,
  ) {
    return _ggml_unary_op_name(
      op,
    );
  }

  late final _ggml_unary_op_namePtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Char> Function(ffi.Int32)>>(
          'ggml_unary_op_name');
  late final _ggml_unary_op_name =
      _ggml_unary_op_namePtr.asFunction<ffi.Pointer<ffi.Char> Function(int)>();

  ffi.Pointer<ffi.Char> ggml_op_desc(
    ffi.Pointer<ggml_tensor> t,
  ) {
    return _ggml_op_desc(
      t,
    );
  }

  late final _ggml_op_descPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<ggml_tensor>)>>('ggml_op_desc');
  late final _ggml_op_desc = _ggml_op_descPtr
      .asFunction<ffi.Pointer<ffi.Char> Function(ffi.Pointer<ggml_tensor>)>();

  int ggml_element_size(
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _ggml_element_size(
      tensor,
    );
  }

  late final _ggml_element_sizePtr =
      _lookup<ffi.NativeFunction<ffi.Size Function(ffi.Pointer<ggml_tensor>)>>(
          'ggml_element_size');
  late final _ggml_element_size = _ggml_element_sizePtr
      .asFunction<int Function(ffi.Pointer<ggml_tensor>)>();

  bool ggml_is_quantized(
    int type,
  ) {
    return _ggml_is_quantized(
      type,
    );
  }

  late final _ggml_is_quantizedPtr =
      _lookup<ffi.NativeFunction<ffi.Bool Function(ffi.Int32)>>(
          'ggml_is_quantized');
  late final _ggml_is_quantized =
      _ggml_is_quantizedPtr.asFunction<bool Function(int)>();

  /// TODO: temporary until model loading of ggml examples is refactored
  int ggml_ftype_to_ggml_type(
    int ftype,
  ) {
    return _ggml_ftype_to_ggml_type(
      ftype,
    );
  }

  late final _ggml_ftype_to_ggml_typePtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Int32)>>(
          'ggml_ftype_to_ggml_type');
  late final _ggml_ftype_to_ggml_type =
      _ggml_ftype_to_ggml_typePtr.asFunction<int Function(int)>();

  bool ggml_is_transposed(
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _ggml_is_transposed(
      tensor,
    );
  }

  late final _ggml_is_transposedPtr =
      _lookup<ffi.NativeFunction<ffi.Bool Function(ffi.Pointer<ggml_tensor>)>>(
          'ggml_is_transposed');
  late final _ggml_is_transposed = _ggml_is_transposedPtr
      .asFunction<bool Function(ffi.Pointer<ggml_tensor>)>();

  bool ggml_is_permuted(
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _ggml_is_permuted(
      tensor,
    );
  }

  late final _ggml_is_permutedPtr =
      _lookup<ffi.NativeFunction<ffi.Bool Function(ffi.Pointer<ggml_tensor>)>>(
          'ggml_is_permuted');
  late final _ggml_is_permuted = _ggml_is_permutedPtr
      .asFunction<bool Function(ffi.Pointer<ggml_tensor>)>();

  bool ggml_is_empty(
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _ggml_is_empty(
      tensor,
    );
  }

  late final _ggml_is_emptyPtr =
      _lookup<ffi.NativeFunction<ffi.Bool Function(ffi.Pointer<ggml_tensor>)>>(
          'ggml_is_empty');
  late final _ggml_is_empty =
      _ggml_is_emptyPtr.asFunction<bool Function(ffi.Pointer<ggml_tensor>)>();

  bool ggml_is_scalar(
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _ggml_is_scalar(
      tensor,
    );
  }

  late final _ggml_is_scalarPtr =
      _lookup<ffi.NativeFunction<ffi.Bool Function(ffi.Pointer<ggml_tensor>)>>(
          'ggml_is_scalar');
  late final _ggml_is_scalar =
      _ggml_is_scalarPtr.asFunction<bool Function(ffi.Pointer<ggml_tensor>)>();

  bool ggml_is_vector(
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _ggml_is_vector(
      tensor,
    );
  }

  late final _ggml_is_vectorPtr =
      _lookup<ffi.NativeFunction<ffi.Bool Function(ffi.Pointer<ggml_tensor>)>>(
          'ggml_is_vector');
  late final _ggml_is_vector =
      _ggml_is_vectorPtr.asFunction<bool Function(ffi.Pointer<ggml_tensor>)>();

  bool ggml_is_matrix(
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _ggml_is_matrix(
      tensor,
    );
  }

  late final _ggml_is_matrixPtr =
      _lookup<ffi.NativeFunction<ffi.Bool Function(ffi.Pointer<ggml_tensor>)>>(
          'ggml_is_matrix');
  late final _ggml_is_matrix =
      _ggml_is_matrixPtr.asFunction<bool Function(ffi.Pointer<ggml_tensor>)>();

  bool ggml_is_3d(
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _ggml_is_3d(
      tensor,
    );
  }

  late final _ggml_is_3dPtr =
      _lookup<ffi.NativeFunction<ffi.Bool Function(ffi.Pointer<ggml_tensor>)>>(
          'ggml_is_3d');
  late final _ggml_is_3d =
      _ggml_is_3dPtr.asFunction<bool Function(ffi.Pointer<ggml_tensor>)>();

  int ggml_n_dims(
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _ggml_n_dims(
      tensor,
    );
  }

  late final _ggml_n_dimsPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<ggml_tensor>)>>(
          'ggml_n_dims');
  late final _ggml_n_dims =
      _ggml_n_dimsPtr.asFunction<int Function(ffi.Pointer<ggml_tensor>)>();

  bool ggml_is_contiguous(
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _ggml_is_contiguous(
      tensor,
    );
  }

  late final _ggml_is_contiguousPtr =
      _lookup<ffi.NativeFunction<ffi.Bool Function(ffi.Pointer<ggml_tensor>)>>(
          'ggml_is_contiguous');
  late final _ggml_is_contiguous = _ggml_is_contiguousPtr
      .asFunction<bool Function(ffi.Pointer<ggml_tensor>)>();

  bool ggml_is_contiguous_0(
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _ggml_is_contiguous_0(
      tensor,
    );
  }

  late final _ggml_is_contiguous_0Ptr =
      _lookup<ffi.NativeFunction<ffi.Bool Function(ffi.Pointer<ggml_tensor>)>>(
          'ggml_is_contiguous_0');
  late final _ggml_is_contiguous_0 = _ggml_is_contiguous_0Ptr
      .asFunction<bool Function(ffi.Pointer<ggml_tensor>)>();

  bool ggml_is_contiguous_1(
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _ggml_is_contiguous_1(
      tensor,
    );
  }

  late final _ggml_is_contiguous_1Ptr =
      _lookup<ffi.NativeFunction<ffi.Bool Function(ffi.Pointer<ggml_tensor>)>>(
          'ggml_is_contiguous_1');
  late final _ggml_is_contiguous_1 = _ggml_is_contiguous_1Ptr
      .asFunction<bool Function(ffi.Pointer<ggml_tensor>)>();

  bool ggml_is_contiguous_2(
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _ggml_is_contiguous_2(
      tensor,
    );
  }

  late final _ggml_is_contiguous_2Ptr =
      _lookup<ffi.NativeFunction<ffi.Bool Function(ffi.Pointer<ggml_tensor>)>>(
          'ggml_is_contiguous_2');
  late final _ggml_is_contiguous_2 = _ggml_is_contiguous_2Ptr
      .asFunction<bool Function(ffi.Pointer<ggml_tensor>)>();

  bool ggml_are_same_shape(
    ffi.Pointer<ggml_tensor> t0,
    ffi.Pointer<ggml_tensor> t1,
  ) {
    return _ggml_are_same_shape(
      t0,
      t1,
    );
  }

  late final _ggml_are_same_shapePtr = _lookup<
      ffi.NativeFunction<
          ffi.Bool Function(ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_are_same_shape');
  late final _ggml_are_same_shape = _ggml_are_same_shapePtr.asFunction<
      bool Function(ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  bool ggml_are_same_stride(
    ffi.Pointer<ggml_tensor> t0,
    ffi.Pointer<ggml_tensor> t1,
  ) {
    return _ggml_are_same_stride(
      t0,
      t1,
    );
  }

  late final _ggml_are_same_stridePtr = _lookup<
      ffi.NativeFunction<
          ffi.Bool Function(ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_are_same_stride');
  late final _ggml_are_same_stride = _ggml_are_same_stridePtr.asFunction<
      bool Function(ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  bool ggml_can_repeat(
    ffi.Pointer<ggml_tensor> t0,
    ffi.Pointer<ggml_tensor> t1,
  ) {
    return _ggml_can_repeat(
      t0,
      t1,
    );
  }

  late final _ggml_can_repeatPtr = _lookup<
      ffi.NativeFunction<
          ffi.Bool Function(ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_can_repeat');
  late final _ggml_can_repeat = _ggml_can_repeatPtr.asFunction<
      bool Function(ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  /// use this to compute the memory overhead of a tensor
  int ggml_tensor_overhead() {
    return _ggml_tensor_overhead();
  }

  late final _ggml_tensor_overheadPtr =
      _lookup<ffi.NativeFunction<ffi.Size Function()>>('ggml_tensor_overhead');
  late final _ggml_tensor_overhead =
      _ggml_tensor_overheadPtr.asFunction<int Function()>();

  bool ggml_validate_row_data(
    int type,
    ffi.Pointer<ffi.Void> data,
    int nbytes,
  ) {
    return _ggml_validate_row_data(
      type,
      data,
      nbytes,
    );
  }

  late final _ggml_validate_row_dataPtr = _lookup<
      ffi.NativeFunction<
          ffi.Bool Function(ffi.Int32, ffi.Pointer<ffi.Void>,
              ffi.Size)>>('ggml_validate_row_data');
  late final _ggml_validate_row_data = _ggml_validate_row_dataPtr
      .asFunction<bool Function(int, ffi.Pointer<ffi.Void>, int)>();

  /// main
  ffi.Pointer<ggml_context> ggml_init(
    ggml_init_params params,
  ) {
    return _ggml_init(
      params,
    );
  }

  late final _ggml_initPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_context> Function(ggml_init_params)>>('ggml_init');
  late final _ggml_init = _ggml_initPtr
      .asFunction<ffi.Pointer<ggml_context> Function(ggml_init_params)>();

  void ggml_reset(
    ffi.Pointer<ggml_context> ctx,
  ) {
    return _ggml_reset(
      ctx,
    );
  }

  late final _ggml_resetPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ggml_context>)>>(
          'ggml_reset');
  late final _ggml_reset =
      _ggml_resetPtr.asFunction<void Function(ffi.Pointer<ggml_context>)>();

  void ggml_free(
    ffi.Pointer<ggml_context> ctx,
  ) {
    return _ggml_free(
      ctx,
    );
  }

  late final _ggml_freePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ggml_context>)>>(
          'ggml_free');
  late final _ggml_free =
      _ggml_freePtr.asFunction<void Function(ffi.Pointer<ggml_context>)>();

  int ggml_used_mem(
    ffi.Pointer<ggml_context> ctx,
  ) {
    return _ggml_used_mem(
      ctx,
    );
  }

  late final _ggml_used_memPtr =
      _lookup<ffi.NativeFunction<ffi.Size Function(ffi.Pointer<ggml_context>)>>(
          'ggml_used_mem');
  late final _ggml_used_mem =
      _ggml_used_memPtr.asFunction<int Function(ffi.Pointer<ggml_context>)>();

  bool ggml_get_no_alloc(
    ffi.Pointer<ggml_context> ctx,
  ) {
    return _ggml_get_no_alloc(
      ctx,
    );
  }

  late final _ggml_get_no_allocPtr =
      _lookup<ffi.NativeFunction<ffi.Bool Function(ffi.Pointer<ggml_context>)>>(
          'ggml_get_no_alloc');
  late final _ggml_get_no_alloc = _ggml_get_no_allocPtr
      .asFunction<bool Function(ffi.Pointer<ggml_context>)>();

  void ggml_set_no_alloc(
    ffi.Pointer<ggml_context> ctx,
    bool no_alloc,
  ) {
    return _ggml_set_no_alloc(
      ctx,
      no_alloc,
    );
  }

  late final _ggml_set_no_allocPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ggml_context>, ffi.Bool)>>('ggml_set_no_alloc');
  late final _ggml_set_no_alloc = _ggml_set_no_allocPtr
      .asFunction<void Function(ffi.Pointer<ggml_context>, bool)>();

  ffi.Pointer<ffi.Void> ggml_get_mem_buffer(
    ffi.Pointer<ggml_context> ctx,
  ) {
    return _ggml_get_mem_buffer(
      ctx,
    );
  }

  late final _ggml_get_mem_bufferPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(
              ffi.Pointer<ggml_context>)>>('ggml_get_mem_buffer');
  late final _ggml_get_mem_buffer = _ggml_get_mem_bufferPtr
      .asFunction<ffi.Pointer<ffi.Void> Function(ffi.Pointer<ggml_context>)>();

  int ggml_get_mem_size(
    ffi.Pointer<ggml_context> ctx,
  ) {
    return _ggml_get_mem_size(
      ctx,
    );
  }

  late final _ggml_get_mem_sizePtr =
      _lookup<ffi.NativeFunction<ffi.Size Function(ffi.Pointer<ggml_context>)>>(
          'ggml_get_mem_size');
  late final _ggml_get_mem_size = _ggml_get_mem_sizePtr
      .asFunction<int Function(ffi.Pointer<ggml_context>)>();

  int ggml_get_max_tensor_size(
    ffi.Pointer<ggml_context> ctx,
  ) {
    return _ggml_get_max_tensor_size(
      ctx,
    );
  }

  late final _ggml_get_max_tensor_sizePtr =
      _lookup<ffi.NativeFunction<ffi.Size Function(ffi.Pointer<ggml_context>)>>(
          'ggml_get_max_tensor_size');
  late final _ggml_get_max_tensor_size = _ggml_get_max_tensor_sizePtr
      .asFunction<int Function(ffi.Pointer<ggml_context>)>();

  ffi.Pointer<ggml_tensor> ggml_new_tensor(
    ffi.Pointer<ggml_context> ctx,
    int type,
    int n_dims,
    ffi.Pointer<ffi.Int64> ne,
  ) {
    return _ggml_new_tensor(
      ctx,
      type,
      n_dims,
      ne,
    );
  }

  late final _ggml_new_tensorPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Int32, ffi.Int, ffi.Pointer<ffi.Int64>)>>('ggml_new_tensor');
  late final _ggml_new_tensor = _ggml_new_tensorPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, int, int, ffi.Pointer<ffi.Int64>)>();

  ffi.Pointer<ggml_tensor> ggml_new_tensor_1d(
    ffi.Pointer<ggml_context> ctx,
    int type,
    int ne0,
  ) {
    return _ggml_new_tensor_1d(
      ctx,
      type,
      ne0,
    );
  }

  late final _ggml_new_tensor_1dPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Int32, ffi.Int64)>>('ggml_new_tensor_1d');
  late final _ggml_new_tensor_1d = _ggml_new_tensor_1dPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>, int, int)>();

  ffi.Pointer<ggml_tensor> ggml_new_tensor_2d(
    ffi.Pointer<ggml_context> ctx,
    int type,
    int ne0,
    int ne1,
  ) {
    return _ggml_new_tensor_2d(
      ctx,
      type,
      ne0,
      ne1,
    );
  }

  late final _ggml_new_tensor_2dPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Int32, ffi.Int64, ffi.Int64)>>('ggml_new_tensor_2d');
  late final _ggml_new_tensor_2d = _ggml_new_tensor_2dPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, int, int, int)>();

  ffi.Pointer<ggml_tensor> ggml_new_tensor_3d(
    ffi.Pointer<ggml_context> ctx,
    int type,
    int ne0,
    int ne1,
    int ne2,
  ) {
    return _ggml_new_tensor_3d(
      ctx,
      type,
      ne0,
      ne1,
      ne2,
    );
  }

  late final _ggml_new_tensor_3dPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Int32,
              ffi.Int64,
              ffi.Int64,
              ffi.Int64)>>('ggml_new_tensor_3d');
  late final _ggml_new_tensor_3d = _ggml_new_tensor_3dPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, int, int, int, int)>();

  ffi.Pointer<ggml_tensor> ggml_new_tensor_4d(
    ffi.Pointer<ggml_context> ctx,
    int type,
    int ne0,
    int ne1,
    int ne2,
    int ne3,
  ) {
    return _ggml_new_tensor_4d(
      ctx,
      type,
      ne0,
      ne1,
      ne2,
      ne3,
    );
  }

  late final _ggml_new_tensor_4dPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Int32,
              ffi.Int64,
              ffi.Int64,
              ffi.Int64,
              ffi.Int64)>>('ggml_new_tensor_4d');
  late final _ggml_new_tensor_4d = _ggml_new_tensor_4dPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, int, int, int, int, int)>();

  ffi.Pointer<ffi.Void> ggml_new_buffer(
    ffi.Pointer<ggml_context> ctx,
    int nbytes,
  ) {
    return _ggml_new_buffer(
      ctx,
      nbytes,
    );
  }

  late final _ggml_new_bufferPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(
              ffi.Pointer<ggml_context>, ffi.Size)>>('ggml_new_buffer');
  late final _ggml_new_buffer = _ggml_new_bufferPtr.asFunction<
      ffi.Pointer<ffi.Void> Function(ffi.Pointer<ggml_context>, int)>();

  ffi.Pointer<ggml_tensor> ggml_dup_tensor(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> src,
  ) {
    return _ggml_dup_tensor(
      ctx,
      src,
    );
  }

  late final _ggml_dup_tensorPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_dup_tensor');
  late final _ggml_dup_tensor = _ggml_dup_tensorPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_view_tensor(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> src,
  ) {
    return _ggml_view_tensor(
      ctx,
      src,
    );
  }

  late final _ggml_view_tensorPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_view_tensor');
  late final _ggml_view_tensor = _ggml_view_tensorPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  /// Context tensor enumeration and lookup
  ffi.Pointer<ggml_tensor> ggml_get_first_tensor(
    ffi.Pointer<ggml_context> ctx,
  ) {
    return _ggml_get_first_tensor(
      ctx,
    );
  }

  late final _ggml_get_first_tensorPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>)>>('ggml_get_first_tensor');
  late final _ggml_get_first_tensor = _ggml_get_first_tensorPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>)>();

  ffi.Pointer<ggml_tensor> ggml_get_next_tensor(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _ggml_get_next_tensor(
      ctx,
      tensor,
    );
  }

  late final _ggml_get_next_tensorPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_get_next_tensor');
  late final _ggml_get_next_tensor = _ggml_get_next_tensorPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_get_tensor(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ffi.Char> name,
  ) {
    return _ggml_get_tensor(
      ctx,
      name,
    );
  }

  late final _ggml_get_tensorPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ffi.Char>)>>('ggml_get_tensor');
  late final _ggml_get_tensor = _ggml_get_tensorPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ffi.Char>)>();

  /// Converts a flat index into coordinates
  void ggml_unravel_index(
    ffi.Pointer<ggml_tensor> tensor,
    int i,
    ffi.Pointer<ffi.Int64> i0,
    ffi.Pointer<ffi.Int64> i1,
    ffi.Pointer<ffi.Int64> i2,
    ffi.Pointer<ffi.Int64> i3,
  ) {
    return _ggml_unravel_index(
      tensor,
      i,
      i0,
      i1,
      i2,
      i3,
    );
  }

  late final _ggml_unravel_indexPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ggml_tensor>,
              ffi.Int64,
              ffi.Pointer<ffi.Int64>,
              ffi.Pointer<ffi.Int64>,
              ffi.Pointer<ffi.Int64>,
              ffi.Pointer<ffi.Int64>)>>('ggml_unravel_index');
  late final _ggml_unravel_index = _ggml_unravel_indexPtr.asFunction<
      void Function(
          ffi.Pointer<ggml_tensor>,
          int,
          ffi.Pointer<ffi.Int64>,
          ffi.Pointer<ffi.Int64>,
          ffi.Pointer<ffi.Int64>,
          ffi.Pointer<ffi.Int64>)>();

  int ggml_get_unary_op(
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _ggml_get_unary_op(
      tensor,
    );
  }

  late final _ggml_get_unary_opPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<ggml_tensor>)>>(
          'ggml_get_unary_op');
  late final _ggml_get_unary_op = _ggml_get_unary_opPtr
      .asFunction<int Function(ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ffi.Void> ggml_get_data(
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _ggml_get_data(
      tensor,
    );
  }

  late final _ggml_get_dataPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(
              ffi.Pointer<ggml_tensor>)>>('ggml_get_data');
  late final _ggml_get_data = _ggml_get_dataPtr
      .asFunction<ffi.Pointer<ffi.Void> Function(ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ffi.Float> ggml_get_data_f32(
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _ggml_get_data_f32(
      tensor,
    );
  }

  late final _ggml_get_data_f32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Float> Function(
              ffi.Pointer<ggml_tensor>)>>('ggml_get_data_f32');
  late final _ggml_get_data_f32 = _ggml_get_data_f32Ptr
      .asFunction<ffi.Pointer<ffi.Float> Function(ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ffi.Char> ggml_get_name(
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _ggml_get_name(
      tensor,
    );
  }

  late final _ggml_get_namePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<ggml_tensor>)>>('ggml_get_name');
  late final _ggml_get_name = _ggml_get_namePtr
      .asFunction<ffi.Pointer<ffi.Char> Function(ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_set_name(
    ffi.Pointer<ggml_tensor> tensor,
    ffi.Pointer<ffi.Char> name,
  ) {
    return _ggml_set_name(
      tensor,
      name,
    );
  }

  late final _ggml_set_namePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ffi.Char>)>>('ggml_set_name');
  late final _ggml_set_name = _ggml_set_namePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ffi.Char>)>();

  ffi.Pointer<ggml_tensor> ggml_format_name(
    ffi.Pointer<ggml_tensor> tensor,
    ffi.Pointer<ffi.Char> fmt,
  ) {
    return _ggml_format_name(
      tensor,
      fmt,
    );
  }

  late final _ggml_format_namePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ffi.Char>)>>('ggml_format_name');
  late final _ggml_format_name = _ggml_format_namePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ffi.Char>)>();

  /// Tensor flags
  void ggml_set_input(
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _ggml_set_input(
      tensor,
    );
  }

  late final _ggml_set_inputPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ggml_tensor>)>>(
          'ggml_set_input');
  late final _ggml_set_input =
      _ggml_set_inputPtr.asFunction<void Function(ffi.Pointer<ggml_tensor>)>();

  void ggml_set_output(
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _ggml_set_output(
      tensor,
    );
  }

  late final _ggml_set_outputPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ggml_tensor>)>>(
          'ggml_set_output');
  late final _ggml_set_output =
      _ggml_set_outputPtr.asFunction<void Function(ffi.Pointer<ggml_tensor>)>();

  void ggml_set_param(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _ggml_set_param(
      ctx,
      tensor,
    );
  }

  late final _ggml_set_paramPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_set_param');
  late final _ggml_set_param = _ggml_set_paramPtr.asFunction<
      void Function(ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  void ggml_set_loss(
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _ggml_set_loss(
      tensor,
    );
  }

  late final _ggml_set_lossPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ggml_tensor>)>>(
          'ggml_set_loss');
  late final _ggml_set_loss =
      _ggml_set_lossPtr.asFunction<void Function(ffi.Pointer<ggml_tensor>)>();

  /// operations on tensors with backpropagation
  ffi.Pointer<ggml_tensor> ggml_dup(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_dup(
      ctx,
      a,
    );
  }

  late final _ggml_dupPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_dup');
  late final _ggml_dup = _ggml_dupPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  /// in-place, returns view(a)
  ffi.Pointer<ggml_tensor> ggml_dup_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_dup_inplace(
      ctx,
      a,
    );
  }

  late final _ggml_dup_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_dup_inplace');
  late final _ggml_dup_inplace = _ggml_dup_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_add(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
  ) {
    return _ggml_add(
      ctx,
      a,
      b,
    );
  }

  late final _ggml_addPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>>('ggml_add');
  late final _ggml_add = _ggml_addPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_add_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
  ) {
    return _ggml_add_inplace(
      ctx,
      a,
      b,
    );
  }

  late final _ggml_add_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_add_inplace');
  late final _ggml_add_inplace = _ggml_add_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_add_cast(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    int type,
  ) {
    return _ggml_add_cast(
      ctx,
      a,
      b,
      type,
    );
  }

  late final _ggml_add_castPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int32)>>('ggml_add_cast');
  late final _ggml_add_cast = _ggml_add_castPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>, int)>();

  ffi.Pointer<ggml_tensor> ggml_add1(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
  ) {
    return _ggml_add1(
      ctx,
      a,
      b,
    );
  }

  late final _ggml_add1Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_add1');
  late final _ggml_add1 = _ggml_add1Ptr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_add1_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
  ) {
    return _ggml_add1_inplace(
      ctx,
      a,
      b,
    );
  }

  late final _ggml_add1_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_add1_inplace');
  late final _ggml_add1_inplace = _ggml_add1_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  /// dst = a
  /// view(dst, nb1, nb2, nb3, offset) += b
  /// return dst
  ffi.Pointer<ggml_tensor> ggml_acc(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    int nb1,
    int nb2,
    int nb3,
    int offset,
  ) {
    return _ggml_acc(
      ctx,
      a,
      b,
      nb1,
      nb2,
      nb3,
      offset,
    );
  }

  late final _ggml_accPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Size,
              ffi.Size,
              ffi.Size,
              ffi.Size)>>('ggml_acc');
  late final _ggml_acc = _ggml_accPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          int,
          int,
          int,
          int)>();

  ffi.Pointer<ggml_tensor> ggml_acc_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    int nb1,
    int nb2,
    int nb3,
    int offset,
  ) {
    return _ggml_acc_inplace(
      ctx,
      a,
      b,
      nb1,
      nb2,
      nb3,
      offset,
    );
  }

  late final _ggml_acc_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Size,
              ffi.Size,
              ffi.Size,
              ffi.Size)>>('ggml_acc_inplace');
  late final _ggml_acc_inplace = _ggml_acc_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          int,
          int,
          int,
          int)>();

  ffi.Pointer<ggml_tensor> ggml_sub(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
  ) {
    return _ggml_sub(
      ctx,
      a,
      b,
    );
  }

  late final _ggml_subPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>>('ggml_sub');
  late final _ggml_sub = _ggml_subPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_sub_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
  ) {
    return _ggml_sub_inplace(
      ctx,
      a,
      b,
    );
  }

  late final _ggml_sub_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_sub_inplace');
  late final _ggml_sub_inplace = _ggml_sub_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_mul(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
  ) {
    return _ggml_mul(
      ctx,
      a,
      b,
    );
  }

  late final _ggml_mulPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>>('ggml_mul');
  late final _ggml_mul = _ggml_mulPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_mul_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
  ) {
    return _ggml_mul_inplace(
      ctx,
      a,
      b,
    );
  }

  late final _ggml_mul_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_mul_inplace');
  late final _ggml_mul_inplace = _ggml_mul_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_div(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
  ) {
    return _ggml_div(
      ctx,
      a,
      b,
    );
  }

  late final _ggml_divPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>>('ggml_div');
  late final _ggml_div = _ggml_divPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_div_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
  ) {
    return _ggml_div_inplace(
      ctx,
      a,
      b,
    );
  }

  late final _ggml_div_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_div_inplace');
  late final _ggml_div_inplace = _ggml_div_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_sqr(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_sqr(
      ctx,
      a,
    );
  }

  late final _ggml_sqrPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_sqr');
  late final _ggml_sqr = _ggml_sqrPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_sqr_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_sqr_inplace(
      ctx,
      a,
    );
  }

  late final _ggml_sqr_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_sqr_inplace');
  late final _ggml_sqr_inplace = _ggml_sqr_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_sqrt(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_sqrt(
      ctx,
      a,
    );
  }

  late final _ggml_sqrtPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_sqrt');
  late final _ggml_sqrt = _ggml_sqrtPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_sqrt_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_sqrt_inplace(
      ctx,
      a,
    );
  }

  late final _ggml_sqrt_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_sqrt_inplace');
  late final _ggml_sqrt_inplace = _ggml_sqrt_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_log(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_log(
      ctx,
      a,
    );
  }

  late final _ggml_logPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_log');
  late final _ggml_log = _ggml_logPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_log_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_log_inplace(
      ctx,
      a,
    );
  }

  late final _ggml_log_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_log_inplace');
  late final _ggml_log_inplace = _ggml_log_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_sin(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_sin(
      ctx,
      a,
    );
  }

  late final _ggml_sinPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_sin');
  late final _ggml_sin = _ggml_sinPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_sin_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_sin_inplace(
      ctx,
      a,
    );
  }

  late final _ggml_sin_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_sin_inplace');
  late final _ggml_sin_inplace = _ggml_sin_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_cos(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_cos(
      ctx,
      a,
    );
  }

  late final _ggml_cosPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_cos');
  late final _ggml_cos = _ggml_cosPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_cos_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_cos_inplace(
      ctx,
      a,
    );
  }

  late final _ggml_cos_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_cos_inplace');
  late final _ggml_cos_inplace = _ggml_cos_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  /// return scalar
  ffi.Pointer<ggml_tensor> ggml_sum(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_sum(
      ctx,
      a,
    );
  }

  late final _ggml_sumPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_sum');
  late final _ggml_sum = _ggml_sumPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  /// sums along rows, with input shape [a,b,c,d] return shape [1,b,c,d]
  ffi.Pointer<ggml_tensor> ggml_sum_rows(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_sum_rows(
      ctx,
      a,
    );
  }

  late final _ggml_sum_rowsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_sum_rows');
  late final _ggml_sum_rows = _ggml_sum_rowsPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  /// mean along rows
  ffi.Pointer<ggml_tensor> ggml_mean(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_mean(
      ctx,
      a,
    );
  }

  late final _ggml_meanPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_mean');
  late final _ggml_mean = _ggml_meanPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  /// argmax along rows
  ffi.Pointer<ggml_tensor> ggml_argmax(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_argmax(
      ctx,
      a,
    );
  }

  late final _ggml_argmaxPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_argmax');
  late final _ggml_argmax = _ggml_argmaxPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  /// count number of equal elements in a and b
  ffi.Pointer<ggml_tensor> ggml_count_equal(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
  ) {
    return _ggml_count_equal(
      ctx,
      a,
      b,
    );
  }

  late final _ggml_count_equalPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_count_equal');
  late final _ggml_count_equal = _ggml_count_equalPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  /// if a is the same shape as b, and a is not parameter, return a
  /// otherwise, return a new tensor: repeat(a) to fit in b
  ffi.Pointer<ggml_tensor> ggml_repeat(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
  ) {
    return _ggml_repeat(
      ctx,
      a,
      b,
    );
  }

  late final _ggml_repeatPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_repeat');
  late final _ggml_repeat = _ggml_repeatPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  /// sums repetitions in a into shape of b
  ffi.Pointer<ggml_tensor> ggml_repeat_back(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
  ) {
    return _ggml_repeat_back(
      ctx,
      a,
      b,
    );
  }

  late final _ggml_repeat_backPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_repeat_back');
  late final _ggml_repeat_back = _ggml_repeat_backPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  /// concat a and b along dim
  /// used in stable-diffusion
  ffi.Pointer<ggml_tensor> ggml_concat(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    int dim,
  ) {
    return _ggml_concat(
      ctx,
      a,
      b,
      dim,
    );
  }

  late final _ggml_concatPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int)>>('ggml_concat');
  late final _ggml_concat = _ggml_concatPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>, int)>();

  ffi.Pointer<ggml_tensor> ggml_abs(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_abs(
      ctx,
      a,
    );
  }

  late final _ggml_absPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_abs');
  late final _ggml_abs = _ggml_absPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_abs_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_abs_inplace(
      ctx,
      a,
    );
  }

  late final _ggml_abs_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_abs_inplace');
  late final _ggml_abs_inplace = _ggml_abs_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_sgn(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_sgn(
      ctx,
      a,
    );
  }

  late final _ggml_sgnPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_sgn');
  late final _ggml_sgn = _ggml_sgnPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_sgn_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_sgn_inplace(
      ctx,
      a,
    );
  }

  late final _ggml_sgn_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_sgn_inplace');
  late final _ggml_sgn_inplace = _ggml_sgn_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_neg(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_neg(
      ctx,
      a,
    );
  }

  late final _ggml_negPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_neg');
  late final _ggml_neg = _ggml_negPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_neg_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_neg_inplace(
      ctx,
      a,
    );
  }

  late final _ggml_neg_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_neg_inplace');
  late final _ggml_neg_inplace = _ggml_neg_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_step(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_step(
      ctx,
      a,
    );
  }

  late final _ggml_stepPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_step');
  late final _ggml_step = _ggml_stepPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_step_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_step_inplace(
      ctx,
      a,
    );
  }

  late final _ggml_step_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_step_inplace');
  late final _ggml_step_inplace = _ggml_step_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_tanh(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_tanh(
      ctx,
      a,
    );
  }

  late final _ggml_tanhPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_tanh');
  late final _ggml_tanh = _ggml_tanhPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_tanh_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_tanh_inplace(
      ctx,
      a,
    );
  }

  late final _ggml_tanh_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_tanh_inplace');
  late final _ggml_tanh_inplace = _ggml_tanh_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_elu(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_elu(
      ctx,
      a,
    );
  }

  late final _ggml_eluPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_elu');
  late final _ggml_elu = _ggml_eluPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_elu_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_elu_inplace(
      ctx,
      a,
    );
  }

  late final _ggml_elu_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_elu_inplace');
  late final _ggml_elu_inplace = _ggml_elu_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_relu(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_relu(
      ctx,
      a,
    );
  }

  late final _ggml_reluPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_relu');
  late final _ggml_relu = _ggml_reluPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_leaky_relu(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    double negative_slope,
    bool inplace,
  ) {
    return _ggml_leaky_relu(
      ctx,
      a,
      negative_slope,
      inplace,
    );
  }

  late final _ggml_leaky_reluPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Float,
              ffi.Bool)>>('ggml_leaky_relu');
  late final _ggml_leaky_relu = _ggml_leaky_reluPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>, double, bool)>();

  ffi.Pointer<ggml_tensor> ggml_relu_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_relu_inplace(
      ctx,
      a,
    );
  }

  late final _ggml_relu_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_relu_inplace');
  late final _ggml_relu_inplace = _ggml_relu_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_sigmoid(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_sigmoid(
      ctx,
      a,
    );
  }

  late final _ggml_sigmoidPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_sigmoid');
  late final _ggml_sigmoid = _ggml_sigmoidPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_sigmoid_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_sigmoid_inplace(
      ctx,
      a,
    );
  }

  late final _ggml_sigmoid_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_sigmoid_inplace');
  late final _ggml_sigmoid_inplace = _ggml_sigmoid_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_gelu(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_gelu(
      ctx,
      a,
    );
  }

  late final _ggml_geluPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_gelu');
  late final _ggml_gelu = _ggml_geluPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_gelu_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_gelu_inplace(
      ctx,
      a,
    );
  }

  late final _ggml_gelu_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_gelu_inplace');
  late final _ggml_gelu_inplace = _ggml_gelu_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_gelu_quick(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_gelu_quick(
      ctx,
      a,
    );
  }

  late final _ggml_gelu_quickPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_gelu_quick');
  late final _ggml_gelu_quick = _ggml_gelu_quickPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_gelu_quick_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_gelu_quick_inplace(
      ctx,
      a,
    );
  }

  late final _ggml_gelu_quick_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_gelu_quick_inplace');
  late final _ggml_gelu_quick_inplace = _ggml_gelu_quick_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_silu(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_silu(
      ctx,
      a,
    );
  }

  late final _ggml_siluPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_silu');
  late final _ggml_silu = _ggml_siluPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_silu_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_silu_inplace(
      ctx,
      a,
    );
  }

  late final _ggml_silu_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_silu_inplace');
  late final _ggml_silu_inplace = _ggml_silu_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  /// a - x
  /// b - dy
  ffi.Pointer<ggml_tensor> ggml_silu_back(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
  ) {
    return _ggml_silu_back(
      ctx,
      a,
      b,
    );
  }

  late final _ggml_silu_backPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_silu_back');
  late final _ggml_silu_back = _ggml_silu_backPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  /// hardswish(x) = x * relu6(x + 3) / 6
  ffi.Pointer<ggml_tensor> ggml_hardswish(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_hardswish(
      ctx,
      a,
    );
  }

  late final _ggml_hardswishPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_hardswish');
  late final _ggml_hardswish = _ggml_hardswishPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  /// hardsigmoid(x) = relu6(x + 3) / 6
  ffi.Pointer<ggml_tensor> ggml_hardsigmoid(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_hardsigmoid(
      ctx,
      a,
    );
  }

  late final _ggml_hardsigmoidPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_hardsigmoid');
  late final _ggml_hardsigmoid = _ggml_hardsigmoidPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_exp(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_exp(
      ctx,
      a,
    );
  }

  late final _ggml_expPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_exp');
  late final _ggml_exp = _ggml_expPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_exp_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_exp_inplace(
      ctx,
      a,
    );
  }

  late final _ggml_exp_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_exp_inplace');
  late final _ggml_exp_inplace = _ggml_exp_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  /// normalize along rows
  ffi.Pointer<ggml_tensor> ggml_norm(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    double eps,
  ) {
    return _ggml_norm(
      ctx,
      a,
      eps,
    );
  }

  late final _ggml_normPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ffi.Float)>>('ggml_norm');
  late final _ggml_norm = _ggml_normPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>, double)>();

  ffi.Pointer<ggml_tensor> ggml_norm_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    double eps,
  ) {
    return _ggml_norm_inplace(
      ctx,
      a,
      eps,
    );
  }

  late final _ggml_norm_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ffi.Float)>>('ggml_norm_inplace');
  late final _ggml_norm_inplace = _ggml_norm_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>, double)>();

  ffi.Pointer<ggml_tensor> ggml_rms_norm(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    double eps,
  ) {
    return _ggml_rms_norm(
      ctx,
      a,
      eps,
    );
  }

  late final _ggml_rms_normPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ffi.Float)>>('ggml_rms_norm');
  late final _ggml_rms_norm = _ggml_rms_normPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>, double)>();

  ffi.Pointer<ggml_tensor> ggml_rms_norm_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    double eps,
  ) {
    return _ggml_rms_norm_inplace(
      ctx,
      a,
      eps,
    );
  }

  late final _ggml_rms_norm_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ffi.Float)>>('ggml_rms_norm_inplace');
  late final _ggml_rms_norm_inplace = _ggml_rms_norm_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>, double)>();

  /// group normalize along ne0*ne1*n_groups
  /// used in stable-diffusion
  ffi.Pointer<ggml_tensor> ggml_group_norm(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int n_groups,
    double eps,
  ) {
    return _ggml_group_norm(
      ctx,
      a,
      n_groups,
      eps,
    );
  }

  late final _ggml_group_normPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int,
              ffi.Float)>>('ggml_group_norm');
  late final _ggml_group_norm = _ggml_group_normPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>, int, double)>();

  ffi.Pointer<ggml_tensor> ggml_group_norm_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int n_groups,
    double eps,
  ) {
    return _ggml_group_norm_inplace(
      ctx,
      a,
      n_groups,
      eps,
    );
  }

  late final _ggml_group_norm_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int,
              ffi.Float)>>('ggml_group_norm_inplace');
  late final _ggml_group_norm_inplace = _ggml_group_norm_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>, int, double)>();

  /// a - x
  /// b - dy
  ffi.Pointer<ggml_tensor> ggml_rms_norm_back(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    double eps,
  ) {
    return _ggml_rms_norm_back(
      ctx,
      a,
      b,
      eps,
    );
  }

  late final _ggml_rms_norm_backPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Float)>>('ggml_rms_norm_back');
  late final _ggml_rms_norm_back = _ggml_rms_norm_backPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>, double)>();

  /// A: k columns, n rows => [ne03, ne02, n, k]
  /// B: k columns, m rows  (i.e. we transpose it internally) => [ne03 * x, ne02 * y, m, k]
  /// result is n columns, m rows => [ne03 * x, ne02 * y, m, n]
  ffi.Pointer<ggml_tensor> ggml_mul_mat(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
  ) {
    return _ggml_mul_mat(
      ctx,
      a,
      b,
    );
  }

  late final _ggml_mul_matPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_mul_mat');
  late final _ggml_mul_mat = _ggml_mul_matPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  /// change the precision of a matrix multiplication
  /// set to GGML_PREC_F32 for higher precision (useful for phi-2)
  void ggml_mul_mat_set_prec(
    ffi.Pointer<ggml_tensor> a,
    int prec,
  ) {
    return _ggml_mul_mat_set_prec(
      a,
      prec,
    );
  }

  late final _ggml_mul_mat_set_precPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ggml_tensor>, ffi.Int32)>>('ggml_mul_mat_set_prec');
  late final _ggml_mul_mat_set_prec = _ggml_mul_mat_set_precPtr
      .asFunction<void Function(ffi.Pointer<ggml_tensor>, int)>();

  /// indirect matrix multiplication
  ffi.Pointer<ggml_tensor> ggml_mul_mat_id(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> as1,
    ffi.Pointer<ggml_tensor> b,
    ffi.Pointer<ggml_tensor> ids,
  ) {
    return _ggml_mul_mat_id(
      ctx,
      as1,
      b,
      ids,
    );
  }

  late final _ggml_mul_mat_idPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_mul_mat_id');
  late final _ggml_mul_mat_id = _ggml_mul_mat_idPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>)>();

  /// A: m columns, n rows,
  /// B: p columns, n rows,
  /// result is m columns, p rows
  ffi.Pointer<ggml_tensor> ggml_out_prod(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
  ) {
    return _ggml_out_prod(
      ctx,
      a,
      b,
    );
  }

  late final _ggml_out_prodPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_out_prod');
  late final _ggml_out_prod = _ggml_out_prodPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  /// operations on tensors without backpropagation
  ffi.Pointer<ggml_tensor> ggml_scale(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    double s,
  ) {
    return _ggml_scale(
      ctx,
      a,
      s,
    );
  }

  late final _ggml_scalePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ffi.Float)>>('ggml_scale');
  late final _ggml_scale = _ggml_scalePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>, double)>();

  /// in-place, returns view(a)
  ffi.Pointer<ggml_tensor> ggml_scale_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    double s,
  ) {
    return _ggml_scale_inplace(
      ctx,
      a,
      s,
    );
  }

  late final _ggml_scale_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ffi.Float)>>('ggml_scale_inplace');
  late final _ggml_scale_inplace = _ggml_scale_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>, double)>();

  /// b -> view(a,offset,nb1,nb2,3), return modified a
  ffi.Pointer<ggml_tensor> ggml_set(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    int nb1,
    int nb2,
    int nb3,
    int offset,
  ) {
    return _ggml_set(
      ctx,
      a,
      b,
      nb1,
      nb2,
      nb3,
      offset,
    );
  }

  late final _ggml_setPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Size,
              ffi.Size,
              ffi.Size,
              ffi.Size)>>('ggml_set');
  late final _ggml_set = _ggml_setPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          int,
          int,
          int,
          int)>();

  /// b -> view(a,offset,nb1,nb2,3), return view(a)
  ffi.Pointer<ggml_tensor> ggml_set_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    int nb1,
    int nb2,
    int nb3,
    int offset,
  ) {
    return _ggml_set_inplace(
      ctx,
      a,
      b,
      nb1,
      nb2,
      nb3,
      offset,
    );
  }

  late final _ggml_set_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Size,
              ffi.Size,
              ffi.Size,
              ffi.Size)>>('ggml_set_inplace');
  late final _ggml_set_inplace = _ggml_set_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          int,
          int,
          int,
          int)>();

  ffi.Pointer<ggml_tensor> ggml_set_1d(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    int offset,
  ) {
    return _ggml_set_1d(
      ctx,
      a,
      b,
      offset,
    );
  }

  late final _ggml_set_1dPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Size)>>('ggml_set_1d');
  late final _ggml_set_1d = _ggml_set_1dPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>, int)>();

  ffi.Pointer<ggml_tensor> ggml_set_1d_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    int offset,
  ) {
    return _ggml_set_1d_inplace(
      ctx,
      a,
      b,
      offset,
    );
  }

  late final _ggml_set_1d_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Size)>>('ggml_set_1d_inplace');
  late final _ggml_set_1d_inplace = _ggml_set_1d_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>, int)>();

  /// b -> view(a,offset,nb1,nb2,3), return modified a
  ffi.Pointer<ggml_tensor> ggml_set_2d(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    int nb1,
    int offset,
  ) {
    return _ggml_set_2d(
      ctx,
      a,
      b,
      nb1,
      offset,
    );
  }

  late final _ggml_set_2dPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Size,
              ffi.Size)>>('ggml_set_2d');
  late final _ggml_set_2d = _ggml_set_2dPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>, int, int)>();

  /// b -> view(a,offset,nb1,nb2,3), return view(a)
  ffi.Pointer<ggml_tensor> ggml_set_2d_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    int nb1,
    int offset,
  ) {
    return _ggml_set_2d_inplace(
      ctx,
      a,
      b,
      nb1,
      offset,
    );
  }

  late final _ggml_set_2d_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Size,
              ffi.Size)>>('ggml_set_2d_inplace');
  late final _ggml_set_2d_inplace = _ggml_set_2d_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>, int, int)>();

  /// a -> b, return view(b)
  ffi.Pointer<ggml_tensor> ggml_cpy(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
  ) {
    return _ggml_cpy(
      ctx,
      a,
      b,
    );
  }

  late final _ggml_cpyPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>>('ggml_cpy');
  late final _ggml_cpy = _ggml_cpyPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_cast(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int type,
  ) {
    return _ggml_cast(
      ctx,
      a,
      type,
    );
  }

  late final _ggml_castPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ffi.Int32)>>('ggml_cast');
  late final _ggml_cast = _ggml_castPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>, int)>();

  /// make contiguous
  ffi.Pointer<ggml_tensor> ggml_cont(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_cont(
      ctx,
      a,
    );
  }

  late final _ggml_contPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_cont');
  late final _ggml_cont = _ggml_contPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  /// make contiguous, with new shape
  ffi.Pointer<ggml_tensor> ggml_cont_1d(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int ne0,
  ) {
    return _ggml_cont_1d(
      ctx,
      a,
      ne0,
    );
  }

  late final _ggml_cont_1dPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ffi.Int64)>>('ggml_cont_1d');
  late final _ggml_cont_1d = _ggml_cont_1dPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>, int)>();

  ffi.Pointer<ggml_tensor> ggml_cont_2d(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int ne0,
    int ne1,
  ) {
    return _ggml_cont_2d(
      ctx,
      a,
      ne0,
      ne1,
    );
  }

  late final _ggml_cont_2dPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ffi.Int64, ffi.Int64)>>('ggml_cont_2d');
  late final _ggml_cont_2d = _ggml_cont_2dPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>, int, int)>();

  ffi.Pointer<ggml_tensor> ggml_cont_3d(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int ne0,
    int ne1,
    int ne2,
  ) {
    return _ggml_cont_3d(
      ctx,
      a,
      ne0,
      ne1,
      ne2,
    );
  }

  late final _ggml_cont_3dPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int64,
              ffi.Int64,
              ffi.Int64)>>('ggml_cont_3d');
  late final _ggml_cont_3d = _ggml_cont_3dPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, int, int, int)>();

  ffi.Pointer<ggml_tensor> ggml_cont_4d(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int ne0,
    int ne1,
    int ne2,
    int ne3,
  ) {
    return _ggml_cont_4d(
      ctx,
      a,
      ne0,
      ne1,
      ne2,
      ne3,
    );
  }

  late final _ggml_cont_4dPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int64,
              ffi.Int64,
              ffi.Int64,
              ffi.Int64)>>('ggml_cont_4d');
  late final _ggml_cont_4d = _ggml_cont_4dPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, int, int, int, int)>();

  /// return view(a), b specifies the new shape
  /// TODO: when we start computing gradient, make a copy instead of view
  ffi.Pointer<ggml_tensor> ggml_reshape(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
  ) {
    return _ggml_reshape(
      ctx,
      a,
      b,
    );
  }

  late final _ggml_reshapePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_reshape');
  late final _ggml_reshape = _ggml_reshapePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  /// return view(a)
  /// TODO: when we start computing gradient, make a copy instead of view
  ffi.Pointer<ggml_tensor> ggml_reshape_1d(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int ne0,
  ) {
    return _ggml_reshape_1d(
      ctx,
      a,
      ne0,
    );
  }

  late final _ggml_reshape_1dPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ffi.Int64)>>('ggml_reshape_1d');
  late final _ggml_reshape_1d = _ggml_reshape_1dPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>, int)>();

  ffi.Pointer<ggml_tensor> ggml_reshape_2d(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int ne0,
    int ne1,
  ) {
    return _ggml_reshape_2d(
      ctx,
      a,
      ne0,
      ne1,
    );
  }

  late final _ggml_reshape_2dPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int64,
              ffi.Int64)>>('ggml_reshape_2d');
  late final _ggml_reshape_2d = _ggml_reshape_2dPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>, int, int)>();

  /// return view(a)
  /// TODO: when we start computing gradient, make a copy instead of view
  ffi.Pointer<ggml_tensor> ggml_reshape_3d(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int ne0,
    int ne1,
    int ne2,
  ) {
    return _ggml_reshape_3d(
      ctx,
      a,
      ne0,
      ne1,
      ne2,
    );
  }

  late final _ggml_reshape_3dPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int64,
              ffi.Int64,
              ffi.Int64)>>('ggml_reshape_3d');
  late final _ggml_reshape_3d = _ggml_reshape_3dPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, int, int, int)>();

  ffi.Pointer<ggml_tensor> ggml_reshape_4d(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int ne0,
    int ne1,
    int ne2,
    int ne3,
  ) {
    return _ggml_reshape_4d(
      ctx,
      a,
      ne0,
      ne1,
      ne2,
      ne3,
    );
  }

  late final _ggml_reshape_4dPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int64,
              ffi.Int64,
              ffi.Int64,
              ffi.Int64)>>('ggml_reshape_4d');
  late final _ggml_reshape_4d = _ggml_reshape_4dPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, int, int, int, int)>();

  /// offset in bytes
  ffi.Pointer<ggml_tensor> ggml_view_1d(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int ne0,
    int offset,
  ) {
    return _ggml_view_1d(
      ctx,
      a,
      ne0,
      offset,
    );
  }

  late final _ggml_view_1dPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ffi.Int64, ffi.Size)>>('ggml_view_1d');
  late final _ggml_view_1d = _ggml_view_1dPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>, int, int)>();

  ffi.Pointer<ggml_tensor> ggml_view_2d(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int ne0,
    int ne1,
    int nb1,
    int offset,
  ) {
    return _ggml_view_2d(
      ctx,
      a,
      ne0,
      ne1,
      nb1,
      offset,
    );
  }

  late final _ggml_view_2dPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int64,
              ffi.Int64,
              ffi.Size,
              ffi.Size)>>('ggml_view_2d');
  late final _ggml_view_2d = _ggml_view_2dPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, int, int, int, int)>();

  ffi.Pointer<ggml_tensor> ggml_view_3d(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int ne0,
    int ne1,
    int ne2,
    int nb1,
    int nb2,
    int offset,
  ) {
    return _ggml_view_3d(
      ctx,
      a,
      ne0,
      ne1,
      ne2,
      nb1,
      nb2,
      offset,
    );
  }

  late final _ggml_view_3dPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int64,
              ffi.Int64,
              ffi.Int64,
              ffi.Size,
              ffi.Size,
              ffi.Size)>>('ggml_view_3d');
  late final _ggml_view_3d = _ggml_view_3dPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, int, int, int, int, int, int)>();

  ffi.Pointer<ggml_tensor> ggml_view_4d(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int ne0,
    int ne1,
    int ne2,
    int ne3,
    int nb1,
    int nb2,
    int nb3,
    int offset,
  ) {
    return _ggml_view_4d(
      ctx,
      a,
      ne0,
      ne1,
      ne2,
      ne3,
      nb1,
      nb2,
      nb3,
      offset,
    );
  }

  late final _ggml_view_4dPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int64,
              ffi.Int64,
              ffi.Int64,
              ffi.Int64,
              ffi.Size,
              ffi.Size,
              ffi.Size,
              ffi.Size)>>('ggml_view_4d');
  late final _ggml_view_4d = _ggml_view_4dPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, int, int, int, int, int, int, int, int)>();

  ffi.Pointer<ggml_tensor> ggml_permute(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int axis0,
    int axis1,
    int axis2,
    int axis3,
  ) {
    return _ggml_permute(
      ctx,
      a,
      axis0,
      axis1,
      axis2,
      axis3,
    );
  }

  late final _ggml_permutePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int,
              ffi.Int,
              ffi.Int,
              ffi.Int)>>('ggml_permute');
  late final _ggml_permute = _ggml_permutePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, int, int, int, int)>();

  /// alias for ggml_permute(ctx, a, 1, 0, 2, 3)
  ffi.Pointer<ggml_tensor> ggml_transpose(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_transpose(
      ctx,
      a,
    );
  }

  late final _ggml_transposePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_transpose');
  late final _ggml_transpose = _ggml_transposePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  /// supports 3D: a->ne[2] == b->ne[1]
  ffi.Pointer<ggml_tensor> ggml_get_rows(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
  ) {
    return _ggml_get_rows(
      ctx,
      a,
      b,
    );
  }

  late final _ggml_get_rowsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_get_rows');
  late final _ggml_get_rows = _ggml_get_rowsPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_get_rows_back(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    ffi.Pointer<ggml_tensor> c,
  ) {
    return _ggml_get_rows_back(
      ctx,
      a,
      b,
      c,
    );
  }

  late final _ggml_get_rows_backPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_get_rows_back');
  late final _ggml_get_rows_back = _ggml_get_rows_backPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_diag(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_diag(
      ctx,
      a,
    );
  }

  late final _ggml_diagPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_diag');
  late final _ggml_diag = _ggml_diagPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  /// set elements above the diagonal to -INF
  ffi.Pointer<ggml_tensor> ggml_diag_mask_inf(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int n_past,
  ) {
    return _ggml_diag_mask_inf(
      ctx,
      a,
      n_past,
    );
  }

  late final _ggml_diag_mask_infPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ffi.Int)>>('ggml_diag_mask_inf');
  late final _ggml_diag_mask_inf = _ggml_diag_mask_infPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>, int)>();

  /// in-place, returns view(a)
  ffi.Pointer<ggml_tensor> ggml_diag_mask_inf_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int n_past,
  ) {
    return _ggml_diag_mask_inf_inplace(
      ctx,
      a,
      n_past,
    );
  }

  late final _ggml_diag_mask_inf_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int)>>('ggml_diag_mask_inf_inplace');
  late final _ggml_diag_mask_inf_inplace =
      _ggml_diag_mask_inf_inplacePtr.asFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>, int)>();

  /// set elements above the diagonal to 0
  ffi.Pointer<ggml_tensor> ggml_diag_mask_zero(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int n_past,
  ) {
    return _ggml_diag_mask_zero(
      ctx,
      a,
      n_past,
    );
  }

  late final _ggml_diag_mask_zeroPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ffi.Int)>>('ggml_diag_mask_zero');
  late final _ggml_diag_mask_zero = _ggml_diag_mask_zeroPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>, int)>();

  /// in-place, returns view(a)
  ffi.Pointer<ggml_tensor> ggml_diag_mask_zero_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int n_past,
  ) {
    return _ggml_diag_mask_zero_inplace(
      ctx,
      a,
      n_past,
    );
  }

  late final _ggml_diag_mask_zero_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int)>>('ggml_diag_mask_zero_inplace');
  late final _ggml_diag_mask_zero_inplace =
      _ggml_diag_mask_zero_inplacePtr.asFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>, int)>();

  ffi.Pointer<ggml_tensor> ggml_soft_max(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_soft_max(
      ctx,
      a,
    );
  }

  late final _ggml_soft_maxPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_soft_max');
  late final _ggml_soft_max = _ggml_soft_maxPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  /// in-place, returns view(a)
  ffi.Pointer<ggml_tensor> ggml_soft_max_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_soft_max_inplace(
      ctx,
      a,
    );
  }

  late final _ggml_soft_max_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_soft_max_inplace');
  late final _ggml_soft_max_inplace = _ggml_soft_max_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  /// fused soft_max(a*scale + mask*(ALiBi slope))
  /// mask is optional
  /// max_bias = 0.0f for no ALiBi
  ffi.Pointer<ggml_tensor> ggml_soft_max_ext(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> mask,
    double scale,
    double max_bias,
  ) {
    return _ggml_soft_max_ext(
      ctx,
      a,
      mask,
      scale,
      max_bias,
    );
  }

  late final _ggml_soft_max_extPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Float,
              ffi.Float)>>('ggml_soft_max_ext');
  late final _ggml_soft_max_ext = _ggml_soft_max_extPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          double,
          double)>();

  ffi.Pointer<ggml_tensor> ggml_soft_max_ext_back(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    double scale,
    double max_bias,
  ) {
    return _ggml_soft_max_ext_back(
      ctx,
      a,
      b,
      scale,
      max_bias,
    );
  }

  late final _ggml_soft_max_ext_backPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Float,
              ffi.Float)>>('ggml_soft_max_ext_back');
  late final _ggml_soft_max_ext_back = _ggml_soft_max_ext_backPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          double,
          double)>();

  /// in-place, returns view(a)
  ffi.Pointer<ggml_tensor> ggml_soft_max_ext_back_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    double scale,
    double max_bias,
  ) {
    return _ggml_soft_max_ext_back_inplace(
      ctx,
      a,
      b,
      scale,
      max_bias,
    );
  }

  late final _ggml_soft_max_ext_back_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Float,
              ffi.Float)>>('ggml_soft_max_ext_back_inplace');
  late final _ggml_soft_max_ext_back_inplace =
      _ggml_soft_max_ext_back_inplacePtr.asFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              double,
              double)>();

  /// rotary position embedding
  /// if (mode & 1) - skip n_past elements (NOT SUPPORTED)
  /// if (mode & GGML_ROPE_TYPE_NEOX) - GPT-NeoX style
  ///
  /// b is an int32 vector with size a->ne[2], it contains the positions
  ffi.Pointer<ggml_tensor> ggml_rope(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    int n_dims,
    int mode,
  ) {
    return _ggml_rope(
      ctx,
      a,
      b,
      n_dims,
      mode,
    );
  }

  late final _ggml_ropePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int,
              ffi.Int)>>('ggml_rope');
  late final _ggml_rope = _ggml_ropePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>, int, int)>();

  /// in-place, returns view(a)
  ffi.Pointer<ggml_tensor> ggml_rope_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    int n_dims,
    int mode,
  ) {
    return _ggml_rope_inplace(
      ctx,
      a,
      b,
      n_dims,
      mode,
    );
  }

  late final _ggml_rope_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int,
              ffi.Int)>>('ggml_rope_inplace');
  late final _ggml_rope_inplace = _ggml_rope_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>, int, int)>();

  /// custom RoPE
  /// c is freq factors (e.g. phi3-128k), (optional)
  ffi.Pointer<ggml_tensor> ggml_rope_ext(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    ffi.Pointer<ggml_tensor> c,
    int n_dims,
    int mode,
    int n_ctx_orig,
    double freq_base,
    double freq_scale,
    double ext_factor,
    double attn_factor,
    double beta_fast,
    double beta_slow,
  ) {
    return _ggml_rope_ext(
      ctx,
      a,
      b,
      c,
      n_dims,
      mode,
      n_ctx_orig,
      freq_base,
      freq_scale,
      ext_factor,
      attn_factor,
      beta_fast,
      beta_slow,
    );
  }

  late final _ggml_rope_extPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int,
              ffi.Int,
              ffi.Int,
              ffi.Float,
              ffi.Float,
              ffi.Float,
              ffi.Float,
              ffi.Float,
              ffi.Float)>>('ggml_rope_ext');
  late final _ggml_rope_ext = _ggml_rope_extPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          int,
          int,
          int,
          double,
          double,
          double,
          double,
          double,
          double)>();

  ffi.Pointer<ggml_tensor> ggml_rope_multi(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    ffi.Pointer<ggml_tensor> c,
    int n_dims,
    ffi.Pointer<ffi.Int> sections,
    int mode,
    int n_ctx_orig,
    double freq_base,
    double freq_scale,
    double ext_factor,
    double attn_factor,
    double beta_fast,
    double beta_slow,
  ) {
    return _ggml_rope_multi(
      ctx,
      a,
      b,
      c,
      n_dims,
      sections,
      mode,
      n_ctx_orig,
      freq_base,
      freq_scale,
      ext_factor,
      attn_factor,
      beta_fast,
      beta_slow,
    );
  }

  late final _ggml_rope_multiPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int,
              ffi.Pointer<ffi.Int>,
              ffi.Int,
              ffi.Int,
              ffi.Float,
              ffi.Float,
              ffi.Float,
              ffi.Float,
              ffi.Float,
              ffi.Float)>>('ggml_rope_multi');
  late final _ggml_rope_multi = _ggml_rope_multiPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          int,
          ffi.Pointer<ffi.Int>,
          int,
          int,
          double,
          double,
          double,
          double,
          double,
          double)>();

  /// in-place, returns view(a)
  ffi.Pointer<ggml_tensor> ggml_rope_ext_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    ffi.Pointer<ggml_tensor> c,
    int n_dims,
    int mode,
    int n_ctx_orig,
    double freq_base,
    double freq_scale,
    double ext_factor,
    double attn_factor,
    double beta_fast,
    double beta_slow,
  ) {
    return _ggml_rope_ext_inplace(
      ctx,
      a,
      b,
      c,
      n_dims,
      mode,
      n_ctx_orig,
      freq_base,
      freq_scale,
      ext_factor,
      attn_factor,
      beta_fast,
      beta_slow,
    );
  }

  late final _ggml_rope_ext_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int,
              ffi.Int,
              ffi.Int,
              ffi.Float,
              ffi.Float,
              ffi.Float,
              ffi.Float,
              ffi.Float,
              ffi.Float)>>('ggml_rope_ext_inplace');
  late final _ggml_rope_ext_inplace = _ggml_rope_ext_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          int,
          int,
          int,
          double,
          double,
          double,
          double,
          double,
          double)>();

  ffi.Pointer<ggml_tensor> ggml_rope_custom(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    int n_dims,
    int mode,
    int n_ctx_orig,
    double freq_base,
    double freq_scale,
    double ext_factor,
    double attn_factor,
    double beta_fast,
    double beta_slow,
  ) {
    return _ggml_rope_custom(
      ctx,
      a,
      b,
      n_dims,
      mode,
      n_ctx_orig,
      freq_base,
      freq_scale,
      ext_factor,
      attn_factor,
      beta_fast,
      beta_slow,
    );
  }

  late final _ggml_rope_customPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int,
              ffi.Int,
              ffi.Int,
              ffi.Float,
              ffi.Float,
              ffi.Float,
              ffi.Float,
              ffi.Float,
              ffi.Float)>>('ggml_rope_custom');
  late final _ggml_rope_custom = _ggml_rope_customPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          int,
          int,
          int,
          double,
          double,
          double,
          double,
          double,
          double)>();

  ffi.Pointer<ggml_tensor> ggml_rope_custom_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    int n_dims,
    int mode,
    int n_ctx_orig,
    double freq_base,
    double freq_scale,
    double ext_factor,
    double attn_factor,
    double beta_fast,
    double beta_slow,
  ) {
    return _ggml_rope_custom_inplace(
      ctx,
      a,
      b,
      n_dims,
      mode,
      n_ctx_orig,
      freq_base,
      freq_scale,
      ext_factor,
      attn_factor,
      beta_fast,
      beta_slow,
    );
  }

  late final _ggml_rope_custom_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int,
              ffi.Int,
              ffi.Int,
              ffi.Float,
              ffi.Float,
              ffi.Float,
              ffi.Float,
              ffi.Float,
              ffi.Float)>>('ggml_rope_custom_inplace');
  late final _ggml_rope_custom_inplace =
      _ggml_rope_custom_inplacePtr.asFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              int,
              int,
              int,
              double,
              double,
              double,
              double,
              double,
              double)>();

  /// compute correction dims for YaRN RoPE scaling
  void ggml_rope_yarn_corr_dims(
    int n_dims,
    int n_ctx_orig,
    double freq_base,
    double beta_fast,
    double beta_slow,
    ffi.Pointer<ffi.Float> dims,
  ) {
    return _ggml_rope_yarn_corr_dims(
      n_dims,
      n_ctx_orig,
      freq_base,
      beta_fast,
      beta_slow,
      dims,
    );
  }

  late final _ggml_rope_yarn_corr_dimsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Int, ffi.Int, ffi.Float, ffi.Float, ffi.Float,
              ffi.Pointer<ffi.Float>)>>('ggml_rope_yarn_corr_dims');
  late final _ggml_rope_yarn_corr_dims =
      _ggml_rope_yarn_corr_dimsPtr.asFunction<
          void Function(
              int, int, double, double, double, ffi.Pointer<ffi.Float>)>();

  /// rotary position embedding backward, i.e compute dx from dy
  /// a - dy
  ffi.Pointer<ggml_tensor> ggml_rope_ext_back(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    ffi.Pointer<ggml_tensor> c,
    int n_dims,
    int mode,
    int n_ctx_orig,
    double freq_base,
    double freq_scale,
    double ext_factor,
    double attn_factor,
    double beta_fast,
    double beta_slow,
  ) {
    return _ggml_rope_ext_back(
      ctx,
      a,
      b,
      c,
      n_dims,
      mode,
      n_ctx_orig,
      freq_base,
      freq_scale,
      ext_factor,
      attn_factor,
      beta_fast,
      beta_slow,
    );
  }

  late final _ggml_rope_ext_backPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int,
              ffi.Int,
              ffi.Int,
              ffi.Float,
              ffi.Float,
              ffi.Float,
              ffi.Float,
              ffi.Float,
              ffi.Float)>>('ggml_rope_ext_back');
  late final _ggml_rope_ext_back = _ggml_rope_ext_backPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          int,
          int,
          int,
          double,
          double,
          double,
          double,
          double,
          double)>();

  ffi.Pointer<ggml_tensor> ggml_rope_multi_back(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    ffi.Pointer<ggml_tensor> c,
    int n_dims,
    ffi.Pointer<ffi.Int> sections,
    int mode,
    int n_ctx_orig,
    double freq_base,
    double freq_scale,
    double ext_factor,
    double attn_factor,
    double beta_fast,
    double beta_slow,
  ) {
    return _ggml_rope_multi_back(
      ctx,
      a,
      b,
      c,
      n_dims,
      sections,
      mode,
      n_ctx_orig,
      freq_base,
      freq_scale,
      ext_factor,
      attn_factor,
      beta_fast,
      beta_slow,
    );
  }

  late final _ggml_rope_multi_backPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int,
              ffi.Pointer<ffi.Int>,
              ffi.Int,
              ffi.Int,
              ffi.Float,
              ffi.Float,
              ffi.Float,
              ffi.Float,
              ffi.Float,
              ffi.Float)>>('ggml_rope_multi_back');
  late final _ggml_rope_multi_back = _ggml_rope_multi_backPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          int,
          ffi.Pointer<ffi.Int>,
          int,
          int,
          double,
          double,
          double,
          double,
          double,
          double)>();

  /// clamp
  /// in-place, returns view(a)
  ffi.Pointer<ggml_tensor> ggml_clamp(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    double min,
    double max,
  ) {
    return _ggml_clamp(
      ctx,
      a,
      min,
      max,
    );
  }

  late final _ggml_clampPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ffi.Float, ffi.Float)>>('ggml_clamp');
  late final _ggml_clamp = _ggml_clampPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, double, double)>();

  /// im2col
  /// converts data into a format that effectively results in a convolution when combined with matrix multiplication
  ffi.Pointer<ggml_tensor> ggml_im2col(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    int s0,
    int s1,
    int p0,
    int p1,
    int d0,
    int d1,
    bool is_2D,
    int dst_type,
  ) {
    return _ggml_im2col(
      ctx,
      a,
      b,
      s0,
      s1,
      p0,
      p1,
      d0,
      d1,
      is_2D,
      dst_type,
    );
  }

  late final _ggml_im2colPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int,
              ffi.Int,
              ffi.Int,
              ffi.Int,
              ffi.Int,
              ffi.Int,
              ffi.Bool,
              ffi.Int32)>>('ggml_im2col');
  late final _ggml_im2col = _ggml_im2colPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          int,
          int,
          int,
          int,
          int,
          int,
          bool,
          int)>();

  ffi.Pointer<ggml_tensor> ggml_im2col_back(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    ffi.Pointer<ffi.Int64> ne,
    int s0,
    int s1,
    int p0,
    int p1,
    int d0,
    int d1,
    bool is_2D,
  ) {
    return _ggml_im2col_back(
      ctx,
      a,
      b,
      ne,
      s0,
      s1,
      p0,
      p1,
      d0,
      d1,
      is_2D,
    );
  }

  late final _ggml_im2col_backPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ffi.Int64>,
              ffi.Int,
              ffi.Int,
              ffi.Int,
              ffi.Int,
              ffi.Int,
              ffi.Int,
              ffi.Bool)>>('ggml_im2col_back');
  late final _ggml_im2col_back = _ggml_im2col_backPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ffi.Int64>,
          int,
          int,
          int,
          int,
          int,
          int,
          bool)>();

  ffi.Pointer<ggml_tensor> ggml_conv_1d(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    int s0,
    int p0,
    int d0,
  ) {
    return _ggml_conv_1d(
      ctx,
      a,
      b,
      s0,
      p0,
      d0,
    );
  }

  late final _ggml_conv_1dPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int,
              ffi.Int,
              ffi.Int)>>('ggml_conv_1d');
  late final _ggml_conv_1d = _ggml_conv_1dPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>, int, int, int)>();

  /// conv_1d with padding = half
  /// alias for ggml_conv_1d(a, b, s, a->ne[0]/2, d)
  ffi.Pointer<ggml_tensor> ggml_conv_1d_ph(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    int s,
    int d,
  ) {
    return _ggml_conv_1d_ph(
      ctx,
      a,
      b,
      s,
      d,
    );
  }

  late final _ggml_conv_1d_phPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int,
              ffi.Int)>>('ggml_conv_1d_ph');
  late final _ggml_conv_1d_ph = _ggml_conv_1d_phPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>, int, int)>();

  /// depthwise
  /// TODO: this is very likely wrong for some cases! - needs more testing
  ffi.Pointer<ggml_tensor> ggml_conv_1d_dw(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    int s0,
    int p0,
    int d0,
  ) {
    return _ggml_conv_1d_dw(
      ctx,
      a,
      b,
      s0,
      p0,
      d0,
    );
  }

  late final _ggml_conv_1d_dwPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int,
              ffi.Int,
              ffi.Int)>>('ggml_conv_1d_dw');
  late final _ggml_conv_1d_dw = _ggml_conv_1d_dwPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>, int, int, int)>();

  ffi.Pointer<ggml_tensor> ggml_conv_1d_dw_ph(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    int s0,
    int d0,
  ) {
    return _ggml_conv_1d_dw_ph(
      ctx,
      a,
      b,
      s0,
      d0,
    );
  }

  late final _ggml_conv_1d_dw_phPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int,
              ffi.Int)>>('ggml_conv_1d_dw_ph');
  late final _ggml_conv_1d_dw_ph = _ggml_conv_1d_dw_phPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>, int, int)>();

  ffi.Pointer<ggml_tensor> ggml_conv_transpose_1d(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    int s0,
    int p0,
    int d0,
  ) {
    return _ggml_conv_transpose_1d(
      ctx,
      a,
      b,
      s0,
      p0,
      d0,
    );
  }

  late final _ggml_conv_transpose_1dPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int,
              ffi.Int,
              ffi.Int)>>('ggml_conv_transpose_1d');
  late final _ggml_conv_transpose_1d = _ggml_conv_transpose_1dPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>, int, int, int)>();

  ffi.Pointer<ggml_tensor> ggml_conv_2d(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    int s0,
    int s1,
    int p0,
    int p1,
    int d0,
    int d1,
  ) {
    return _ggml_conv_2d(
      ctx,
      a,
      b,
      s0,
      s1,
      p0,
      p1,
      d0,
      d1,
    );
  }

  late final _ggml_conv_2dPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int,
              ffi.Int,
              ffi.Int,
              ffi.Int,
              ffi.Int,
              ffi.Int)>>('ggml_conv_2d');
  late final _ggml_conv_2d = _ggml_conv_2dPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          int,
          int,
          int,
          int,
          int,
          int)>();

  /// kernel size is a->ne[0] x a->ne[1]
  /// stride is equal to kernel size
  /// padding is zero
  /// example:
  /// a:     16   16    3  768
  /// b:   1024 1024    3    1
  /// res:   64   64  768    1
  /// used in sam
  ffi.Pointer<ggml_tensor> ggml_conv_2d_sk_p0(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
  ) {
    return _ggml_conv_2d_sk_p0(
      ctx,
      a,
      b,
    );
  }

  late final _ggml_conv_2d_sk_p0Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_conv_2d_sk_p0');
  late final _ggml_conv_2d_sk_p0 = _ggml_conv_2d_sk_p0Ptr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  /// kernel size is a->ne[0] x a->ne[1]
  /// stride is 1
  /// padding is half
  /// example:
  /// a:      3    3    256  256
  /// b:     64   64    256    1
  /// res:   64   64    256    1
  /// used in sam
  ffi.Pointer<ggml_tensor> ggml_conv_2d_s1_ph(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
  ) {
    return _ggml_conv_2d_s1_ph(
      ctx,
      a,
      b,
    );
  }

  late final _ggml_conv_2d_s1_phPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_conv_2d_s1_ph');
  late final _ggml_conv_2d_s1_ph = _ggml_conv_2d_s1_phPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  /// depthwise
  ffi.Pointer<ggml_tensor> ggml_conv_2d_dw(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    int s0,
    int s1,
    int p0,
    int p1,
    int d0,
    int d1,
  ) {
    return _ggml_conv_2d_dw(
      ctx,
      a,
      b,
      s0,
      s1,
      p0,
      p1,
      d0,
      d1,
    );
  }

  late final _ggml_conv_2d_dwPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int,
              ffi.Int,
              ffi.Int,
              ffi.Int,
              ffi.Int,
              ffi.Int)>>('ggml_conv_2d_dw');
  late final _ggml_conv_2d_dw = _ggml_conv_2d_dwPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          int,
          int,
          int,
          int,
          int,
          int)>();

  ffi.Pointer<ggml_tensor> ggml_conv_transpose_2d_p0(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    int stride,
  ) {
    return _ggml_conv_transpose_2d_p0(
      ctx,
      a,
      b,
      stride,
    );
  }

  late final _ggml_conv_transpose_2d_p0Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int)>>('ggml_conv_transpose_2d_p0');
  late final _ggml_conv_transpose_2d_p0 =
      _ggml_conv_transpose_2d_p0Ptr.asFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>, int)>();

  ffi.Pointer<ggml_tensor> ggml_pool_1d(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int op,
    int k0,
    int s0,
    int p0,
  ) {
    return _ggml_pool_1d(
      ctx,
      a,
      op,
      k0,
      s0,
      p0,
    );
  }

  late final _ggml_pool_1dPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int32,
              ffi.Int,
              ffi.Int,
              ffi.Int)>>('ggml_pool_1d');
  late final _ggml_pool_1d = _ggml_pool_1dPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, int, int, int, int)>();

  /// the result will have 2*p0 padding for the first dimension
  /// and 2*p1 padding for the second dimension
  ffi.Pointer<ggml_tensor> ggml_pool_2d(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int op,
    int k0,
    int k1,
    int s0,
    int s1,
    double p0,
    double p1,
  ) {
    return _ggml_pool_2d(
      ctx,
      a,
      op,
      k0,
      k1,
      s0,
      s1,
      p0,
      p1,
    );
  }

  late final _ggml_pool_2dPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int32,
              ffi.Int,
              ffi.Int,
              ffi.Int,
              ffi.Int,
              ffi.Float,
              ffi.Float)>>('ggml_pool_2d');
  late final _ggml_pool_2d = _ggml_pool_2dPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, int, int, int, int, int, double, double)>();

  ffi.Pointer<ggml_tensor> ggml_pool_2d_back(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> af,
    int op,
    int k0,
    int k1,
    int s0,
    int s1,
    double p0,
    double p1,
  ) {
    return _ggml_pool_2d_back(
      ctx,
      a,
      af,
      op,
      k0,
      k1,
      s0,
      s1,
      p0,
      p1,
    );
  }

  late final _ggml_pool_2d_backPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int32,
              ffi.Int,
              ffi.Int,
              ffi.Int,
              ffi.Int,
              ffi.Float,
              ffi.Float)>>('ggml_pool_2d_back');
  late final _ggml_pool_2d_back = _ggml_pool_2d_backPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          int,
          int,
          int,
          int,
          int,
          double,
          double)>();

  /// nearest interpolate
  /// multiplies ne0 and ne1 by scale factor
  /// used in stable-diffusion
  ffi.Pointer<ggml_tensor> ggml_upscale(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int scale_factor,
  ) {
    return _ggml_upscale(
      ctx,
      a,
      scale_factor,
    );
  }

  late final _ggml_upscalePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ffi.Int)>>('ggml_upscale');
  late final _ggml_upscale = _ggml_upscalePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>, int)>();

  /// nearest interpolate
  /// nearest interpolate to specified dimensions
  /// used in tortoise.cpp
  ffi.Pointer<ggml_tensor> ggml_upscale_ext(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int ne0,
    int ne1,
    int ne2,
    int ne3,
  ) {
    return _ggml_upscale_ext(
      ctx,
      a,
      ne0,
      ne1,
      ne2,
      ne3,
    );
  }

  late final _ggml_upscale_extPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int,
              ffi.Int,
              ffi.Int,
              ffi.Int)>>('ggml_upscale_ext');
  late final _ggml_upscale_ext = _ggml_upscale_extPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, int, int, int, int)>();

  /// pad each dimension with zeros: [x, ..., x] -> [x, ..., x, 0, ..., 0]
  ffi.Pointer<ggml_tensor> ggml_pad(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int p0,
    int p1,
    int p2,
    int p3,
  ) {
    return _ggml_pad(
      ctx,
      a,
      p0,
      p1,
      p2,
      p3,
    );
  }

  late final _ggml_padPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int,
              ffi.Int,
              ffi.Int,
              ffi.Int)>>('ggml_pad');
  late final _ggml_pad = _ggml_padPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, int, int, int, int)>();

  /// pad each dimension with reflection: [a, b, c, d] -> [b, a, b, c, d, c]
  ffi.Pointer<ggml_tensor> ggml_pad_reflect_1d(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int p0,
    int p1,
  ) {
    return _ggml_pad_reflect_1d(
      ctx,
      a,
      p0,
      p1,
    );
  }

  late final _ggml_pad_reflect_1dPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int,
              ffi.Int)>>('ggml_pad_reflect_1d');
  late final _ggml_pad_reflect_1d = _ggml_pad_reflect_1dPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>, int, int)>();

  /// Ref: https://github.com/CompVis/stable-diffusion/blob/main/ldm/modules/diffusionmodules/util.py#L151
  /// timesteps: [N,]
  /// return: [N, dim]
  ffi.Pointer<ggml_tensor> ggml_timestep_embedding(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> timesteps,
    int dim,
    int max_period,
  ) {
    return _ggml_timestep_embedding(
      ctx,
      timesteps,
      dim,
      max_period,
    );
  }

  late final _ggml_timestep_embeddingPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int,
              ffi.Int)>>('ggml_timestep_embedding');
  late final _ggml_timestep_embedding = _ggml_timestep_embeddingPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>, int, int)>();

  ffi.Pointer<ggml_tensor> ggml_argsort(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int order,
  ) {
    return _ggml_argsort(
      ctx,
      a,
      order,
    );
  }

  late final _ggml_argsortPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ffi.Int32)>>('ggml_argsort');
  late final _ggml_argsort = _ggml_argsortPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>, int)>();

  ffi.Pointer<ggml_tensor> ggml_arange(
    ffi.Pointer<ggml_context> ctx,
    double start,
    double stop,
    double step,
  ) {
    return _ggml_arange(
      ctx,
      start,
      stop,
      step,
    );
  }

  late final _ggml_arangePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Float, ffi.Float, ffi.Float)>>('ggml_arange');
  late final _ggml_arange = _ggml_arangePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, double, double, double)>();

  /// top k elements per row
  ffi.Pointer<ggml_tensor> ggml_top_k(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int k,
  ) {
    return _ggml_top_k(
      ctx,
      a,
      k,
    );
  }

  late final _ggml_top_kPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ffi.Int)>>('ggml_top_k');
  late final _ggml_top_k = _ggml_top_kPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>, int)>();

  /// q:    [n_embd, n_batch,     n_head,    1]
  /// k:    [n_embd, n_kv,        n_head_kv, 1]
  /// v:    [n_embd, n_kv,        n_head_kv, 1] !! not transposed !!
  /// mask: [n_kv,   n_batch_pad, 1,         1] !! n_batch_pad = GGML_PAD(n_batch, GGML_KQ_MASK_PAD) !!
  /// res:  [n_embd, n_head,      n_batch,   1] !! permuted !!
  ffi.Pointer<ggml_tensor> ggml_flash_attn_ext(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> q,
    ffi.Pointer<ggml_tensor> k,
    ffi.Pointer<ggml_tensor> v,
    ffi.Pointer<ggml_tensor> mask,
    double scale,
    double max_bias,
    double logit_softcap,
  ) {
    return _ggml_flash_attn_ext(
      ctx,
      q,
      k,
      v,
      mask,
      scale,
      max_bias,
      logit_softcap,
    );
  }

  late final _ggml_flash_attn_extPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Float,
              ffi.Float,
              ffi.Float)>>('ggml_flash_attn_ext');
  late final _ggml_flash_attn_ext = _ggml_flash_attn_extPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          double,
          double,
          double)>();

  void ggml_flash_attn_ext_set_prec(
    ffi.Pointer<ggml_tensor> a,
    int prec,
  ) {
    return _ggml_flash_attn_ext_set_prec(
      a,
      prec,
    );
  }

  late final _ggml_flash_attn_ext_set_precPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ggml_tensor>,
              ffi.Int32)>>('ggml_flash_attn_ext_set_prec');
  late final _ggml_flash_attn_ext_set_prec = _ggml_flash_attn_ext_set_precPtr
      .asFunction<void Function(ffi.Pointer<ggml_tensor>, int)>();

  int ggml_flash_attn_ext_get_prec(
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_flash_attn_ext_get_prec(
      a,
    );
  }

  late final _ggml_flash_attn_ext_get_precPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<ggml_tensor>)>>(
          'ggml_flash_attn_ext_get_prec');
  late final _ggml_flash_attn_ext_get_prec = _ggml_flash_attn_ext_get_precPtr
      .asFunction<int Function(ffi.Pointer<ggml_tensor>)>();

  /// TODO: needs to be adapted to ggml_flash_attn_ext
  ffi.Pointer<ggml_tensor> ggml_flash_attn_back(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> q,
    ffi.Pointer<ggml_tensor> k,
    ffi.Pointer<ggml_tensor> v,
    ffi.Pointer<ggml_tensor> d,
    bool masked,
  ) {
    return _ggml_flash_attn_back(
      ctx,
      q,
      k,
      v,
      d,
      masked,
    );
  }

  late final _ggml_flash_attn_backPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Bool)>>('ggml_flash_attn_back');
  late final _ggml_flash_attn_back = _ggml_flash_attn_backPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          bool)>();

  ffi.Pointer<ggml_tensor> ggml_ssm_conv(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> sx,
    ffi.Pointer<ggml_tensor> c,
  ) {
    return _ggml_ssm_conv(
      ctx,
      sx,
      c,
    );
  }

  late final _ggml_ssm_convPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_ssm_conv');
  late final _ggml_ssm_conv = _ggml_ssm_convPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_ssm_scan(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> s,
    ffi.Pointer<ggml_tensor> x,
    ffi.Pointer<ggml_tensor> dt,
    ffi.Pointer<ggml_tensor> A,
    ffi.Pointer<ggml_tensor> B,
    ffi.Pointer<ggml_tensor> C,
  ) {
    return _ggml_ssm_scan(
      ctx,
      s,
      x,
      dt,
      A,
      B,
      C,
    );
  }

  late final _ggml_ssm_scanPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_ssm_scan');
  late final _ggml_ssm_scan = _ggml_ssm_scanPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>)>();

  /// partition into non-overlapping windows with padding if needed
  /// example:
  /// a:   768   64   64    1
  /// w:    14
  /// res: 768   14   14    25
  /// used in sam
  ffi.Pointer<ggml_tensor> ggml_win_part(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int w,
  ) {
    return _ggml_win_part(
      ctx,
      a,
      w,
    );
  }

  late final _ggml_win_partPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ffi.Int)>>('ggml_win_part');
  late final _ggml_win_part = _ggml_win_partPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>, int)>();

  /// reverse of ggml_win_part
  /// used in sam
  ffi.Pointer<ggml_tensor> ggml_win_unpart(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int w0,
    int h0,
    int w,
  ) {
    return _ggml_win_unpart(
      ctx,
      a,
      w0,
      h0,
      w,
    );
  }

  late final _ggml_win_unpartPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int,
              ffi.Int,
              ffi.Int)>>('ggml_win_unpart');
  late final _ggml_win_unpart = _ggml_win_unpartPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, int, int, int)>();

  ffi.Pointer<ggml_tensor> ggml_unary(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int op,
  ) {
    return _ggml_unary(
      ctx,
      a,
      op,
    );
  }

  late final _ggml_unaryPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ffi.Int32)>>('ggml_unary');
  late final _ggml_unary = _ggml_unaryPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>, int)>();

  ffi.Pointer<ggml_tensor> ggml_unary_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int op,
  ) {
    return _ggml_unary_inplace(
      ctx,
      a,
      op,
    );
  }

  late final _ggml_unary_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ffi.Int32)>>('ggml_unary_inplace');
  late final _ggml_unary_inplace = _ggml_unary_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>, int)>();

  /// used in sam
  ffi.Pointer<ggml_tensor> ggml_get_rel_pos(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int qh,
    int kh,
  ) {
    return _ggml_get_rel_pos(
      ctx,
      a,
      qh,
      kh,
    );
  }

  late final _ggml_get_rel_posPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ffi.Int, ffi.Int)>>('ggml_get_rel_pos');
  late final _ggml_get_rel_pos = _ggml_get_rel_posPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>, int, int)>();

  /// used in sam
  ffi.Pointer<ggml_tensor> ggml_add_rel_pos(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> pw,
    ffi.Pointer<ggml_tensor> ph,
  ) {
    return _ggml_add_rel_pos(
      ctx,
      a,
      pw,
      ph,
    );
  }

  late final _ggml_add_rel_posPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_add_rel_pos');
  late final _ggml_add_rel_pos = _ggml_add_rel_posPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_add_rel_pos_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> pw,
    ffi.Pointer<ggml_tensor> ph,
  ) {
    return _ggml_add_rel_pos_inplace(
      ctx,
      a,
      pw,
      ph,
    );
  }

  late final _ggml_add_rel_pos_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_add_rel_pos_inplace');
  late final _ggml_add_rel_pos_inplace =
      _ggml_add_rel_pos_inplacePtr.asFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_rwkv_wkv6(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> k,
    ffi.Pointer<ggml_tensor> v,
    ffi.Pointer<ggml_tensor> r,
    ffi.Pointer<ggml_tensor> tf,
    ffi.Pointer<ggml_tensor> td,
    ffi.Pointer<ggml_tensor> state,
  ) {
    return _ggml_rwkv_wkv6(
      ctx,
      k,
      v,
      r,
      tf,
      td,
      state,
    );
  }

  late final _ggml_rwkv_wkv6Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_rwkv_wkv6');
  late final _ggml_rwkv_wkv6 = _ggml_rwkv_wkv6Ptr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_gated_linear_attn(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> k,
    ffi.Pointer<ggml_tensor> v,
    ffi.Pointer<ggml_tensor> q,
    ffi.Pointer<ggml_tensor> g,
    ffi.Pointer<ggml_tensor> state,
    double scale,
  ) {
    return _ggml_gated_linear_attn(
      ctx,
      k,
      v,
      q,
      g,
      state,
      scale,
    );
  }

  late final _ggml_gated_linear_attnPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Float)>>('ggml_gated_linear_attn');
  late final _ggml_gated_linear_attn = _ggml_gated_linear_attnPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          double)>();

  ffi.Pointer<ggml_tensor> ggml_map_unary_f32(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ggml_unary_op_f32_t fun,
  ) {
    return _ggml_map_unary_f32(
      ctx,
      a,
      fun,
    );
  }

  late final _ggml_map_unary_f32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ggml_unary_op_f32_t)>>('ggml_map_unary_f32');
  late final _ggml_map_unary_f32 = _ggml_map_unary_f32Ptr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ggml_unary_op_f32_t)>();

  ffi.Pointer<ggml_tensor> ggml_map_unary_inplace_f32(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ggml_unary_op_f32_t fun,
  ) {
    return _ggml_map_unary_inplace_f32(
      ctx,
      a,
      fun,
    );
  }

  late final _ggml_map_unary_inplace_f32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ggml_unary_op_f32_t)>>('ggml_map_unary_inplace_f32');
  late final _ggml_map_unary_inplace_f32 =
      _ggml_map_unary_inplace_f32Ptr.asFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ggml_unary_op_f32_t)>();

  ffi.Pointer<ggml_tensor> ggml_map_binary_f32(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    ggml_binary_op_f32_t fun,
  ) {
    return _ggml_map_binary_f32(
      ctx,
      a,
      b,
      fun,
    );
  }

  late final _ggml_map_binary_f32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ggml_binary_op_f32_t)>>('ggml_map_binary_f32');
  late final _ggml_map_binary_f32 = _ggml_map_binary_f32Ptr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          ggml_binary_op_f32_t)>();

  ffi.Pointer<ggml_tensor> ggml_map_binary_inplace_f32(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    ggml_binary_op_f32_t fun,
  ) {
    return _ggml_map_binary_inplace_f32(
      ctx,
      a,
      b,
      fun,
    );
  }

  late final _ggml_map_binary_inplace_f32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ggml_binary_op_f32_t)>>('ggml_map_binary_inplace_f32');
  late final _ggml_map_binary_inplace_f32 =
      _ggml_map_binary_inplace_f32Ptr.asFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ggml_binary_op_f32_t)>();

  ffi.Pointer<ggml_tensor> ggml_map_custom1_f32(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ggml_custom1_op_f32_t fun,
  ) {
    return _ggml_map_custom1_f32(
      ctx,
      a,
      fun,
    );
  }

  late final _ggml_map_custom1_f32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ggml_custom1_op_f32_t)>>('ggml_map_custom1_f32');
  late final _ggml_map_custom1_f32 = _ggml_map_custom1_f32Ptr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ggml_custom1_op_f32_t)>();

  ffi.Pointer<ggml_tensor> ggml_map_custom1_inplace_f32(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ggml_custom1_op_f32_t fun,
  ) {
    return _ggml_map_custom1_inplace_f32(
      ctx,
      a,
      fun,
    );
  }

  late final _ggml_map_custom1_inplace_f32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ggml_custom1_op_f32_t)>>('ggml_map_custom1_inplace_f32');
  late final _ggml_map_custom1_inplace_f32 =
      _ggml_map_custom1_inplace_f32Ptr.asFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ggml_custom1_op_f32_t)>();

  ffi.Pointer<ggml_tensor> ggml_map_custom2_f32(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    ggml_custom2_op_f32_t fun,
  ) {
    return _ggml_map_custom2_f32(
      ctx,
      a,
      b,
      fun,
    );
  }

  late final _ggml_map_custom2_f32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ggml_custom2_op_f32_t)>>('ggml_map_custom2_f32');
  late final _ggml_map_custom2_f32 = _ggml_map_custom2_f32Ptr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          ggml_custom2_op_f32_t)>();

  ffi.Pointer<ggml_tensor> ggml_map_custom2_inplace_f32(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    ggml_custom2_op_f32_t fun,
  ) {
    return _ggml_map_custom2_inplace_f32(
      ctx,
      a,
      b,
      fun,
    );
  }

  late final _ggml_map_custom2_inplace_f32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ggml_custom2_op_f32_t)>>('ggml_map_custom2_inplace_f32');
  late final _ggml_map_custom2_inplace_f32 =
      _ggml_map_custom2_inplace_f32Ptr.asFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ggml_custom2_op_f32_t)>();

  ffi.Pointer<ggml_tensor> ggml_map_custom3_f32(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    ffi.Pointer<ggml_tensor> c,
    ggml_custom3_op_f32_t fun,
  ) {
    return _ggml_map_custom3_f32(
      ctx,
      a,
      b,
      c,
      fun,
    );
  }

  late final _ggml_map_custom3_f32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ggml_custom3_op_f32_t)>>('ggml_map_custom3_f32');
  late final _ggml_map_custom3_f32 = _ggml_map_custom3_f32Ptr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          ggml_custom3_op_f32_t)>();

  ffi.Pointer<ggml_tensor> ggml_map_custom3_inplace_f32(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    ffi.Pointer<ggml_tensor> c,
    ggml_custom3_op_f32_t fun,
  ) {
    return _ggml_map_custom3_inplace_f32(
      ctx,
      a,
      b,
      c,
      fun,
    );
  }

  late final _ggml_map_custom3_inplace_f32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ggml_custom3_op_f32_t)>>('ggml_map_custom3_inplace_f32');
  late final _ggml_map_custom3_inplace_f32 =
      _ggml_map_custom3_inplace_f32Ptr.asFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ggml_custom3_op_f32_t)>();

  /// n_tasks == GGML_N_TASKS_MAX means to use max number of tasks
  ffi.Pointer<ggml_tensor> ggml_map_custom1(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ggml_custom1_op_t fun,
    int n_tasks,
    ffi.Pointer<ffi.Void> userdata,
  ) {
    return _ggml_map_custom1(
      ctx,
      a,
      fun,
      n_tasks,
      userdata,
    );
  }

  late final _ggml_map_custom1Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ggml_custom1_op_t,
              ffi.Int,
              ffi.Pointer<ffi.Void>)>>('ggml_map_custom1');
  late final _ggml_map_custom1 = _ggml_map_custom1Ptr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>,
          ggml_custom1_op_t,
          int,
          ffi.Pointer<ffi.Void>)>();

  ffi.Pointer<ggml_tensor> ggml_map_custom1_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ggml_custom1_op_t fun,
    int n_tasks,
    ffi.Pointer<ffi.Void> userdata,
  ) {
    return _ggml_map_custom1_inplace(
      ctx,
      a,
      fun,
      n_tasks,
      userdata,
    );
  }

  late final _ggml_map_custom1_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ggml_custom1_op_t,
              ffi.Int,
              ffi.Pointer<ffi.Void>)>>('ggml_map_custom1_inplace');
  late final _ggml_map_custom1_inplace =
      _ggml_map_custom1_inplacePtr.asFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ggml_custom1_op_t,
              int,
              ffi.Pointer<ffi.Void>)>();

  ffi.Pointer<ggml_tensor> ggml_map_custom2(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    ggml_custom2_op_t fun,
    int n_tasks,
    ffi.Pointer<ffi.Void> userdata,
  ) {
    return _ggml_map_custom2(
      ctx,
      a,
      b,
      fun,
      n_tasks,
      userdata,
    );
  }

  late final _ggml_map_custom2Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ggml_custom2_op_t,
              ffi.Int,
              ffi.Pointer<ffi.Void>)>>('ggml_map_custom2');
  late final _ggml_map_custom2 = _ggml_map_custom2Ptr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          ggml_custom2_op_t,
          int,
          ffi.Pointer<ffi.Void>)>();

  ffi.Pointer<ggml_tensor> ggml_map_custom2_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    ggml_custom2_op_t fun,
    int n_tasks,
    ffi.Pointer<ffi.Void> userdata,
  ) {
    return _ggml_map_custom2_inplace(
      ctx,
      a,
      b,
      fun,
      n_tasks,
      userdata,
    );
  }

  late final _ggml_map_custom2_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ggml_custom2_op_t,
              ffi.Int,
              ffi.Pointer<ffi.Void>)>>('ggml_map_custom2_inplace');
  late final _ggml_map_custom2_inplace =
      _ggml_map_custom2_inplacePtr.asFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ggml_custom2_op_t,
              int,
              ffi.Pointer<ffi.Void>)>();

  ffi.Pointer<ggml_tensor> ggml_map_custom3(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    ffi.Pointer<ggml_tensor> c,
    ggml_custom3_op_t fun,
    int n_tasks,
    ffi.Pointer<ffi.Void> userdata,
  ) {
    return _ggml_map_custom3(
      ctx,
      a,
      b,
      c,
      fun,
      n_tasks,
      userdata,
    );
  }

  late final _ggml_map_custom3Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ggml_custom3_op_t,
              ffi.Int,
              ffi.Pointer<ffi.Void>)>>('ggml_map_custom3');
  late final _ggml_map_custom3 = _ggml_map_custom3Ptr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          ggml_custom3_op_t,
          int,
          ffi.Pointer<ffi.Void>)>();

  ffi.Pointer<ggml_tensor> ggml_map_custom3_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    ffi.Pointer<ggml_tensor> c,
    ggml_custom3_op_t fun,
    int n_tasks,
    ffi.Pointer<ffi.Void> userdata,
  ) {
    return _ggml_map_custom3_inplace(
      ctx,
      a,
      b,
      c,
      fun,
      n_tasks,
      userdata,
    );
  }

  late final _ggml_map_custom3_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ggml_custom3_op_t,
              ffi.Int,
              ffi.Pointer<ffi.Void>)>>('ggml_map_custom3_inplace');
  late final _ggml_map_custom3_inplace =
      _ggml_map_custom3_inplacePtr.asFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ggml_custom3_op_t,
              int,
              ffi.Pointer<ffi.Void>)>();

  /// loss function
  ffi.Pointer<ggml_tensor> ggml_cross_entropy_loss(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
  ) {
    return _ggml_cross_entropy_loss(
      ctx,
      a,
      b,
    );
  }

  late final _ggml_cross_entropy_lossPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_cross_entropy_loss');
  late final _ggml_cross_entropy_loss = _ggml_cross_entropy_lossPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_cross_entropy_loss_back(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    ffi.Pointer<ggml_tensor> c,
  ) {
    return _ggml_cross_entropy_loss_back(
      ctx,
      a,
      b,
      c,
    );
  }

  late final _ggml_cross_entropy_loss_backPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_cross_entropy_loss_back');
  late final _ggml_cross_entropy_loss_back =
      _ggml_cross_entropy_loss_backPtr.asFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>();

  /// AdamW optimizer step
  /// Paper: https://arxiv.org/pdf/1711.05101v3.pdf
  /// PyTorch: https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html
  ffi.Pointer<ggml_tensor> ggml_opt_step_adamw(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> grad,
    ffi.Pointer<ggml_tensor> m,
    ffi.Pointer<ggml_tensor> v,
    ffi.Pointer<ggml_tensor> adamw_params,
  ) {
    return _ggml_opt_step_adamw(
      ctx,
      a,
      grad,
      m,
      v,
      adamw_params,
    );
  }

  late final _ggml_opt_step_adamwPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_opt_step_adamw');
  late final _ggml_opt_step_adamw = _ggml_opt_step_adamwPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>)>();

  /// automatic differentiation
  void ggml_build_forward_expand(
    ffi.Pointer<ggml_cgraph> cgraph,
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _ggml_build_forward_expand(
      cgraph,
      tensor,
    );
  }

  late final _ggml_build_forward_expandPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ggml_cgraph>,
              ffi.Pointer<ggml_tensor>)>>('ggml_build_forward_expand');
  late final _ggml_build_forward_expand =
      _ggml_build_forward_expandPtr.asFunction<
          void Function(ffi.Pointer<ggml_cgraph>, ffi.Pointer<ggml_tensor>)>();

  void ggml_build_backward_expand(
    ffi.Pointer<ggml_context> ctx_static,
    ffi.Pointer<ggml_context> ctx_compute,
    ffi.Pointer<ggml_cgraph> cgraph,
    bool accumulate,
  ) {
    return _ggml_build_backward_expand(
      ctx_static,
      ctx_compute,
      cgraph,
      accumulate,
    );
  }

  late final _ggml_build_backward_expandPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_cgraph>,
              ffi.Bool)>>('ggml_build_backward_expand');
  late final _ggml_build_backward_expand =
      _ggml_build_backward_expandPtr.asFunction<
          void Function(ffi.Pointer<ggml_context>, ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_cgraph>, bool)>();

  /// graph allocation in a context
  ffi.Pointer<ggml_cgraph> ggml_new_graph(
    ffi.Pointer<ggml_context> ctx,
  ) {
    return _ggml_new_graph(
      ctx,
    );
  }

  late final _ggml_new_graphPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_cgraph> Function(
              ffi.Pointer<ggml_context>)>>('ggml_new_graph');
  late final _ggml_new_graph = _ggml_new_graphPtr.asFunction<
      ffi.Pointer<ggml_cgraph> Function(ffi.Pointer<ggml_context>)>();

  ffi.Pointer<ggml_cgraph> ggml_new_graph_custom(
    ffi.Pointer<ggml_context> ctx,
    int size,
    bool grads,
  ) {
    return _ggml_new_graph_custom(
      ctx,
      size,
      grads,
    );
  }

  late final _ggml_new_graph_customPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_cgraph> Function(ffi.Pointer<ggml_context>, ffi.Size,
              ffi.Bool)>>('ggml_new_graph_custom');
  late final _ggml_new_graph_custom = _ggml_new_graph_customPtr.asFunction<
      ffi.Pointer<ggml_cgraph> Function(
          ffi.Pointer<ggml_context>, int, bool)>();

  ffi.Pointer<ggml_cgraph> ggml_graph_dup(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_cgraph> cgraph,
  ) {
    return _ggml_graph_dup(
      ctx,
      cgraph,
    );
  }

  late final _ggml_graph_dupPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_cgraph> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_cgraph>)>>('ggml_graph_dup');
  late final _ggml_graph_dup = _ggml_graph_dupPtr.asFunction<
      ffi.Pointer<ggml_cgraph> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_cgraph>)>();

  void ggml_graph_cpy(
    ffi.Pointer<ggml_cgraph> src,
    ffi.Pointer<ggml_cgraph> dst,
  ) {
    return _ggml_graph_cpy(
      src,
      dst,
    );
  }

  late final _ggml_graph_cpyPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ggml_cgraph>,
              ffi.Pointer<ggml_cgraph>)>>('ggml_graph_cpy');
  late final _ggml_graph_cpy = _ggml_graph_cpyPtr.asFunction<
      void Function(ffi.Pointer<ggml_cgraph>, ffi.Pointer<ggml_cgraph>)>();

  void ggml_graph_reset(
    ffi.Pointer<ggml_cgraph> cgraph,
  ) {
    return _ggml_graph_reset(
      cgraph,
    );
  }

  late final _ggml_graph_resetPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ggml_cgraph>)>>(
          'ggml_graph_reset');
  late final _ggml_graph_reset = _ggml_graph_resetPtr
      .asFunction<void Function(ffi.Pointer<ggml_cgraph>)>();

  void ggml_graph_clear(
    ffi.Pointer<ggml_cgraph> cgraph,
  ) {
    return _ggml_graph_clear(
      cgraph,
    );
  }

  late final _ggml_graph_clearPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ggml_cgraph>)>>(
          'ggml_graph_clear');
  late final _ggml_graph_clear = _ggml_graph_clearPtr
      .asFunction<void Function(ffi.Pointer<ggml_cgraph>)>();

  int ggml_graph_size(
    ffi.Pointer<ggml_cgraph> cgraph,
  ) {
    return _ggml_graph_size(
      cgraph,
    );
  }

  late final _ggml_graph_sizePtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<ggml_cgraph>)>>(
          'ggml_graph_size');
  late final _ggml_graph_size =
      _ggml_graph_sizePtr.asFunction<int Function(ffi.Pointer<ggml_cgraph>)>();

  ffi.Pointer<ggml_tensor> ggml_graph_node(
    ffi.Pointer<ggml_cgraph> cgraph,
    int i,
  ) {
    return _ggml_graph_node(
      cgraph,
      i,
    );
  }

  late final _ggml_graph_nodePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_cgraph>, ffi.Int)>>('ggml_graph_node');
  late final _ggml_graph_node = _ggml_graph_nodePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_cgraph>, int)>();

  ffi.Pointer<ffi.Pointer<ggml_tensor>> ggml_graph_nodes(
    ffi.Pointer<ggml_cgraph> cgraph,
  ) {
    return _ggml_graph_nodes(
      cgraph,
    );
  }

  late final _ggml_graph_nodesPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Pointer<ggml_tensor>> Function(
              ffi.Pointer<ggml_cgraph>)>>('ggml_graph_nodes');
  late final _ggml_graph_nodes = _ggml_graph_nodesPtr.asFunction<
      ffi.Pointer<ffi.Pointer<ggml_tensor>> Function(
          ffi.Pointer<ggml_cgraph>)>();

  int ggml_graph_n_nodes(
    ffi.Pointer<ggml_cgraph> cgraph,
  ) {
    return _ggml_graph_n_nodes(
      cgraph,
    );
  }

  late final _ggml_graph_n_nodesPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<ggml_cgraph>)>>(
          'ggml_graph_n_nodes');
  late final _ggml_graph_n_nodes = _ggml_graph_n_nodesPtr
      .asFunction<int Function(ffi.Pointer<ggml_cgraph>)>();

  void ggml_graph_add_node(
    ffi.Pointer<ggml_cgraph> cgraph,
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _ggml_graph_add_node(
      cgraph,
      tensor,
    );
  }

  late final _ggml_graph_add_nodePtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ggml_cgraph>,
              ffi.Pointer<ggml_tensor>)>>('ggml_graph_add_node');
  late final _ggml_graph_add_node = _ggml_graph_add_nodePtr.asFunction<
      void Function(ffi.Pointer<ggml_cgraph>, ffi.Pointer<ggml_tensor>)>();

  int ggml_graph_overhead() {
    return _ggml_graph_overhead();
  }

  late final _ggml_graph_overheadPtr =
      _lookup<ffi.NativeFunction<ffi.Size Function()>>('ggml_graph_overhead');
  late final _ggml_graph_overhead =
      _ggml_graph_overheadPtr.asFunction<int Function()>();

  int ggml_graph_overhead_custom(
    int size,
    bool grads,
  ) {
    return _ggml_graph_overhead_custom(
      size,
      grads,
    );
  }

  late final _ggml_graph_overhead_customPtr =
      _lookup<ffi.NativeFunction<ffi.Size Function(ffi.Size, ffi.Bool)>>(
          'ggml_graph_overhead_custom');
  late final _ggml_graph_overhead_custom =
      _ggml_graph_overhead_customPtr.asFunction<int Function(int, bool)>();

  ffi.Pointer<ggml_tensor> ggml_graph_get_tensor(
    ffi.Pointer<ggml_cgraph> cgraph,
    ffi.Pointer<ffi.Char> name,
  ) {
    return _ggml_graph_get_tensor(
      cgraph,
      name,
    );
  }

  late final _ggml_graph_get_tensorPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_cgraph>,
              ffi.Pointer<ffi.Char>)>>('ggml_graph_get_tensor');
  late final _ggml_graph_get_tensor = _ggml_graph_get_tensorPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_cgraph>, ffi.Pointer<ffi.Char>)>();

  ffi.Pointer<ggml_tensor> ggml_graph_get_grad(
    ffi.Pointer<ggml_cgraph> cgraph,
    ffi.Pointer<ggml_tensor> node,
  ) {
    return _ggml_graph_get_grad(
      cgraph,
      node,
    );
  }

  late final _ggml_graph_get_gradPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_cgraph>,
              ffi.Pointer<ggml_tensor>)>>('ggml_graph_get_grad');
  late final _ggml_graph_get_grad = _ggml_graph_get_gradPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_cgraph>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_graph_get_grad_acc(
    ffi.Pointer<ggml_cgraph> cgraph,
    ffi.Pointer<ggml_tensor> node,
  ) {
    return _ggml_graph_get_grad_acc(
      cgraph,
      node,
    );
  }

  late final _ggml_graph_get_grad_accPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_cgraph>,
              ffi.Pointer<ggml_tensor>)>>('ggml_graph_get_grad_acc');
  late final _ggml_graph_get_grad_acc = _ggml_graph_get_grad_accPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_cgraph>, ffi.Pointer<ggml_tensor>)>();

  void ggml_graph_export(
    ffi.Pointer<ggml_cgraph> cgraph,
    ffi.Pointer<ffi.Char> fname,
  ) {
    return _ggml_graph_export(
      cgraph,
      fname,
    );
  }

  late final _ggml_graph_exportPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ggml_cgraph>,
              ffi.Pointer<ffi.Char>)>>('ggml_graph_export');
  late final _ggml_graph_export = _ggml_graph_exportPtr.asFunction<
      void Function(ffi.Pointer<ggml_cgraph>, ffi.Pointer<ffi.Char>)>();

  ffi.Pointer<ggml_cgraph> ggml_graph_import(
    ffi.Pointer<ffi.Char> fname,
    ffi.Pointer<ffi.Pointer<ggml_context>> ctx_data,
    ffi.Pointer<ffi.Pointer<ggml_context>> ctx_eval,
  ) {
    return _ggml_graph_import(
      fname,
      ctx_data,
      ctx_eval,
    );
  }

  late final _ggml_graph_importPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_cgraph> Function(
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Pointer<ggml_context>>,
              ffi.Pointer<ffi.Pointer<ggml_context>>)>>('ggml_graph_import');
  late final _ggml_graph_import = _ggml_graph_importPtr.asFunction<
      ffi.Pointer<ggml_cgraph> Function(
          ffi.Pointer<ffi.Char>,
          ffi.Pointer<ffi.Pointer<ggml_context>>,
          ffi.Pointer<ffi.Pointer<ggml_context>>)>();

  /// print info and performance information for the graph
  void ggml_graph_print(
    ffi.Pointer<ggml_cgraph> cgraph,
  ) {
    return _ggml_graph_print(
      cgraph,
    );
  }

  late final _ggml_graph_printPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ggml_cgraph>)>>(
          'ggml_graph_print');
  late final _ggml_graph_print = _ggml_graph_printPtr
      .asFunction<void Function(ffi.Pointer<ggml_cgraph>)>();

  /// dump the graph into a file using the dot format
  void ggml_graph_dump_dot(
    ffi.Pointer<ggml_cgraph> gb,
    ffi.Pointer<ggml_cgraph> gf,
    ffi.Pointer<ffi.Char> filename,
  ) {
    return _ggml_graph_dump_dot(
      gb,
      gf,
      filename,
    );
  }

  late final _ggml_graph_dump_dotPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ggml_cgraph>, ffi.Pointer<ggml_cgraph>,
              ffi.Pointer<ffi.Char>)>>('ggml_graph_dump_dot');
  late final _ggml_graph_dump_dot = _ggml_graph_dump_dotPtr.asFunction<
      void Function(ffi.Pointer<ggml_cgraph>, ffi.Pointer<ggml_cgraph>,
          ffi.Pointer<ffi.Char>)>();

  /// Set callback for all future logging events.
  /// If this is not called, or NULL is supplied, everything is output on stderr.
  void ggml_log_set(
    ggml_log_callback log_callback,
    ffi.Pointer<ffi.Void> user_data,
  ) {
    return _ggml_log_set(
      log_callback,
      user_data,
    );
  }

  late final _ggml_log_setPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ggml_log_callback, ffi.Pointer<ffi.Void>)>>('ggml_log_set');
  late final _ggml_log_set = _ggml_log_setPtr
      .asFunction<void Function(ggml_log_callback, ffi.Pointer<ffi.Void>)>();

  ffi.Pointer<ggml_tensor> ggml_set_zero(
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _ggml_set_zero(
      tensor,
    );
  }

  late final _ggml_set_zeroPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_tensor>)>>('ggml_set_zero');
  late final _ggml_set_zero = _ggml_set_zeroPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_tensor>)>();

  /// - ggml_quantize_init can be called multiple times with the same type
  /// it will only initialize the quantization tables for the first call or after ggml_quantize_free
  /// automatically called by ggml_quantize_chunk for convenience
  ///
  /// - ggml_quantize_free will free any memory allocated by ggml_quantize_init
  /// call this at the end of the program to avoid memory leaks
  ///
  /// note: these are thread-safe
  void ggml_quantize_init(
    int type,
  ) {
    return _ggml_quantize_init(
      type,
    );
  }

  late final _ggml_quantize_initPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Int32)>>(
          'ggml_quantize_init');
  late final _ggml_quantize_init =
      _ggml_quantize_initPtr.asFunction<void Function(int)>();

  void ggml_quantize_free() {
    return _ggml_quantize_free();
  }

  late final _ggml_quantize_freePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('ggml_quantize_free');
  late final _ggml_quantize_free =
      _ggml_quantize_freePtr.asFunction<void Function()>();

  /// some quantization type cannot be used without an importance matrix
  bool ggml_quantize_requires_imatrix(
    int type,
  ) {
    return _ggml_quantize_requires_imatrix(
      type,
    );
  }

  late final _ggml_quantize_requires_imatrixPtr =
      _lookup<ffi.NativeFunction<ffi.Bool Function(ffi.Int32)>>(
          'ggml_quantize_requires_imatrix');
  late final _ggml_quantize_requires_imatrix =
      _ggml_quantize_requires_imatrixPtr.asFunction<bool Function(int)>();

  /// calls ggml_quantize_init internally (i.e. can allocate memory)
  int ggml_quantize_chunk(
    int type,
    ffi.Pointer<ffi.Float> src,
    ffi.Pointer<ffi.Void> dst,
    int start,
    int nrows,
    int n_per_row,
    ffi.Pointer<ffi.Float> imatrix,
  ) {
    return _ggml_quantize_chunk(
      type,
      src,
      dst,
      start,
      nrows,
      n_per_row,
      imatrix,
    );
  }

  late final _ggml_quantize_chunkPtr = _lookup<
      ffi.NativeFunction<
          ffi.Size Function(
              ffi.Int32,
              ffi.Pointer<ffi.Float>,
              ffi.Pointer<ffi.Void>,
              ffi.Int64,
              ffi.Int64,
              ffi.Int64,
              ffi.Pointer<ffi.Float>)>>('ggml_quantize_chunk');
  late final _ggml_quantize_chunk = _ggml_quantize_chunkPtr.asFunction<
      int Function(int, ffi.Pointer<ffi.Float>, ffi.Pointer<ffi.Void>, int, int,
          int, ffi.Pointer<ffi.Float>)>();

  ffi.Pointer<ggml_type_traits> ggml_get_type_traits(
    int type,
  ) {
    return _ggml_get_type_traits(
      type,
    );
  }

  late final _ggml_get_type_traitsPtr = _lookup<
          ffi
          .NativeFunction<ffi.Pointer<ggml_type_traits> Function(ffi.Int32)>>(
      'ggml_get_type_traits');
  late final _ggml_get_type_traits = _ggml_get_type_traitsPtr
      .asFunction<ffi.Pointer<ggml_type_traits> Function(int)>();

  ggml_threadpool_params ggml_threadpool_params_default(
    int n_threads,
  ) {
    return _ggml_threadpool_params_default(
      n_threads,
    );
  }

  late final _ggml_threadpool_params_defaultPtr =
      _lookup<ffi.NativeFunction<ggml_threadpool_params Function(ffi.Int)>>(
          'ggml_threadpool_params_default');
  late final _ggml_threadpool_params_default =
      _ggml_threadpool_params_defaultPtr
          .asFunction<ggml_threadpool_params Function(int)>();

  void ggml_threadpool_params_init(
    ffi.Pointer<ggml_threadpool_params> p,
    int n_threads,
  ) {
    return _ggml_threadpool_params_init(
      p,
      n_threads,
    );
  }

  late final _ggml_threadpool_params_initPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ggml_threadpool_params>,
              ffi.Int)>>('ggml_threadpool_params_init');
  late final _ggml_threadpool_params_init = _ggml_threadpool_params_initPtr
      .asFunction<void Function(ffi.Pointer<ggml_threadpool_params>, int)>();

  bool ggml_threadpool_params_match(
    ffi.Pointer<ggml_threadpool_params> p0,
    ffi.Pointer<ggml_threadpool_params> p1,
  ) {
    return _ggml_threadpool_params_match(
      p0,
      p1,
    );
  }

  late final _ggml_threadpool_params_matchPtr = _lookup<
          ffi.NativeFunction<
              ffi.Bool Function(ffi.Pointer<ggml_threadpool_params>,
                  ffi.Pointer<ggml_threadpool_params>)>>(
      'ggml_threadpool_params_match');
  late final _ggml_threadpool_params_match =
      _ggml_threadpool_params_matchPtr.asFunction<
          bool Function(ffi.Pointer<ggml_threadpool_params>,
              ffi.Pointer<ggml_threadpool_params>)>();

  /// Backend buffer type
  ffi.Pointer<ffi.Char> ggml_backend_buft_name(
    ggml_backend_buffer_type_t buft,
  ) {
    return _ggml_backend_buft_name(
      buft,
    );
  }

  late final _ggml_backend_buft_namePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(
              ggml_backend_buffer_type_t)>>('ggml_backend_buft_name');
  late final _ggml_backend_buft_name = _ggml_backend_buft_namePtr
      .asFunction<ffi.Pointer<ffi.Char> Function(ggml_backend_buffer_type_t)>();

  ggml_backend_buffer_t ggml_backend_buft_alloc_buffer(
    ggml_backend_buffer_type_t buft,
    int size,
  ) {
    return _ggml_backend_buft_alloc_buffer(
      buft,
      size,
    );
  }

  late final _ggml_backend_buft_alloc_bufferPtr = _lookup<
      ffi.NativeFunction<
          ggml_backend_buffer_t Function(ggml_backend_buffer_type_t,
              ffi.Size)>>('ggml_backend_buft_alloc_buffer');
  late final _ggml_backend_buft_alloc_buffer =
      _ggml_backend_buft_alloc_bufferPtr.asFunction<
          ggml_backend_buffer_t Function(ggml_backend_buffer_type_t, int)>();

  int ggml_backend_buft_get_alignment(
    ggml_backend_buffer_type_t buft,
  ) {
    return _ggml_backend_buft_get_alignment(
      buft,
    );
  }

  late final _ggml_backend_buft_get_alignmentPtr = _lookup<
          ffi.NativeFunction<ffi.Size Function(ggml_backend_buffer_type_t)>>(
      'ggml_backend_buft_get_alignment');
  late final _ggml_backend_buft_get_alignment =
      _ggml_backend_buft_get_alignmentPtr
          .asFunction<int Function(ggml_backend_buffer_type_t)>();

  int ggml_backend_buft_get_max_size(
    ggml_backend_buffer_type_t buft,
  ) {
    return _ggml_backend_buft_get_max_size(
      buft,
    );
  }

  late final _ggml_backend_buft_get_max_sizePtr = _lookup<
          ffi.NativeFunction<ffi.Size Function(ggml_backend_buffer_type_t)>>(
      'ggml_backend_buft_get_max_size');
  late final _ggml_backend_buft_get_max_size =
      _ggml_backend_buft_get_max_sizePtr
          .asFunction<int Function(ggml_backend_buffer_type_t)>();

  int ggml_backend_buft_get_alloc_size(
    ggml_backend_buffer_type_t buft,
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _ggml_backend_buft_get_alloc_size(
      buft,
      tensor,
    );
  }

  late final _ggml_backend_buft_get_alloc_sizePtr = _lookup<
      ffi.NativeFunction<
          ffi.Size Function(ggml_backend_buffer_type_t,
              ffi.Pointer<ggml_tensor>)>>('ggml_backend_buft_get_alloc_size');
  late final _ggml_backend_buft_get_alloc_size =
      _ggml_backend_buft_get_alloc_sizePtr.asFunction<
          int Function(ggml_backend_buffer_type_t, ffi.Pointer<ggml_tensor>)>();

  bool ggml_backend_buft_is_host(
    ggml_backend_buffer_type_t buft,
  ) {
    return _ggml_backend_buft_is_host(
      buft,
    );
  }

  late final _ggml_backend_buft_is_hostPtr = _lookup<
          ffi.NativeFunction<ffi.Bool Function(ggml_backend_buffer_type_t)>>(
      'ggml_backend_buft_is_host');
  late final _ggml_backend_buft_is_host = _ggml_backend_buft_is_hostPtr
      .asFunction<bool Function(ggml_backend_buffer_type_t)>();

  ggml_backend_dev_t ggml_backend_buft_get_device(
    ggml_backend_buffer_type_t buft,
  ) {
    return _ggml_backend_buft_get_device(
      buft,
    );
  }

  late final _ggml_backend_buft_get_devicePtr = _lookup<
      ffi.NativeFunction<
          ggml_backend_dev_t Function(
              ggml_backend_buffer_type_t)>>('ggml_backend_buft_get_device');
  late final _ggml_backend_buft_get_device = _ggml_backend_buft_get_devicePtr
      .asFunction<ggml_backend_dev_t Function(ggml_backend_buffer_type_t)>();

  ffi.Pointer<ffi.Char> ggml_backend_buffer_name(
    ggml_backend_buffer_t buffer,
  ) {
    return _ggml_backend_buffer_name(
      buffer,
    );
  }

  late final _ggml_backend_buffer_namePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(
              ggml_backend_buffer_t)>>('ggml_backend_buffer_name');
  late final _ggml_backend_buffer_name = _ggml_backend_buffer_namePtr
      .asFunction<ffi.Pointer<ffi.Char> Function(ggml_backend_buffer_t)>();

  void ggml_backend_buffer_free(
    ggml_backend_buffer_t buffer,
  ) {
    return _ggml_backend_buffer_free(
      buffer,
    );
  }

  late final _ggml_backend_buffer_freePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ggml_backend_buffer_t)>>(
          'ggml_backend_buffer_free');
  late final _ggml_backend_buffer_free = _ggml_backend_buffer_freePtr
      .asFunction<void Function(ggml_backend_buffer_t)>();

  ffi.Pointer<ffi.Void> ggml_backend_buffer_get_base(
    ggml_backend_buffer_t buffer,
  ) {
    return _ggml_backend_buffer_get_base(
      buffer,
    );
  }

  late final _ggml_backend_buffer_get_basePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(
              ggml_backend_buffer_t)>>('ggml_backend_buffer_get_base');
  late final _ggml_backend_buffer_get_base = _ggml_backend_buffer_get_basePtr
      .asFunction<ffi.Pointer<ffi.Void> Function(ggml_backend_buffer_t)>();

  int ggml_backend_buffer_get_size(
    ggml_backend_buffer_t buffer,
  ) {
    return _ggml_backend_buffer_get_size(
      buffer,
    );
  }

  late final _ggml_backend_buffer_get_sizePtr =
      _lookup<ffi.NativeFunction<ffi.Size Function(ggml_backend_buffer_t)>>(
          'ggml_backend_buffer_get_size');
  late final _ggml_backend_buffer_get_size = _ggml_backend_buffer_get_sizePtr
      .asFunction<int Function(ggml_backend_buffer_t)>();

  void ggml_backend_buffer_init_tensor(
    ggml_backend_buffer_t buffer,
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _ggml_backend_buffer_init_tensor(
      buffer,
      tensor,
    );
  }

  late final _ggml_backend_buffer_init_tensorPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ggml_backend_buffer_t,
              ffi.Pointer<ggml_tensor>)>>('ggml_backend_buffer_init_tensor');
  late final _ggml_backend_buffer_init_tensor =
      _ggml_backend_buffer_init_tensorPtr.asFunction<
          void Function(ggml_backend_buffer_t, ffi.Pointer<ggml_tensor>)>();

  int ggml_backend_buffer_get_alignment(
    ggml_backend_buffer_t buffer,
  ) {
    return _ggml_backend_buffer_get_alignment(
      buffer,
    );
  }

  late final _ggml_backend_buffer_get_alignmentPtr =
      _lookup<ffi.NativeFunction<ffi.Size Function(ggml_backend_buffer_t)>>(
          'ggml_backend_buffer_get_alignment');
  late final _ggml_backend_buffer_get_alignment =
      _ggml_backend_buffer_get_alignmentPtr
          .asFunction<int Function(ggml_backend_buffer_t)>();

  int ggml_backend_buffer_get_max_size(
    ggml_backend_buffer_t buffer,
  ) {
    return _ggml_backend_buffer_get_max_size(
      buffer,
    );
  }

  late final _ggml_backend_buffer_get_max_sizePtr =
      _lookup<ffi.NativeFunction<ffi.Size Function(ggml_backend_buffer_t)>>(
          'ggml_backend_buffer_get_max_size');
  late final _ggml_backend_buffer_get_max_size =
      _ggml_backend_buffer_get_max_sizePtr
          .asFunction<int Function(ggml_backend_buffer_t)>();

  int ggml_backend_buffer_get_alloc_size(
    ggml_backend_buffer_t buffer,
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _ggml_backend_buffer_get_alloc_size(
      buffer,
      tensor,
    );
  }

  late final _ggml_backend_buffer_get_alloc_sizePtr = _lookup<
      ffi.NativeFunction<
          ffi.Size Function(ggml_backend_buffer_t,
              ffi.Pointer<ggml_tensor>)>>('ggml_backend_buffer_get_alloc_size');
  late final _ggml_backend_buffer_get_alloc_size =
      _ggml_backend_buffer_get_alloc_sizePtr.asFunction<
          int Function(ggml_backend_buffer_t, ffi.Pointer<ggml_tensor>)>();

  void ggml_backend_buffer_clear(
    ggml_backend_buffer_t buffer,
    int value,
  ) {
    return _ggml_backend_buffer_clear(
      buffer,
      value,
    );
  }

  late final _ggml_backend_buffer_clearPtr = _lookup<
          ffi
          .NativeFunction<ffi.Void Function(ggml_backend_buffer_t, ffi.Uint8)>>(
      'ggml_backend_buffer_clear');
  late final _ggml_backend_buffer_clear = _ggml_backend_buffer_clearPtr
      .asFunction<void Function(ggml_backend_buffer_t, int)>();

  bool ggml_backend_buffer_is_host(
    ggml_backend_buffer_t buffer,
  ) {
    return _ggml_backend_buffer_is_host(
      buffer,
    );
  }

  late final _ggml_backend_buffer_is_hostPtr =
      _lookup<ffi.NativeFunction<ffi.Bool Function(ggml_backend_buffer_t)>>(
          'ggml_backend_buffer_is_host');
  late final _ggml_backend_buffer_is_host = _ggml_backend_buffer_is_hostPtr
      .asFunction<bool Function(ggml_backend_buffer_t)>();

  void ggml_backend_buffer_set_usage(
    ggml_backend_buffer_t buffer,
    int usage,
  ) {
    return _ggml_backend_buffer_set_usage(
      buffer,
      usage,
    );
  }

  late final _ggml_backend_buffer_set_usagePtr = _lookup<
          ffi
          .NativeFunction<ffi.Void Function(ggml_backend_buffer_t, ffi.Int32)>>(
      'ggml_backend_buffer_set_usage');
  late final _ggml_backend_buffer_set_usage = _ggml_backend_buffer_set_usagePtr
      .asFunction<void Function(ggml_backend_buffer_t, int)>();

  int ggml_backend_buffer_get_usage(
    ggml_backend_buffer_t buffer,
  ) {
    return _ggml_backend_buffer_get_usage(
      buffer,
    );
  }

  late final _ggml_backend_buffer_get_usagePtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ggml_backend_buffer_t)>>(
          'ggml_backend_buffer_get_usage');
  late final _ggml_backend_buffer_get_usage = _ggml_backend_buffer_get_usagePtr
      .asFunction<int Function(ggml_backend_buffer_t)>();

  ggml_backend_buffer_type_t ggml_backend_buffer_get_type(
    ggml_backend_buffer_t buffer,
  ) {
    return _ggml_backend_buffer_get_type(
      buffer,
    );
  }

  late final _ggml_backend_buffer_get_typePtr = _lookup<
      ffi.NativeFunction<
          ggml_backend_buffer_type_t Function(
              ggml_backend_buffer_t)>>('ggml_backend_buffer_get_type');
  late final _ggml_backend_buffer_get_type = _ggml_backend_buffer_get_typePtr
      .asFunction<ggml_backend_buffer_type_t Function(ggml_backend_buffer_t)>();

  void ggml_backend_buffer_reset(
    ggml_backend_buffer_t buffer,
  ) {
    return _ggml_backend_buffer_reset(
      buffer,
    );
  }

  late final _ggml_backend_buffer_resetPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ggml_backend_buffer_t)>>(
          'ggml_backend_buffer_reset');
  late final _ggml_backend_buffer_reset = _ggml_backend_buffer_resetPtr
      .asFunction<void Function(ggml_backend_buffer_t)>();

  /// tensor copy between different backends
  void ggml_backend_tensor_copy(
    ffi.Pointer<ggml_tensor> src,
    ffi.Pointer<ggml_tensor> dst,
  ) {
    return _ggml_backend_tensor_copy(
      src,
      dst,
    );
  }

  late final _ggml_backend_tensor_copyPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_backend_tensor_copy');
  late final _ggml_backend_tensor_copy =
      _ggml_backend_tensor_copyPtr.asFunction<
          void Function(ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  /// Backend (stream)
  ggml_guid_t ggml_backend_guid(
    ggml_backend_t backend,
  ) {
    return _ggml_backend_guid(
      backend,
    );
  }

  late final _ggml_backend_guidPtr =
      _lookup<ffi.NativeFunction<ggml_guid_t Function(ggml_backend_t)>>(
          'ggml_backend_guid');
  late final _ggml_backend_guid =
      _ggml_backend_guidPtr.asFunction<ggml_guid_t Function(ggml_backend_t)>();

  ffi.Pointer<ffi.Char> ggml_backend_name(
    ggml_backend_t backend,
  ) {
    return _ggml_backend_name(
      backend,
    );
  }

  late final _ggml_backend_namePtr = _lookup<
          ffi.NativeFunction<ffi.Pointer<ffi.Char> Function(ggml_backend_t)>>(
      'ggml_backend_name');
  late final _ggml_backend_name = _ggml_backend_namePtr
      .asFunction<ffi.Pointer<ffi.Char> Function(ggml_backend_t)>();

  void ggml_backend_free(
    ggml_backend_t backend,
  ) {
    return _ggml_backend_free(
      backend,
    );
  }

  late final _ggml_backend_freePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ggml_backend_t)>>(
          'ggml_backend_free');
  late final _ggml_backend_free =
      _ggml_backend_freePtr.asFunction<void Function(ggml_backend_t)>();

  ggml_backend_buffer_type_t ggml_backend_get_default_buffer_type(
    ggml_backend_t backend,
  ) {
    return _ggml_backend_get_default_buffer_type(
      backend,
    );
  }

  late final _ggml_backend_get_default_buffer_typePtr = _lookup<
          ffi
          .NativeFunction<ggml_backend_buffer_type_t Function(ggml_backend_t)>>(
      'ggml_backend_get_default_buffer_type');
  late final _ggml_backend_get_default_buffer_type =
      _ggml_backend_get_default_buffer_typePtr
          .asFunction<ggml_backend_buffer_type_t Function(ggml_backend_t)>();

  ggml_backend_buffer_t ggml_backend_alloc_buffer(
    ggml_backend_t backend,
    int size,
  ) {
    return _ggml_backend_alloc_buffer(
      backend,
      size,
    );
  }

  late final _ggml_backend_alloc_bufferPtr = _lookup<
      ffi.NativeFunction<
          ggml_backend_buffer_t Function(
              ggml_backend_t, ffi.Size)>>('ggml_backend_alloc_buffer');
  late final _ggml_backend_alloc_buffer = _ggml_backend_alloc_bufferPtr
      .asFunction<ggml_backend_buffer_t Function(ggml_backend_t, int)>();

  int ggml_backend_get_alignment(
    ggml_backend_t backend,
  ) {
    return _ggml_backend_get_alignment(
      backend,
    );
  }

  late final _ggml_backend_get_alignmentPtr =
      _lookup<ffi.NativeFunction<ffi.Size Function(ggml_backend_t)>>(
          'ggml_backend_get_alignment');
  late final _ggml_backend_get_alignment =
      _ggml_backend_get_alignmentPtr.asFunction<int Function(ggml_backend_t)>();

  int ggml_backend_get_max_size(
    ggml_backend_t backend,
  ) {
    return _ggml_backend_get_max_size(
      backend,
    );
  }

  late final _ggml_backend_get_max_sizePtr =
      _lookup<ffi.NativeFunction<ffi.Size Function(ggml_backend_t)>>(
          'ggml_backend_get_max_size');
  late final _ggml_backend_get_max_size =
      _ggml_backend_get_max_sizePtr.asFunction<int Function(ggml_backend_t)>();

  void ggml_backend_tensor_set_async(
    ggml_backend_t backend,
    ffi.Pointer<ggml_tensor> tensor,
    ffi.Pointer<ffi.Void> data,
    int offset,
    int size,
  ) {
    return _ggml_backend_tensor_set_async(
      backend,
      tensor,
      data,
      offset,
      size,
    );
  }

  late final _ggml_backend_tensor_set_asyncPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ggml_backend_t,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ffi.Void>,
              ffi.Size,
              ffi.Size)>>('ggml_backend_tensor_set_async');
  late final _ggml_backend_tensor_set_async =
      _ggml_backend_tensor_set_asyncPtr.asFunction<
          void Function(ggml_backend_t, ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ffi.Void>, int, int)>();

  void ggml_backend_tensor_get_async(
    ggml_backend_t backend,
    ffi.Pointer<ggml_tensor> tensor,
    ffi.Pointer<ffi.Void> data,
    int offset,
    int size,
  ) {
    return _ggml_backend_tensor_get_async(
      backend,
      tensor,
      data,
      offset,
      size,
    );
  }

  late final _ggml_backend_tensor_get_asyncPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ggml_backend_t,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ffi.Void>,
              ffi.Size,
              ffi.Size)>>('ggml_backend_tensor_get_async');
  late final _ggml_backend_tensor_get_async =
      _ggml_backend_tensor_get_asyncPtr.asFunction<
          void Function(ggml_backend_t, ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ffi.Void>, int, int)>();

  /// "offset" refers to the offset in tensor->data for setting/getting data
  void ggml_backend_tensor_set(
    ffi.Pointer<ggml_tensor> tensor,
    ffi.Pointer<ffi.Void> data,
    int offset,
    int size,
  ) {
    return _ggml_backend_tensor_set(
      tensor,
      data,
      offset,
      size,
    );
  }

  late final _ggml_backend_tensor_setPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ggml_tensor>, ffi.Pointer<ffi.Void>,
              ffi.Size, ffi.Size)>>('ggml_backend_tensor_set');
  late final _ggml_backend_tensor_set = _ggml_backend_tensor_setPtr.asFunction<
      void Function(
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ffi.Void>, int, int)>();

  void ggml_backend_tensor_get(
    ffi.Pointer<ggml_tensor> tensor,
    ffi.Pointer<ffi.Void> data,
    int offset,
    int size,
  ) {
    return _ggml_backend_tensor_get(
      tensor,
      data,
      offset,
      size,
    );
  }

  late final _ggml_backend_tensor_getPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ggml_tensor>, ffi.Pointer<ffi.Void>,
              ffi.Size, ffi.Size)>>('ggml_backend_tensor_get');
  late final _ggml_backend_tensor_get = _ggml_backend_tensor_getPtr.asFunction<
      void Function(
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ffi.Void>, int, int)>();

  void ggml_backend_tensor_memset(
    ffi.Pointer<ggml_tensor> tensor,
    int value,
    int offset,
    int size,
  ) {
    return _ggml_backend_tensor_memset(
      tensor,
      value,
      offset,
      size,
    );
  }

  late final _ggml_backend_tensor_memsetPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ggml_tensor>, ffi.Uint8, ffi.Size,
              ffi.Size)>>('ggml_backend_tensor_memset');
  late final _ggml_backend_tensor_memset = _ggml_backend_tensor_memsetPtr
      .asFunction<void Function(ffi.Pointer<ggml_tensor>, int, int, int)>();

  void ggml_backend_synchronize(
    ggml_backend_t backend,
  ) {
    return _ggml_backend_synchronize(
      backend,
    );
  }

  late final _ggml_backend_synchronizePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ggml_backend_t)>>(
          'ggml_backend_synchronize');
  late final _ggml_backend_synchronize =
      _ggml_backend_synchronizePtr.asFunction<void Function(ggml_backend_t)>();

  ggml_backend_graph_plan_t ggml_backend_graph_plan_create(
    ggml_backend_t backend,
    ffi.Pointer<ggml_cgraph> cgraph,
  ) {
    return _ggml_backend_graph_plan_create(
      backend,
      cgraph,
    );
  }

  late final _ggml_backend_graph_plan_createPtr = _lookup<
      ffi.NativeFunction<
          ggml_backend_graph_plan_t Function(ggml_backend_t,
              ffi.Pointer<ggml_cgraph>)>>('ggml_backend_graph_plan_create');
  late final _ggml_backend_graph_plan_create =
      _ggml_backend_graph_plan_createPtr.asFunction<
          ggml_backend_graph_plan_t Function(
              ggml_backend_t, ffi.Pointer<ggml_cgraph>)>();

  void ggml_backend_graph_plan_free(
    ggml_backend_t backend,
    ggml_backend_graph_plan_t plan,
  ) {
    return _ggml_backend_graph_plan_free(
      backend,
      plan,
    );
  }

  late final _ggml_backend_graph_plan_freePtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ggml_backend_t,
              ggml_backend_graph_plan_t)>>('ggml_backend_graph_plan_free');
  late final _ggml_backend_graph_plan_free = _ggml_backend_graph_plan_freePtr
      .asFunction<void Function(ggml_backend_t, ggml_backend_graph_plan_t)>();

  int ggml_backend_graph_plan_compute(
    ggml_backend_t backend,
    ggml_backend_graph_plan_t plan,
  ) {
    return _ggml_backend_graph_plan_compute(
      backend,
      plan,
    );
  }

  late final _ggml_backend_graph_plan_computePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ggml_backend_t,
              ggml_backend_graph_plan_t)>>('ggml_backend_graph_plan_compute');
  late final _ggml_backend_graph_plan_compute =
      _ggml_backend_graph_plan_computePtr.asFunction<
          int Function(ggml_backend_t, ggml_backend_graph_plan_t)>();

  int ggml_backend_graph_compute(
    ggml_backend_t backend,
    ffi.Pointer<ggml_cgraph> cgraph,
  ) {
    return _ggml_backend_graph_compute(
      backend,
      cgraph,
    );
  }

  late final _ggml_backend_graph_computePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ggml_backend_t,
              ffi.Pointer<ggml_cgraph>)>>('ggml_backend_graph_compute');
  late final _ggml_backend_graph_compute = _ggml_backend_graph_computePtr
      .asFunction<int Function(ggml_backend_t, ffi.Pointer<ggml_cgraph>)>();

  int ggml_backend_graph_compute_async(
    ggml_backend_t backend,
    ffi.Pointer<ggml_cgraph> cgraph,
  ) {
    return _ggml_backend_graph_compute_async(
      backend,
      cgraph,
    );
  }

  late final _ggml_backend_graph_compute_asyncPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ggml_backend_t,
              ffi.Pointer<ggml_cgraph>)>>('ggml_backend_graph_compute_async');
  late final _ggml_backend_graph_compute_async =
      _ggml_backend_graph_compute_asyncPtr
          .asFunction<int Function(ggml_backend_t, ffi.Pointer<ggml_cgraph>)>();

  /// NOTE: will be removed, use device version instead
  bool ggml_backend_supports_op(
    ggml_backend_t backend,
    ffi.Pointer<ggml_tensor> op,
  ) {
    return _ggml_backend_supports_op(
      backend,
      op,
    );
  }

  late final _ggml_backend_supports_opPtr = _lookup<
      ffi.NativeFunction<
          ffi.Bool Function(ggml_backend_t,
              ffi.Pointer<ggml_tensor>)>>('ggml_backend_supports_op');
  late final _ggml_backend_supports_op = _ggml_backend_supports_opPtr
      .asFunction<bool Function(ggml_backend_t, ffi.Pointer<ggml_tensor>)>();

  bool ggml_backend_supports_buft(
    ggml_backend_t backend,
    ggml_backend_buffer_type_t buft,
  ) {
    return _ggml_backend_supports_buft(
      backend,
      buft,
    );
  }

  late final _ggml_backend_supports_buftPtr = _lookup<
      ffi.NativeFunction<
          ffi.Bool Function(ggml_backend_t,
              ggml_backend_buffer_type_t)>>('ggml_backend_supports_buft');
  late final _ggml_backend_supports_buft = _ggml_backend_supports_buftPtr
      .asFunction<bool Function(ggml_backend_t, ggml_backend_buffer_type_t)>();

  bool ggml_backend_offload_op(
    ggml_backend_t backend,
    ffi.Pointer<ggml_tensor> op,
  ) {
    return _ggml_backend_offload_op(
      backend,
      op,
    );
  }

  late final _ggml_backend_offload_opPtr = _lookup<
      ffi.NativeFunction<
          ffi.Bool Function(ggml_backend_t,
              ffi.Pointer<ggml_tensor>)>>('ggml_backend_offload_op');
  late final _ggml_backend_offload_op = _ggml_backend_offload_opPtr
      .asFunction<bool Function(ggml_backend_t, ffi.Pointer<ggml_tensor>)>();

  /// asynchronous copy
  /// the copy is performed after all the currently queued operations in backend_src
  /// backend_dst will wait for the copy to complete before performing other operations
  /// automatic fallback to sync copy if async is not supported
  void ggml_backend_tensor_copy_async(
    ggml_backend_t backend_src,
    ggml_backend_t backend_dst,
    ffi.Pointer<ggml_tensor> src,
    ffi.Pointer<ggml_tensor> dst,
  ) {
    return _ggml_backend_tensor_copy_async(
      backend_src,
      backend_dst,
      src,
      dst,
    );
  }

  late final _ggml_backend_tensor_copy_asyncPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ggml_backend_t,
              ggml_backend_t,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_backend_tensor_copy_async');
  late final _ggml_backend_tensor_copy_async =
      _ggml_backend_tensor_copy_asyncPtr.asFunction<
          void Function(ggml_backend_t, ggml_backend_t,
              ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  ggml_backend_dev_t ggml_backend_get_device(
    ggml_backend_t backend,
  ) {
    return _ggml_backend_get_device(
      backend,
    );
  }

  late final _ggml_backend_get_devicePtr =
      _lookup<ffi.NativeFunction<ggml_backend_dev_t Function(ggml_backend_t)>>(
          'ggml_backend_get_device');
  late final _ggml_backend_get_device = _ggml_backend_get_devicePtr
      .asFunction<ggml_backend_dev_t Function(ggml_backend_t)>();

  /// Events
  ggml_backend_event_t ggml_backend_event_new(
    ggml_backend_dev_t device,
  ) {
    return _ggml_backend_event_new(
      device,
    );
  }

  late final _ggml_backend_event_newPtr = _lookup<
          ffi
          .NativeFunction<ggml_backend_event_t Function(ggml_backend_dev_t)>>(
      'ggml_backend_event_new');
  late final _ggml_backend_event_new = _ggml_backend_event_newPtr
      .asFunction<ggml_backend_event_t Function(ggml_backend_dev_t)>();

  void ggml_backend_event_free(
    ggml_backend_event_t event,
  ) {
    return _ggml_backend_event_free(
      event,
    );
  }

  late final _ggml_backend_event_freePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ggml_backend_event_t)>>(
          'ggml_backend_event_free');
  late final _ggml_backend_event_free = _ggml_backend_event_freePtr
      .asFunction<void Function(ggml_backend_event_t)>();

  void ggml_backend_event_record(
    ggml_backend_event_t event,
    ggml_backend_t backend,
  ) {
    return _ggml_backend_event_record(
      event,
      backend,
    );
  }

  late final _ggml_backend_event_recordPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ggml_backend_event_t,
              ggml_backend_t)>>('ggml_backend_event_record');
  late final _ggml_backend_event_record = _ggml_backend_event_recordPtr
      .asFunction<void Function(ggml_backend_event_t, ggml_backend_t)>();

  void ggml_backend_event_synchronize(
    ggml_backend_event_t event,
  ) {
    return _ggml_backend_event_synchronize(
      event,
    );
  }

  late final _ggml_backend_event_synchronizePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ggml_backend_event_t)>>(
          'ggml_backend_event_synchronize');
  late final _ggml_backend_event_synchronize =
      _ggml_backend_event_synchronizePtr
          .asFunction<void Function(ggml_backend_event_t)>();

  void ggml_backend_event_wait(
    ggml_backend_t backend,
    ggml_backend_event_t event,
  ) {
    return _ggml_backend_event_wait(
      backend,
      event,
    );
  }

  late final _ggml_backend_event_waitPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ggml_backend_t,
              ggml_backend_event_t)>>('ggml_backend_event_wait');
  late final _ggml_backend_event_wait = _ggml_backend_event_waitPtr
      .asFunction<void Function(ggml_backend_t, ggml_backend_event_t)>();

  ffi.Pointer<ffi.Char> ggml_backend_dev_name(
    ggml_backend_dev_t device,
  ) {
    return _ggml_backend_dev_name(
      device,
    );
  }

  late final _ggml_backend_dev_namePtr = _lookup<
          ffi
          .NativeFunction<ffi.Pointer<ffi.Char> Function(ggml_backend_dev_t)>>(
      'ggml_backend_dev_name');
  late final _ggml_backend_dev_name = _ggml_backend_dev_namePtr
      .asFunction<ffi.Pointer<ffi.Char> Function(ggml_backend_dev_t)>();

  ffi.Pointer<ffi.Char> ggml_backend_dev_description(
    ggml_backend_dev_t device,
  ) {
    return _ggml_backend_dev_description(
      device,
    );
  }

  late final _ggml_backend_dev_descriptionPtr = _lookup<
          ffi
          .NativeFunction<ffi.Pointer<ffi.Char> Function(ggml_backend_dev_t)>>(
      'ggml_backend_dev_description');
  late final _ggml_backend_dev_description = _ggml_backend_dev_descriptionPtr
      .asFunction<ffi.Pointer<ffi.Char> Function(ggml_backend_dev_t)>();

  void ggml_backend_dev_memory(
    ggml_backend_dev_t device,
    ffi.Pointer<ffi.Size> free,
    ffi.Pointer<ffi.Size> total,
  ) {
    return _ggml_backend_dev_memory(
      device,
      free,
      total,
    );
  }

  late final _ggml_backend_dev_memoryPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ggml_backend_dev_t, ffi.Pointer<ffi.Size>,
              ffi.Pointer<ffi.Size>)>>('ggml_backend_dev_memory');
  late final _ggml_backend_dev_memory = _ggml_backend_dev_memoryPtr.asFunction<
      void Function(
          ggml_backend_dev_t, ffi.Pointer<ffi.Size>, ffi.Pointer<ffi.Size>)>();

  int ggml_backend_dev_type1(
    ggml_backend_dev_t device,
  ) {
    return _ggml_backend_dev_type1(
      device,
    );
  }

  late final _ggml_backend_dev_type1Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ggml_backend_dev_t)>>(
          'ggml_backend_dev_type');
  late final _ggml_backend_dev_type1 =
      _ggml_backend_dev_type1Ptr.asFunction<int Function(ggml_backend_dev_t)>();

  void ggml_backend_dev_get_props(
    ggml_backend_dev_t device,
    ffi.Pointer<ggml_backend_dev_props> props,
  ) {
    return _ggml_backend_dev_get_props(
      device,
      props,
    );
  }

  late final _ggml_backend_dev_get_propsPtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(
                  ggml_backend_dev_t, ffi.Pointer<ggml_backend_dev_props>)>>(
      'ggml_backend_dev_get_props');
  late final _ggml_backend_dev_get_props =
      _ggml_backend_dev_get_propsPtr.asFunction<
          void Function(
              ggml_backend_dev_t, ffi.Pointer<ggml_backend_dev_props>)>();

  ggml_backend_reg_t ggml_backend_dev_backend_reg(
    ggml_backend_dev_t device,
  ) {
    return _ggml_backend_dev_backend_reg(
      device,
    );
  }

  late final _ggml_backend_dev_backend_regPtr = _lookup<
          ffi.NativeFunction<ggml_backend_reg_t Function(ggml_backend_dev_t)>>(
      'ggml_backend_dev_backend_reg');
  late final _ggml_backend_dev_backend_reg = _ggml_backend_dev_backend_regPtr
      .asFunction<ggml_backend_reg_t Function(ggml_backend_dev_t)>();

  ggml_backend_t ggml_backend_dev_init(
    ggml_backend_dev_t device,
    ffi.Pointer<ffi.Char> params,
  ) {
    return _ggml_backend_dev_init(
      device,
      params,
    );
  }

  late final _ggml_backend_dev_initPtr = _lookup<
      ffi.NativeFunction<
          ggml_backend_t Function(ggml_backend_dev_t,
              ffi.Pointer<ffi.Char>)>>('ggml_backend_dev_init');
  late final _ggml_backend_dev_init = _ggml_backend_dev_initPtr.asFunction<
      ggml_backend_t Function(ggml_backend_dev_t, ffi.Pointer<ffi.Char>)>();

  ggml_backend_buffer_type_t ggml_backend_dev_buffer_type(
    ggml_backend_dev_t device,
  ) {
    return _ggml_backend_dev_buffer_type(
      device,
    );
  }

  late final _ggml_backend_dev_buffer_typePtr = _lookup<
      ffi.NativeFunction<
          ggml_backend_buffer_type_t Function(
              ggml_backend_dev_t)>>('ggml_backend_dev_buffer_type');
  late final _ggml_backend_dev_buffer_type = _ggml_backend_dev_buffer_typePtr
      .asFunction<ggml_backend_buffer_type_t Function(ggml_backend_dev_t)>();

  ggml_backend_buffer_type_t ggml_backend_dev_host_buffer_type(
    ggml_backend_dev_t device,
  ) {
    return _ggml_backend_dev_host_buffer_type(
      device,
    );
  }

  late final _ggml_backend_dev_host_buffer_typePtr = _lookup<
      ffi.NativeFunction<
          ggml_backend_buffer_type_t Function(
              ggml_backend_dev_t)>>('ggml_backend_dev_host_buffer_type');
  late final _ggml_backend_dev_host_buffer_type =
      _ggml_backend_dev_host_buffer_typePtr.asFunction<
          ggml_backend_buffer_type_t Function(ggml_backend_dev_t)>();

  ggml_backend_buffer_t ggml_backend_dev_buffer_from_host_ptr(
    ggml_backend_dev_t device,
    ffi.Pointer<ffi.Void> ptr,
    int size,
    int max_tensor_size,
  ) {
    return _ggml_backend_dev_buffer_from_host_ptr(
      device,
      ptr,
      size,
      max_tensor_size,
    );
  }

  late final _ggml_backend_dev_buffer_from_host_ptrPtr = _lookup<
      ffi.NativeFunction<
          ggml_backend_buffer_t Function(
              ggml_backend_dev_t,
              ffi.Pointer<ffi.Void>,
              ffi.Size,
              ffi.Size)>>('ggml_backend_dev_buffer_from_host_ptr');
  late final _ggml_backend_dev_buffer_from_host_ptr =
      _ggml_backend_dev_buffer_from_host_ptrPtr.asFunction<
          ggml_backend_buffer_t Function(
              ggml_backend_dev_t, ffi.Pointer<ffi.Void>, int, int)>();

  bool ggml_backend_dev_supports_op(
    ggml_backend_dev_t device,
    ffi.Pointer<ggml_tensor> op,
  ) {
    return _ggml_backend_dev_supports_op(
      device,
      op,
    );
  }

  late final _ggml_backend_dev_supports_opPtr = _lookup<
      ffi.NativeFunction<
          ffi.Bool Function(ggml_backend_dev_t,
              ffi.Pointer<ggml_tensor>)>>('ggml_backend_dev_supports_op');
  late final _ggml_backend_dev_supports_op =
      _ggml_backend_dev_supports_opPtr.asFunction<
          bool Function(ggml_backend_dev_t, ffi.Pointer<ggml_tensor>)>();

  bool ggml_backend_dev_supports_buft(
    ggml_backend_dev_t device,
    ggml_backend_buffer_type_t buft,
  ) {
    return _ggml_backend_dev_supports_buft(
      device,
      buft,
    );
  }

  late final _ggml_backend_dev_supports_buftPtr = _lookup<
      ffi.NativeFunction<
          ffi.Bool Function(ggml_backend_dev_t,
              ggml_backend_buffer_type_t)>>('ggml_backend_dev_supports_buft');
  late final _ggml_backend_dev_supports_buft =
      _ggml_backend_dev_supports_buftPtr.asFunction<
          bool Function(ggml_backend_dev_t, ggml_backend_buffer_type_t)>();

  bool ggml_backend_dev_offload_op(
    ggml_backend_dev_t device,
    ffi.Pointer<ggml_tensor> op,
  ) {
    return _ggml_backend_dev_offload_op(
      device,
      op,
    );
  }

  late final _ggml_backend_dev_offload_opPtr = _lookup<
      ffi.NativeFunction<
          ffi.Bool Function(ggml_backend_dev_t,
              ffi.Pointer<ggml_tensor>)>>('ggml_backend_dev_offload_op');
  late final _ggml_backend_dev_offload_op =
      _ggml_backend_dev_offload_opPtr.asFunction<
          bool Function(ggml_backend_dev_t, ffi.Pointer<ggml_tensor>)>();

  /// Backend (reg)
  ffi.Pointer<ffi.Char> ggml_backend_reg_name(
    ggml_backend_reg_t reg,
  ) {
    return _ggml_backend_reg_name(
      reg,
    );
  }

  late final _ggml_backend_reg_namePtr = _lookup<
          ffi
          .NativeFunction<ffi.Pointer<ffi.Char> Function(ggml_backend_reg_t)>>(
      'ggml_backend_reg_name');
  late final _ggml_backend_reg_name = _ggml_backend_reg_namePtr
      .asFunction<ffi.Pointer<ffi.Char> Function(ggml_backend_reg_t)>();

  int ggml_backend_reg_dev_count(
    ggml_backend_reg_t reg,
  ) {
    return _ggml_backend_reg_dev_count(
      reg,
    );
  }

  late final _ggml_backend_reg_dev_countPtr =
      _lookup<ffi.NativeFunction<ffi.Size Function(ggml_backend_reg_t)>>(
          'ggml_backend_reg_dev_count');
  late final _ggml_backend_reg_dev_count = _ggml_backend_reg_dev_countPtr
      .asFunction<int Function(ggml_backend_reg_t)>();

  ggml_backend_dev_t ggml_backend_reg_dev_get(
    ggml_backend_reg_t reg,
    int index,
  ) {
    return _ggml_backend_reg_dev_get(
      reg,
      index,
    );
  }

  late final _ggml_backend_reg_dev_getPtr = _lookup<
      ffi.NativeFunction<
          ggml_backend_dev_t Function(
              ggml_backend_reg_t, ffi.Size)>>('ggml_backend_reg_dev_get');
  late final _ggml_backend_reg_dev_get = _ggml_backend_reg_dev_getPtr
      .asFunction<ggml_backend_dev_t Function(ggml_backend_reg_t, int)>();

  ffi.Pointer<ffi.Void> ggml_backend_reg_get_proc_address(
    ggml_backend_reg_t reg,
    ffi.Pointer<ffi.Char> name,
  ) {
    return _ggml_backend_reg_get_proc_address(
      reg,
      name,
    );
  }

  late final _ggml_backend_reg_get_proc_addressPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(ggml_backend_reg_t,
              ffi.Pointer<ffi.Char>)>>('ggml_backend_reg_get_proc_address');
  late final _ggml_backend_reg_get_proc_address =
      _ggml_backend_reg_get_proc_addressPtr.asFunction<
          ffi.Pointer<ffi.Void> Function(
              ggml_backend_reg_t, ffi.Pointer<ffi.Char>)>();

  /// Backend registry
  void ggml_backend_device_register(
    ggml_backend_dev_t device,
  ) {
    return _ggml_backend_device_register(
      device,
    );
  }

  late final _ggml_backend_device_registerPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ggml_backend_dev_t)>>(
          'ggml_backend_device_register');
  late final _ggml_backend_device_register = _ggml_backend_device_registerPtr
      .asFunction<void Function(ggml_backend_dev_t)>();

  /// Backend (reg) enumeration
  int ggml_backend_reg_count() {
    return _ggml_backend_reg_count();
  }

  late final _ggml_backend_reg_countPtr =
      _lookup<ffi.NativeFunction<ffi.Size Function()>>(
          'ggml_backend_reg_count');
  late final _ggml_backend_reg_count =
      _ggml_backend_reg_countPtr.asFunction<int Function()>();

  ggml_backend_reg_t ggml_backend_reg_get(
    int index,
  ) {
    return _ggml_backend_reg_get(
      index,
    );
  }

  late final _ggml_backend_reg_getPtr =
      _lookup<ffi.NativeFunction<ggml_backend_reg_t Function(ffi.Size)>>(
          'ggml_backend_reg_get');
  late final _ggml_backend_reg_get =
      _ggml_backend_reg_getPtr.asFunction<ggml_backend_reg_t Function(int)>();

  ggml_backend_reg_t ggml_backend_reg_by_name(
    ffi.Pointer<ffi.Char> name,
  ) {
    return _ggml_backend_reg_by_name(
      name,
    );
  }

  late final _ggml_backend_reg_by_namePtr = _lookup<
          ffi
          .NativeFunction<ggml_backend_reg_t Function(ffi.Pointer<ffi.Char>)>>(
      'ggml_backend_reg_by_name');
  late final _ggml_backend_reg_by_name = _ggml_backend_reg_by_namePtr
      .asFunction<ggml_backend_reg_t Function(ffi.Pointer<ffi.Char>)>();

  /// Device enumeration
  int ggml_backend_dev_count() {
    return _ggml_backend_dev_count();
  }

  late final _ggml_backend_dev_countPtr =
      _lookup<ffi.NativeFunction<ffi.Size Function()>>(
          'ggml_backend_dev_count');
  late final _ggml_backend_dev_count =
      _ggml_backend_dev_countPtr.asFunction<int Function()>();

  ggml_backend_dev_t ggml_backend_dev_get(
    int index,
  ) {
    return _ggml_backend_dev_get(
      index,
    );
  }

  late final _ggml_backend_dev_getPtr =
      _lookup<ffi.NativeFunction<ggml_backend_dev_t Function(ffi.Size)>>(
          'ggml_backend_dev_get');
  late final _ggml_backend_dev_get =
      _ggml_backend_dev_getPtr.asFunction<ggml_backend_dev_t Function(int)>();

  ggml_backend_dev_t ggml_backend_dev_by_name(
    ffi.Pointer<ffi.Char> name,
  ) {
    return _ggml_backend_dev_by_name(
      name,
    );
  }

  late final _ggml_backend_dev_by_namePtr = _lookup<
          ffi
          .NativeFunction<ggml_backend_dev_t Function(ffi.Pointer<ffi.Char>)>>(
      'ggml_backend_dev_by_name');
  late final _ggml_backend_dev_by_name = _ggml_backend_dev_by_namePtr
      .asFunction<ggml_backend_dev_t Function(ffi.Pointer<ffi.Char>)>();

  ggml_backend_dev_t ggml_backend_dev_by_type(
    int type,
  ) {
    return _ggml_backend_dev_by_type(
      type,
    );
  }

  late final _ggml_backend_dev_by_typePtr =
      _lookup<ffi.NativeFunction<ggml_backend_dev_t Function(ffi.Int32)>>(
          'ggml_backend_dev_by_type');
  late final _ggml_backend_dev_by_type = _ggml_backend_dev_by_typePtr
      .asFunction<ggml_backend_dev_t Function(int)>();

  /// Direct backend (stream) initialization
  /// = ggml_backend_dev_init(ggml_backend_dev_by_name(name), params)
  ggml_backend_t ggml_backend_init_by_name(
    ffi.Pointer<ffi.Char> name,
    ffi.Pointer<ffi.Char> params,
  ) {
    return _ggml_backend_init_by_name(
      name,
      params,
    );
  }

  late final _ggml_backend_init_by_namePtr = _lookup<
      ffi.NativeFunction<
          ggml_backend_t Function(ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>)>>('ggml_backend_init_by_name');
  late final _ggml_backend_init_by_name =
      _ggml_backend_init_by_namePtr.asFunction<
          ggml_backend_t Function(
              ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>)>();

  /// = ggml_backend_dev_init(ggml_backend_dev_by_type(type), params)
  ggml_backend_t ggml_backend_init_by_type(
    int type,
    ffi.Pointer<ffi.Char> params,
  ) {
    return _ggml_backend_init_by_type(
      type,
      params,
    );
  }

  late final _ggml_backend_init_by_typePtr = _lookup<
      ffi.NativeFunction<
          ggml_backend_t Function(
              ffi.Int32, ffi.Pointer<ffi.Char>)>>('ggml_backend_init_by_type');
  late final _ggml_backend_init_by_type = _ggml_backend_init_by_typePtr
      .asFunction<ggml_backend_t Function(int, ffi.Pointer<ffi.Char>)>();

  /// = ggml_backend_dev_init(ggml_backend_dev_by_type(GPU) OR ggml_backend_dev_by_type(CPU), NULL)
  ggml_backend_t ggml_backend_init_best() {
    return _ggml_backend_init_best();
  }

  late final _ggml_backend_init_bestPtr =
      _lookup<ffi.NativeFunction<ggml_backend_t Function()>>(
          'ggml_backend_init_best');
  late final _ggml_backend_init_best =
      _ggml_backend_init_bestPtr.asFunction<ggml_backend_t Function()>();

  /// Load a backend from a dynamic library and register it
  ggml_backend_reg_t ggml_backend_load(
    ffi.Pointer<ffi.Char> path,
  ) {
    return _ggml_backend_load(
      path,
    );
  }

  late final _ggml_backend_loadPtr = _lookup<
          ffi
          .NativeFunction<ggml_backend_reg_t Function(ffi.Pointer<ffi.Char>)>>(
      'ggml_backend_load');
  late final _ggml_backend_load = _ggml_backend_loadPtr
      .asFunction<ggml_backend_reg_t Function(ffi.Pointer<ffi.Char>)>();

  /// Unload a backend if loaded dynamically and unregister it
  void ggml_backend_unload(
    ggml_backend_reg_t reg,
  ) {
    return _ggml_backend_unload(
      reg,
    );
  }

  late final _ggml_backend_unloadPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ggml_backend_reg_t)>>(
          'ggml_backend_unload');
  late final _ggml_backend_unload =
      _ggml_backend_unloadPtr.asFunction<void Function(ggml_backend_reg_t)>();

  /// Load all known backends from dynamic libraries
  void ggml_backend_load_all() {
    return _ggml_backend_load_all();
  }

  late final _ggml_backend_load_allPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('ggml_backend_load_all');
  late final _ggml_backend_load_all =
      _ggml_backend_load_allPtr.asFunction<void Function()>();

  void ggml_backend_load_all_from_path(
    ffi.Pointer<ffi.Char> dir_path,
  ) {
    return _ggml_backend_load_all_from_path(
      dir_path,
    );
  }

  late final _ggml_backend_load_all_from_pathPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Char>)>>(
          'ggml_backend_load_all_from_path');
  late final _ggml_backend_load_all_from_path =
      _ggml_backend_load_all_from_pathPtr
          .asFunction<void Function(ffi.Pointer<ffi.Char>)>();

  /// Initialize a backend scheduler, backends with low index are given priority over backends with high index
  ggml_backend_sched_t ggml_backend_sched_new(
    ffi.Pointer<ggml_backend_t> backends,
    ffi.Pointer<ggml_backend_buffer_type_t> bufts,
    int n_backends,
    int graph_size,
    bool parallel,
  ) {
    return _ggml_backend_sched_new(
      backends,
      bufts,
      n_backends,
      graph_size,
      parallel,
    );
  }

  late final _ggml_backend_sched_newPtr = _lookup<
      ffi.NativeFunction<
          ggml_backend_sched_t Function(
              ffi.Pointer<ggml_backend_t>,
              ffi.Pointer<ggml_backend_buffer_type_t>,
              ffi.Int,
              ffi.Size,
              ffi.Bool)>>('ggml_backend_sched_new');
  late final _ggml_backend_sched_new = _ggml_backend_sched_newPtr.asFunction<
      ggml_backend_sched_t Function(ffi.Pointer<ggml_backend_t>,
          ffi.Pointer<ggml_backend_buffer_type_t>, int, int, bool)>();

  void ggml_backend_sched_free(
    ggml_backend_sched_t sched,
  ) {
    return _ggml_backend_sched_free(
      sched,
    );
  }

  late final _ggml_backend_sched_freePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ggml_backend_sched_t)>>(
          'ggml_backend_sched_free');
  late final _ggml_backend_sched_free = _ggml_backend_sched_freePtr
      .asFunction<void Function(ggml_backend_sched_t)>();

  /// Initialize backend buffers from a measure graph
  bool ggml_backend_sched_reserve(
    ggml_backend_sched_t sched,
    ffi.Pointer<ggml_cgraph> measure_graph,
  ) {
    return _ggml_backend_sched_reserve(
      sched,
      measure_graph,
    );
  }

  late final _ggml_backend_sched_reservePtr = _lookup<
      ffi.NativeFunction<
          ffi.Bool Function(ggml_backend_sched_t,
              ffi.Pointer<ggml_cgraph>)>>('ggml_backend_sched_reserve');
  late final _ggml_backend_sched_reserve =
      _ggml_backend_sched_reservePtr.asFunction<
          bool Function(ggml_backend_sched_t, ffi.Pointer<ggml_cgraph>)>();

  int ggml_backend_sched_get_n_backends(
    ggml_backend_sched_t sched,
  ) {
    return _ggml_backend_sched_get_n_backends(
      sched,
    );
  }

  late final _ggml_backend_sched_get_n_backendsPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ggml_backend_sched_t)>>(
          'ggml_backend_sched_get_n_backends');
  late final _ggml_backend_sched_get_n_backends =
      _ggml_backend_sched_get_n_backendsPtr
          .asFunction<int Function(ggml_backend_sched_t)>();

  ggml_backend_t ggml_backend_sched_get_backend(
    ggml_backend_sched_t sched,
    int i,
  ) {
    return _ggml_backend_sched_get_backend(
      sched,
      i,
    );
  }

  late final _ggml_backend_sched_get_backendPtr = _lookup<
      ffi.NativeFunction<
          ggml_backend_t Function(ggml_backend_sched_t,
              ffi.Int)>>('ggml_backend_sched_get_backend');
  late final _ggml_backend_sched_get_backend =
      _ggml_backend_sched_get_backendPtr
          .asFunction<ggml_backend_t Function(ggml_backend_sched_t, int)>();

  /// Get the number of splits of the last graph
  int ggml_backend_sched_get_n_splits(
    ggml_backend_sched_t sched,
  ) {
    return _ggml_backend_sched_get_n_splits(
      sched,
    );
  }

  late final _ggml_backend_sched_get_n_splitsPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ggml_backend_sched_t)>>(
          'ggml_backend_sched_get_n_splits');
  late final _ggml_backend_sched_get_n_splits =
      _ggml_backend_sched_get_n_splitsPtr
          .asFunction<int Function(ggml_backend_sched_t)>();

  int ggml_backend_sched_get_n_copies(
    ggml_backend_sched_t sched,
  ) {
    return _ggml_backend_sched_get_n_copies(
      sched,
    );
  }

  late final _ggml_backend_sched_get_n_copiesPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ggml_backend_sched_t)>>(
          'ggml_backend_sched_get_n_copies');
  late final _ggml_backend_sched_get_n_copies =
      _ggml_backend_sched_get_n_copiesPtr
          .asFunction<int Function(ggml_backend_sched_t)>();

  int ggml_backend_sched_get_buffer_size(
    ggml_backend_sched_t sched,
    ggml_backend_t backend,
  ) {
    return _ggml_backend_sched_get_buffer_size(
      sched,
      backend,
    );
  }

  late final _ggml_backend_sched_get_buffer_sizePtr = _lookup<
      ffi.NativeFunction<
          ffi.Size Function(ggml_backend_sched_t,
              ggml_backend_t)>>('ggml_backend_sched_get_buffer_size');
  late final _ggml_backend_sched_get_buffer_size =
      _ggml_backend_sched_get_buffer_sizePtr
          .asFunction<int Function(ggml_backend_sched_t, ggml_backend_t)>();

  void ggml_backend_sched_set_tensor_backend(
    ggml_backend_sched_t sched,
    ffi.Pointer<ggml_tensor> node,
    ggml_backend_t backend,
  ) {
    return _ggml_backend_sched_set_tensor_backend(
      sched,
      node,
      backend,
    );
  }

  late final _ggml_backend_sched_set_tensor_backendPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ggml_backend_sched_t, ffi.Pointer<ggml_tensor>,
              ggml_backend_t)>>('ggml_backend_sched_set_tensor_backend');
  late final _ggml_backend_sched_set_tensor_backend =
      _ggml_backend_sched_set_tensor_backendPtr.asFunction<
          void Function(ggml_backend_sched_t, ffi.Pointer<ggml_tensor>,
              ggml_backend_t)>();

  ggml_backend_t ggml_backend_sched_get_tensor_backend(
    ggml_backend_sched_t sched,
    ffi.Pointer<ggml_tensor> node,
  ) {
    return _ggml_backend_sched_get_tensor_backend(
      sched,
      node,
    );
  }

  late final _ggml_backend_sched_get_tensor_backendPtr = _lookup<
          ffi.NativeFunction<
              ggml_backend_t Function(
                  ggml_backend_sched_t, ffi.Pointer<ggml_tensor>)>>(
      'ggml_backend_sched_get_tensor_backend');
  late final _ggml_backend_sched_get_tensor_backend =
      _ggml_backend_sched_get_tensor_backendPtr.asFunction<
          ggml_backend_t Function(
              ggml_backend_sched_t, ffi.Pointer<ggml_tensor>)>();

  /// Allocate and compute graph on the backend scheduler
  bool ggml_backend_sched_alloc_graph(
    ggml_backend_sched_t sched,
    ffi.Pointer<ggml_cgraph> graph,
  ) {
    return _ggml_backend_sched_alloc_graph(
      sched,
      graph,
    );
  }

  late final _ggml_backend_sched_alloc_graphPtr = _lookup<
      ffi.NativeFunction<
          ffi.Bool Function(ggml_backend_sched_t,
              ffi.Pointer<ggml_cgraph>)>>('ggml_backend_sched_alloc_graph');
  late final _ggml_backend_sched_alloc_graph =
      _ggml_backend_sched_alloc_graphPtr.asFunction<
          bool Function(ggml_backend_sched_t, ffi.Pointer<ggml_cgraph>)>();

  int ggml_backend_sched_graph_compute(
    ggml_backend_sched_t sched,
    ffi.Pointer<ggml_cgraph> graph,
  ) {
    return _ggml_backend_sched_graph_compute(
      sched,
      graph,
    );
  }

  late final _ggml_backend_sched_graph_computePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ggml_backend_sched_t,
              ffi.Pointer<ggml_cgraph>)>>('ggml_backend_sched_graph_compute');
  late final _ggml_backend_sched_graph_compute =
      _ggml_backend_sched_graph_computePtr.asFunction<
          int Function(ggml_backend_sched_t, ffi.Pointer<ggml_cgraph>)>();

  int ggml_backend_sched_graph_compute_async(
    ggml_backend_sched_t sched,
    ffi.Pointer<ggml_cgraph> graph,
  ) {
    return _ggml_backend_sched_graph_compute_async(
      sched,
      graph,
    );
  }

  late final _ggml_backend_sched_graph_compute_asyncPtr = _lookup<
          ffi.NativeFunction<
              ffi.Int32 Function(
                  ggml_backend_sched_t, ffi.Pointer<ggml_cgraph>)>>(
      'ggml_backend_sched_graph_compute_async');
  late final _ggml_backend_sched_graph_compute_async =
      _ggml_backend_sched_graph_compute_asyncPtr.asFunction<
          int Function(ggml_backend_sched_t, ffi.Pointer<ggml_cgraph>)>();

  void ggml_backend_sched_synchronize(
    ggml_backend_sched_t sched,
  ) {
    return _ggml_backend_sched_synchronize(
      sched,
    );
  }

  late final _ggml_backend_sched_synchronizePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ggml_backend_sched_t)>>(
          'ggml_backend_sched_synchronize');
  late final _ggml_backend_sched_synchronize =
      _ggml_backend_sched_synchronizePtr
          .asFunction<void Function(ggml_backend_sched_t)>();

  /// Reset all assignments and allocators - must be called before changing the node backends or allocating a new graph.
  /// This in effect deallocates all tensors that were previously allocated and leaves them with dangling pointers.
  /// The correct way to use this API is to discard the deallocated tensors and create new ones.
  void ggml_backend_sched_reset(
    ggml_backend_sched_t sched,
  ) {
    return _ggml_backend_sched_reset(
      sched,
    );
  }

  late final _ggml_backend_sched_resetPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ggml_backend_sched_t)>>(
          'ggml_backend_sched_reset');
  late final _ggml_backend_sched_reset = _ggml_backend_sched_resetPtr
      .asFunction<void Function(ggml_backend_sched_t)>();

  /// Set a callback to be called for each resulting node during graph compute
  void ggml_backend_sched_set_eval_callback(
    ggml_backend_sched_t sched,
    ggml_backend_sched_eval_callback callback,
    ffi.Pointer<ffi.Void> user_data,
  ) {
    return _ggml_backend_sched_set_eval_callback(
      sched,
      callback,
      user_data,
    );
  }

  late final _ggml_backend_sched_set_eval_callbackPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ggml_backend_sched_t,
              ggml_backend_sched_eval_callback,
              ffi.Pointer<ffi.Void>)>>('ggml_backend_sched_set_eval_callback');
  late final _ggml_backend_sched_set_eval_callback =
      _ggml_backend_sched_set_eval_callbackPtr.asFunction<
          void Function(ggml_backend_sched_t, ggml_backend_sched_eval_callback,
              ffi.Pointer<ffi.Void>)>();

  /// Copy a graph to a different backend
  ggml_backend_graph_copy ggml_backend_graph_copy1(
    ggml_backend_t backend,
    ffi.Pointer<ggml_cgraph> graph,
  ) {
    return _ggml_backend_graph_copy1(
      backend,
      graph,
    );
  }

  late final _ggml_backend_graph_copy1Ptr = _lookup<
      ffi.NativeFunction<
          ggml_backend_graph_copy Function(ggml_backend_t,
              ffi.Pointer<ggml_cgraph>)>>('ggml_backend_graph_copy');
  late final _ggml_backend_graph_copy1 =
      _ggml_backend_graph_copy1Ptr.asFunction<
          ggml_backend_graph_copy Function(
              ggml_backend_t, ffi.Pointer<ggml_cgraph>)>();

  void ggml_backend_graph_copy_free(
    ggml_backend_graph_copy copy,
  ) {
    return _ggml_backend_graph_copy_free(
      copy,
    );
  }

  late final _ggml_backend_graph_copy_freePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ggml_backend_graph_copy)>>(
          'ggml_backend_graph_copy_free');
  late final _ggml_backend_graph_copy_free = _ggml_backend_graph_copy_freePtr
      .asFunction<void Function(ggml_backend_graph_copy)>();

  /// Compare the output of two backends
  bool ggml_backend_compare_graph_backend(
    ggml_backend_t backend1,
    ggml_backend_t backend2,
    ffi.Pointer<ggml_cgraph> graph,
    ggml_backend_eval_callback callback,
    ffi.Pointer<ffi.Void> user_data,
  ) {
    return _ggml_backend_compare_graph_backend(
      backend1,
      backend2,
      graph,
      callback,
      user_data,
    );
  }

  late final _ggml_backend_compare_graph_backendPtr = _lookup<
      ffi.NativeFunction<
          ffi.Bool Function(
              ggml_backend_t,
              ggml_backend_t,
              ffi.Pointer<ggml_cgraph>,
              ggml_backend_eval_callback,
              ffi.Pointer<ffi.Void>)>>('ggml_backend_compare_graph_backend');
  late final _ggml_backend_compare_graph_backend =
      _ggml_backend_compare_graph_backendPtr.asFunction<
          bool Function(
              ggml_backend_t,
              ggml_backend_t,
              ffi.Pointer<ggml_cgraph>,
              ggml_backend_eval_callback,
              ffi.Pointer<ffi.Void>)>();

  /// Tensor initialization
  void ggml_backend_tensor_alloc(
    ggml_backend_buffer_t buffer,
    ffi.Pointer<ggml_tensor> tensor,
    ffi.Pointer<ffi.Void> addr,
  ) {
    return _ggml_backend_tensor_alloc(
      buffer,
      tensor,
      addr,
    );
  }

  late final _ggml_backend_tensor_allocPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ggml_backend_buffer_t, ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ffi.Void>)>>('ggml_backend_tensor_alloc');
  late final _ggml_backend_tensor_alloc =
      _ggml_backend_tensor_allocPtr.asFunction<
          void Function(ggml_backend_buffer_t, ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ffi.Void>)>();

  void ggml_backend_view_init(
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _ggml_backend_view_init(
      tensor,
    );
  }

  late final _ggml_backend_view_initPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ggml_tensor>)>>(
          'ggml_backend_view_init');
  late final _ggml_backend_view_init = _ggml_backend_view_initPtr
      .asFunction<void Function(ffi.Pointer<ggml_tensor>)>();

  /// CPU buffer types are always available
  ggml_backend_buffer_t ggml_backend_cpu_buffer_from_ptr(
    ffi.Pointer<ffi.Void> ptr,
    int size,
  ) {
    return _ggml_backend_cpu_buffer_from_ptr(
      ptr,
      size,
    );
  }

  late final _ggml_backend_cpu_buffer_from_ptrPtr = _lookup<
      ffi.NativeFunction<
          ggml_backend_buffer_t Function(ffi.Pointer<ffi.Void>,
              ffi.Size)>>('ggml_backend_cpu_buffer_from_ptr');
  late final _ggml_backend_cpu_buffer_from_ptr =
      _ggml_backend_cpu_buffer_from_ptrPtr.asFunction<
          ggml_backend_buffer_t Function(ffi.Pointer<ffi.Void>, int)>();

  ggml_backend_buffer_type_t ggml_backend_cpu_buffer_type() {
    return _ggml_backend_cpu_buffer_type();
  }

  late final _ggml_backend_cpu_buffer_typePtr =
      _lookup<ffi.NativeFunction<ggml_backend_buffer_type_t Function()>>(
          'ggml_backend_cpu_buffer_type');
  late final _ggml_backend_cpu_buffer_type = _ggml_backend_cpu_buffer_typePtr
      .asFunction<ggml_backend_buffer_type_t Function()>();

  void ggml_numa_init(
    int numa,
  ) {
    return _ggml_numa_init(
      numa,
    );
  }

  late final _ggml_numa_initPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Int32)>>(
          'ggml_numa_init');
  late final _ggml_numa_init =
      _ggml_numa_initPtr.asFunction<void Function(int)>();

  bool ggml_is_numa() {
    return _ggml_is_numa();
  }

  late final _ggml_is_numaPtr =
      _lookup<ffi.NativeFunction<ffi.Bool Function()>>('ggml_is_numa');
  late final _ggml_is_numa = _ggml_is_numaPtr.asFunction<bool Function()>();

  ffi.Pointer<ggml_tensor> ggml_new_i32(
    ffi.Pointer<ggml_context> ctx,
    int value,
  ) {
    return _ggml_new_i32(
      ctx,
      value,
    );
  }

  late final _ggml_new_i32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>, ffi.Int32)>>('ggml_new_i32');
  late final _ggml_new_i32 = _ggml_new_i32Ptr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>, int)>();

  ffi.Pointer<ggml_tensor> ggml_new_f32(
    ffi.Pointer<ggml_context> ctx,
    double value,
  ) {
    return _ggml_new_f32(
      ctx,
      value,
    );
  }

  late final _ggml_new_f32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>, ffi.Float)>>('ggml_new_f32');
  late final _ggml_new_f32 = _ggml_new_f32Ptr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>, double)>();

  ffi.Pointer<ggml_tensor> ggml_set_i32(
    ffi.Pointer<ggml_tensor> tensor,
    int value,
  ) {
    return _ggml_set_i32(
      tensor,
      value,
    );
  }

  late final _ggml_set_i32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_tensor>, ffi.Int32)>>('ggml_set_i32');
  late final _ggml_set_i32 = _ggml_set_i32Ptr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_tensor>, int)>();

  ffi.Pointer<ggml_tensor> ggml_set_f32(
    ffi.Pointer<ggml_tensor> tensor,
    double value,
  ) {
    return _ggml_set_f32(
      tensor,
      value,
    );
  }

  late final _ggml_set_f32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_tensor>, ffi.Float)>>('ggml_set_f32');
  late final _ggml_set_f32 = _ggml_set_f32Ptr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_tensor>, double)>();

  int ggml_get_i32_1d(
    ffi.Pointer<ggml_tensor> tensor,
    int i,
  ) {
    return _ggml_get_i32_1d(
      tensor,
      i,
    );
  }

  late final _ggml_get_i32_1dPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<ggml_tensor>, ffi.Int)>>('ggml_get_i32_1d');
  late final _ggml_get_i32_1d = _ggml_get_i32_1dPtr
      .asFunction<int Function(ffi.Pointer<ggml_tensor>, int)>();

  void ggml_set_i32_1d(
    ffi.Pointer<ggml_tensor> tensor,
    int i,
    int value,
  ) {
    return _ggml_set_i32_1d(
      tensor,
      i,
      value,
    );
  }

  late final _ggml_set_i32_1dPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ggml_tensor>, ffi.Int,
              ffi.Int32)>>('ggml_set_i32_1d');
  late final _ggml_set_i32_1d = _ggml_set_i32_1dPtr
      .asFunction<void Function(ffi.Pointer<ggml_tensor>, int, int)>();

  int ggml_get_i32_nd(
    ffi.Pointer<ggml_tensor> tensor,
    int i0,
    int i1,
    int i2,
    int i3,
  ) {
    return _ggml_get_i32_nd(
      tensor,
      i0,
      i1,
      i2,
      i3,
    );
  }

  late final _ggml_get_i32_ndPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<ggml_tensor>, ffi.Int, ffi.Int,
              ffi.Int, ffi.Int)>>('ggml_get_i32_nd');
  late final _ggml_get_i32_nd = _ggml_get_i32_ndPtr
      .asFunction<int Function(ffi.Pointer<ggml_tensor>, int, int, int, int)>();

  void ggml_set_i32_nd(
    ffi.Pointer<ggml_tensor> tensor,
    int i0,
    int i1,
    int i2,
    int i3,
    int value,
  ) {
    return _ggml_set_i32_nd(
      tensor,
      i0,
      i1,
      i2,
      i3,
      value,
    );
  }

  late final _ggml_set_i32_ndPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ggml_tensor>, ffi.Int, ffi.Int, ffi.Int,
              ffi.Int, ffi.Int32)>>('ggml_set_i32_nd');
  late final _ggml_set_i32_nd = _ggml_set_i32_ndPtr.asFunction<
      void Function(ffi.Pointer<ggml_tensor>, int, int, int, int, int)>();

  double ggml_get_f32_1d(
    ffi.Pointer<ggml_tensor> tensor,
    int i,
  ) {
    return _ggml_get_f32_1d(
      tensor,
      i,
    );
  }

  late final _ggml_get_f32_1dPtr = _lookup<
      ffi.NativeFunction<
          ffi.Float Function(
              ffi.Pointer<ggml_tensor>, ffi.Int)>>('ggml_get_f32_1d');
  late final _ggml_get_f32_1d = _ggml_get_f32_1dPtr
      .asFunction<double Function(ffi.Pointer<ggml_tensor>, int)>();

  void ggml_set_f32_1d(
    ffi.Pointer<ggml_tensor> tensor,
    int i,
    double value,
  ) {
    return _ggml_set_f32_1d(
      tensor,
      i,
      value,
    );
  }

  late final _ggml_set_f32_1dPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ggml_tensor>, ffi.Int,
              ffi.Float)>>('ggml_set_f32_1d');
  late final _ggml_set_f32_1d = _ggml_set_f32_1dPtr
      .asFunction<void Function(ffi.Pointer<ggml_tensor>, int, double)>();

  double ggml_get_f32_nd(
    ffi.Pointer<ggml_tensor> tensor,
    int i0,
    int i1,
    int i2,
    int i3,
  ) {
    return _ggml_get_f32_nd(
      tensor,
      i0,
      i1,
      i2,
      i3,
    );
  }

  late final _ggml_get_f32_ndPtr = _lookup<
      ffi.NativeFunction<
          ffi.Float Function(ffi.Pointer<ggml_tensor>, ffi.Int, ffi.Int,
              ffi.Int, ffi.Int)>>('ggml_get_f32_nd');
  late final _ggml_get_f32_nd = _ggml_get_f32_ndPtr.asFunction<
      double Function(ffi.Pointer<ggml_tensor>, int, int, int, int)>();

  void ggml_set_f32_nd(
    ffi.Pointer<ggml_tensor> tensor,
    int i0,
    int i1,
    int i2,
    int i3,
    double value,
  ) {
    return _ggml_set_f32_nd(
      tensor,
      i0,
      i1,
      i2,
      i3,
      value,
    );
  }

  late final _ggml_set_f32_ndPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ggml_tensor>, ffi.Int, ffi.Int, ffi.Int,
              ffi.Int, ffi.Float)>>('ggml_set_f32_nd');
  late final _ggml_set_f32_nd = _ggml_set_f32_ndPtr.asFunction<
      void Function(ffi.Pointer<ggml_tensor>, int, int, int, int, double)>();

  ffi.Pointer<ggml_threadpool> ggml_threadpool_new(
    ffi.Pointer<ggml_threadpool_params> params,
  ) {
    return _ggml_threadpool_new(
      params,
    );
  }

  late final _ggml_threadpool_newPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_threadpool> Function(
              ffi.Pointer<ggml_threadpool_params>)>>('ggml_threadpool_new');
  late final _ggml_threadpool_new = _ggml_threadpool_newPtr.asFunction<
      ffi.Pointer<ggml_threadpool> Function(
          ffi.Pointer<ggml_threadpool_params>)>();

  void ggml_threadpool_free(
    ffi.Pointer<ggml_threadpool> threadpool,
  ) {
    return _ggml_threadpool_free(
      threadpool,
    );
  }

  late final _ggml_threadpool_freePtr = _lookup<
          ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ggml_threadpool>)>>(
      'ggml_threadpool_free');
  late final _ggml_threadpool_free = _ggml_threadpool_freePtr
      .asFunction<void Function(ffi.Pointer<ggml_threadpool>)>();

  int ggml_threadpool_get_n_threads(
    ffi.Pointer<ggml_threadpool> threadpool,
  ) {
    return _ggml_threadpool_get_n_threads(
      threadpool,
    );
  }

  late final _ggml_threadpool_get_n_threadsPtr = _lookup<
          ffi.NativeFunction<ffi.Int Function(ffi.Pointer<ggml_threadpool>)>>(
      'ggml_threadpool_get_n_threads');
  late final _ggml_threadpool_get_n_threads = _ggml_threadpool_get_n_threadsPtr
      .asFunction<int Function(ffi.Pointer<ggml_threadpool>)>();

  void ggml_threadpool_pause(
    ffi.Pointer<ggml_threadpool> threadpool,
  ) {
    return _ggml_threadpool_pause(
      threadpool,
    );
  }

  late final _ggml_threadpool_pausePtr = _lookup<
          ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ggml_threadpool>)>>(
      'ggml_threadpool_pause');
  late final _ggml_threadpool_pause = _ggml_threadpool_pausePtr
      .asFunction<void Function(ffi.Pointer<ggml_threadpool>)>();

  void ggml_threadpool_resume(
    ffi.Pointer<ggml_threadpool> threadpool,
  ) {
    return _ggml_threadpool_resume(
      threadpool,
    );
  }

  late final _ggml_threadpool_resumePtr = _lookup<
          ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ggml_threadpool>)>>(
      'ggml_threadpool_resume');
  late final _ggml_threadpool_resume = _ggml_threadpool_resumePtr
      .asFunction<void Function(ffi.Pointer<ggml_threadpool>)>();

  /// ggml_graph_plan() has to be called before ggml_graph_compute()
  /// when plan.work_size > 0, caller must allocate memory for plan.work_data
  ggml_cplan ggml_graph_plan(
    ffi.Pointer<ggml_cgraph> cgraph,
    int n_threads,
    ffi.Pointer<ggml_threadpool> threadpool,
  ) {
    return _ggml_graph_plan(
      cgraph,
      n_threads,
      threadpool,
    );
  }

  late final _ggml_graph_planPtr = _lookup<
      ffi.NativeFunction<
          ggml_cplan Function(ffi.Pointer<ggml_cgraph>, ffi.Int,
              ffi.Pointer<ggml_threadpool>)>>('ggml_graph_plan');
  late final _ggml_graph_plan = _ggml_graph_planPtr.asFunction<
      ggml_cplan Function(
          ffi.Pointer<ggml_cgraph>, int, ffi.Pointer<ggml_threadpool>)>();

  int ggml_graph_compute(
    ffi.Pointer<ggml_cgraph> cgraph,
    ffi.Pointer<ggml_cplan> cplan,
  ) {
    return _ggml_graph_compute(
      cgraph,
      cplan,
    );
  }

  late final _ggml_graph_computePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<ggml_cgraph>,
              ffi.Pointer<ggml_cplan>)>>('ggml_graph_compute');
  late final _ggml_graph_compute = _ggml_graph_computePtr.asFunction<
      int Function(ffi.Pointer<ggml_cgraph>, ffi.Pointer<ggml_cplan>)>();

  /// same as ggml_graph_compute() but the work data is allocated as a part of the context
  /// note: the drawback of this API is that you must have ensured that the context has enough memory for the work data
  int ggml_graph_compute_with_ctx(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_cgraph> cgraph,
    int n_threads,
  ) {
    return _ggml_graph_compute_with_ctx(
      ctx,
      cgraph,
      n_threads,
    );
  }

  late final _ggml_graph_compute_with_ctxPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_cgraph>,
              ffi.Int)>>('ggml_graph_compute_with_ctx');
  late final _ggml_graph_compute_with_ctx =
      _ggml_graph_compute_with_ctxPtr.asFunction<
          int Function(
              ffi.Pointer<ggml_context>, ffi.Pointer<ggml_cgraph>, int)>();

  /// x86
  int ggml_cpu_has_sse3() {
    return _ggml_cpu_has_sse3();
  }

  late final _ggml_cpu_has_sse3Ptr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('ggml_cpu_has_sse3');
  late final _ggml_cpu_has_sse3 =
      _ggml_cpu_has_sse3Ptr.asFunction<int Function()>();

  int ggml_cpu_has_ssse3() {
    return _ggml_cpu_has_ssse3();
  }

  late final _ggml_cpu_has_ssse3Ptr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('ggml_cpu_has_ssse3');
  late final _ggml_cpu_has_ssse3 =
      _ggml_cpu_has_ssse3Ptr.asFunction<int Function()>();

  int ggml_cpu_has_avx() {
    return _ggml_cpu_has_avx();
  }

  late final _ggml_cpu_has_avxPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('ggml_cpu_has_avx');
  late final _ggml_cpu_has_avx =
      _ggml_cpu_has_avxPtr.asFunction<int Function()>();

  int ggml_cpu_has_avx_vnni() {
    return _ggml_cpu_has_avx_vnni();
  }

  late final _ggml_cpu_has_avx_vnniPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('ggml_cpu_has_avx_vnni');
  late final _ggml_cpu_has_avx_vnni =
      _ggml_cpu_has_avx_vnniPtr.asFunction<int Function()>();

  int ggml_cpu_has_avx2() {
    return _ggml_cpu_has_avx2();
  }

  late final _ggml_cpu_has_avx2Ptr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('ggml_cpu_has_avx2');
  late final _ggml_cpu_has_avx2 =
      _ggml_cpu_has_avx2Ptr.asFunction<int Function()>();

  int ggml_cpu_has_f16c() {
    return _ggml_cpu_has_f16c();
  }

  late final _ggml_cpu_has_f16cPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('ggml_cpu_has_f16c');
  late final _ggml_cpu_has_f16c =
      _ggml_cpu_has_f16cPtr.asFunction<int Function()>();

  int ggml_cpu_has_fma() {
    return _ggml_cpu_has_fma();
  }

  late final _ggml_cpu_has_fmaPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('ggml_cpu_has_fma');
  late final _ggml_cpu_has_fma =
      _ggml_cpu_has_fmaPtr.asFunction<int Function()>();

  int ggml_cpu_has_avx512() {
    return _ggml_cpu_has_avx512();
  }

  late final _ggml_cpu_has_avx512Ptr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('ggml_cpu_has_avx512');
  late final _ggml_cpu_has_avx512 =
      _ggml_cpu_has_avx512Ptr.asFunction<int Function()>();

  int ggml_cpu_has_avx512_vbmi() {
    return _ggml_cpu_has_avx512_vbmi();
  }

  late final _ggml_cpu_has_avx512_vbmiPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>(
          'ggml_cpu_has_avx512_vbmi');
  late final _ggml_cpu_has_avx512_vbmi =
      _ggml_cpu_has_avx512_vbmiPtr.asFunction<int Function()>();

  int ggml_cpu_has_avx512_vnni() {
    return _ggml_cpu_has_avx512_vnni();
  }

  late final _ggml_cpu_has_avx512_vnniPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>(
          'ggml_cpu_has_avx512_vnni');
  late final _ggml_cpu_has_avx512_vnni =
      _ggml_cpu_has_avx512_vnniPtr.asFunction<int Function()>();

  int ggml_cpu_has_avx512_bf16() {
    return _ggml_cpu_has_avx512_bf16();
  }

  late final _ggml_cpu_has_avx512_bf16Ptr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>(
          'ggml_cpu_has_avx512_bf16');
  late final _ggml_cpu_has_avx512_bf16 =
      _ggml_cpu_has_avx512_bf16Ptr.asFunction<int Function()>();

  int ggml_cpu_has_amx_int8() {
    return _ggml_cpu_has_amx_int8();
  }

  late final _ggml_cpu_has_amx_int8Ptr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('ggml_cpu_has_amx_int8');
  late final _ggml_cpu_has_amx_int8 =
      _ggml_cpu_has_amx_int8Ptr.asFunction<int Function()>();

  /// ARM
  int ggml_cpu_has_neon() {
    return _ggml_cpu_has_neon();
  }

  late final _ggml_cpu_has_neonPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('ggml_cpu_has_neon');
  late final _ggml_cpu_has_neon =
      _ggml_cpu_has_neonPtr.asFunction<int Function()>();

  int ggml_cpu_has_arm_fma() {
    return _ggml_cpu_has_arm_fma();
  }

  late final _ggml_cpu_has_arm_fmaPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('ggml_cpu_has_arm_fma');
  late final _ggml_cpu_has_arm_fma =
      _ggml_cpu_has_arm_fmaPtr.asFunction<int Function()>();

  int ggml_cpu_has_fp16_va() {
    return _ggml_cpu_has_fp16_va();
  }

  late final _ggml_cpu_has_fp16_vaPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('ggml_cpu_has_fp16_va');
  late final _ggml_cpu_has_fp16_va =
      _ggml_cpu_has_fp16_vaPtr.asFunction<int Function()>();

  int ggml_cpu_has_dotprod() {
    return _ggml_cpu_has_dotprod();
  }

  late final _ggml_cpu_has_dotprodPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('ggml_cpu_has_dotprod');
  late final _ggml_cpu_has_dotprod =
      _ggml_cpu_has_dotprodPtr.asFunction<int Function()>();

  int ggml_cpu_has_matmul_int8() {
    return _ggml_cpu_has_matmul_int8();
  }

  late final _ggml_cpu_has_matmul_int8Ptr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>(
          'ggml_cpu_has_matmul_int8');
  late final _ggml_cpu_has_matmul_int8 =
      _ggml_cpu_has_matmul_int8Ptr.asFunction<int Function()>();

  int ggml_cpu_has_sve() {
    return _ggml_cpu_has_sve();
  }

  late final _ggml_cpu_has_svePtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('ggml_cpu_has_sve');
  late final _ggml_cpu_has_sve =
      _ggml_cpu_has_svePtr.asFunction<int Function()>();

  int ggml_cpu_get_sve_cnt() {
    return _ggml_cpu_get_sve_cnt();
  }

  late final _ggml_cpu_get_sve_cntPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('ggml_cpu_get_sve_cnt');
  late final _ggml_cpu_get_sve_cnt =
      _ggml_cpu_get_sve_cntPtr.asFunction<int Function()>();

  /// other
  int ggml_cpu_has_riscv_v() {
    return _ggml_cpu_has_riscv_v();
  }

  late final _ggml_cpu_has_riscv_vPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('ggml_cpu_has_riscv_v');
  late final _ggml_cpu_has_riscv_v =
      _ggml_cpu_has_riscv_vPtr.asFunction<int Function()>();

  int ggml_cpu_has_vsx() {
    return _ggml_cpu_has_vsx();
  }

  late final _ggml_cpu_has_vsxPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('ggml_cpu_has_vsx');
  late final _ggml_cpu_has_vsx =
      _ggml_cpu_has_vsxPtr.asFunction<int Function()>();

  int ggml_cpu_has_wasm_simd() {
    return _ggml_cpu_has_wasm_simd();
  }

  late final _ggml_cpu_has_wasm_simdPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('ggml_cpu_has_wasm_simd');
  late final _ggml_cpu_has_wasm_simd =
      _ggml_cpu_has_wasm_simdPtr.asFunction<int Function()>();

  int ggml_cpu_has_llamafile() {
    return _ggml_cpu_has_llamafile();
  }

  late final _ggml_cpu_has_llamafilePtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('ggml_cpu_has_llamafile');
  late final _ggml_cpu_has_llamafile =
      _ggml_cpu_has_llamafilePtr.asFunction<int Function()>();

  ffi.Pointer<ggml_type_traits_cpu> ggml_get_type_traits_cpu(
    int type,
  ) {
    return _ggml_get_type_traits_cpu(
      type,
    );
  }

  late final _ggml_get_type_traits_cpuPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_type_traits_cpu> Function(
              ffi.Int32)>>('ggml_get_type_traits_cpu');
  late final _ggml_get_type_traits_cpu = _ggml_get_type_traits_cpuPtr
      .asFunction<ffi.Pointer<ggml_type_traits_cpu> Function(int)>();

  void ggml_cpu_init() {
    return _ggml_cpu_init();
  }

  late final _ggml_cpu_initPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('ggml_cpu_init');
  late final _ggml_cpu_init = _ggml_cpu_initPtr.asFunction<void Function()>();

  /// CPU backend
  ggml_backend_t ggml_backend_cpu_init() {
    return _ggml_backend_cpu_init();
  }

  late final _ggml_backend_cpu_initPtr =
      _lookup<ffi.NativeFunction<ggml_backend_t Function()>>(
          'ggml_backend_cpu_init');
  late final _ggml_backend_cpu_init =
      _ggml_backend_cpu_initPtr.asFunction<ggml_backend_t Function()>();

  bool ggml_backend_is_cpu(
    ggml_backend_t backend,
  ) {
    return _ggml_backend_is_cpu(
      backend,
    );
  }

  late final _ggml_backend_is_cpuPtr =
      _lookup<ffi.NativeFunction<ffi.Bool Function(ggml_backend_t)>>(
          'ggml_backend_is_cpu');
  late final _ggml_backend_is_cpu =
      _ggml_backend_is_cpuPtr.asFunction<bool Function(ggml_backend_t)>();

  void ggml_backend_cpu_set_n_threads(
    ggml_backend_t backend_cpu,
    int n_threads,
  ) {
    return _ggml_backend_cpu_set_n_threads(
      backend_cpu,
      n_threads,
    );
  }

  late final _ggml_backend_cpu_set_n_threadsPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ggml_backend_t, ffi.Int)>>(
          'ggml_backend_cpu_set_n_threads');
  late final _ggml_backend_cpu_set_n_threads =
      _ggml_backend_cpu_set_n_threadsPtr
          .asFunction<void Function(ggml_backend_t, int)>();

  void ggml_backend_cpu_set_threadpool(
    ggml_backend_t backend_cpu,
    ggml_threadpool_t threadpool,
  ) {
    return _ggml_backend_cpu_set_threadpool(
      backend_cpu,
      threadpool,
    );
  }

  late final _ggml_backend_cpu_set_threadpoolPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ggml_backend_t,
              ggml_threadpool_t)>>('ggml_backend_cpu_set_threadpool');
  late final _ggml_backend_cpu_set_threadpool =
      _ggml_backend_cpu_set_threadpoolPtr
          .asFunction<void Function(ggml_backend_t, ggml_threadpool_t)>();

  void ggml_backend_cpu_set_abort_callback(
    ggml_backend_t backend_cpu,
    ggml_abort_callback abort_callback,
    ffi.Pointer<ffi.Void> abort_callback_data,
  ) {
    return _ggml_backend_cpu_set_abort_callback(
      backend_cpu,
      abort_callback,
      abort_callback_data,
    );
  }

  late final _ggml_backend_cpu_set_abort_callbackPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ggml_backend_t, ggml_abort_callback,
              ffi.Pointer<ffi.Void>)>>('ggml_backend_cpu_set_abort_callback');
  late final _ggml_backend_cpu_set_abort_callback =
      _ggml_backend_cpu_set_abort_callbackPtr.asFunction<
          void Function(
              ggml_backend_t, ggml_abort_callback, ffi.Pointer<ffi.Void>)>();

  ggml_backend_reg_t ggml_backend_cpu_reg() {
    return _ggml_backend_cpu_reg();
  }

  late final _ggml_backend_cpu_regPtr =
      _lookup<ffi.NativeFunction<ggml_backend_reg_t Function()>>(
          'ggml_backend_cpu_reg');
  late final _ggml_backend_cpu_reg =
      _ggml_backend_cpu_regPtr.asFunction<ggml_backend_reg_t Function()>();
}

/// C interface
///
/// The following interface is thread-safe as long as the sample whisper_context is not used by multiple threads
/// concurrently.
///
/// Basic usage:
///
/// #include "whisper.h"
///
/// ...
///
/// whisper_context_params cparams = whisper_context_default_params();
///
/// struct whisper_context * ctx = whisper_init_from_file_with_params("/path/to/ggml-base.en.bin", cparams);
///
/// if (whisper_full(ctx, wparams, pcmf32.data(), pcmf32.size()) != 0) {
/// fprintf(stderr, "failed to process audio\n");
/// return 7;
/// }
///
/// const int n_segments = whisper_full_n_segments(ctx);
/// for (int i = 0; i < n_segments; ++i) {
/// const char * text = whisper_full_get_segment_text(ctx, i);
/// printf("%s", text);
/// }
///
/// whisper_free(ctx);
///
/// ...
///
/// This is a demonstration of the most straightforward usage of the library.
/// "pcmf32" contains the RAW audio data in 32-bit floating point format.
///
/// The interface also allows for more fine-grained control over the computation, but it requires a deeper
/// understanding of how the model works.
final class whisper_context extends ffi.Opaque {}

final class whisper_state extends ffi.Opaque {}

/// Parameters for the whisper_full() function
/// If you change the order or add new parameters, make sure to update the default values in whisper.cpp:
/// whisper_full_default_params()
final class whisper_full_params extends ffi.Struct {
  @ffi.Int32()
  external int strategy;

  @ffi.Int()
  external int n_threads;

  /// max tokens to use from past text as prompt for the decoder
  @ffi.Int()
  external int n_max_text_ctx;

  /// start offset in ms
  @ffi.Int()
  external int offset_ms;

  /// audio duration to process in ms
  @ffi.Int()
  external int duration_ms;

  @ffi.Bool()
  external bool translate;

  /// do not use past transcription (if any) as initial prompt for the decoder
  @ffi.Bool()
  external bool no_context;

  /// do not generate timestamps
  @ffi.Bool()
  external bool no_timestamps;

  /// force single segment output (useful for streaming)
  @ffi.Bool()
  external bool single_segment;

  /// print special tokens (e.g. <SOT>, <EOT>, <BEG>, etc.)
  @ffi.Bool()
  external bool print_special;

  /// print progress information
  @ffi.Bool()
  external bool print_progress;

  /// print results from within whisper.cpp (avoid it, use callback instead)
  @ffi.Bool()
  external bool print_realtime;

  /// print timestamps for each text segment when printing realtime
  @ffi.Bool()
  external bool print_timestamps;

  /// enable token-level timestamps
  @ffi.Bool()
  external bool token_timestamps;

  /// timestamp token probability threshold (~0.01)
  @ffi.Float()
  external double thold_pt;

  /// timestamp token sum probability threshold (~0.01)
  @ffi.Float()
  external double thold_ptsum;

  /// max segment length in characters
  @ffi.Int()
  external int max_len;

  /// split on word rather than on token (when used with max_len)
  @ffi.Bool()
  external bool split_on_word;

  /// max tokens per segment (0 = no limit)
  @ffi.Int()
  external int max_tokens;

  /// enable debug_mode provides extra info (eg. Dump log_mel)
  @ffi.Bool()
  external bool debug_mode;

  /// overwrite the audio context size (0 = use default)
  @ffi.Int()
  external int audio_ctx;

  /// enable tinydiarize speaker turn detection
  @ffi.Bool()
  external bool tdrz_enable;

  /// A regular expression that matches tokens to suppress
  external ffi.Pointer<ffi.Char> suppress_regex;

  /// tokens to provide to the whisper decoder as initial prompt
  /// these are prepended to any existing text context from a previous call
  /// use whisper_tokenize() to convert text to tokens
  /// maximum of whisper_n_text_ctx()/2 tokens are used (typically 224)
  external ffi.Pointer<ffi.Char> initial_prompt;

  external ffi.Pointer<whisper_token> prompt_tokens;

  @ffi.Int()
  external int prompt_n_tokens;

  /// for auto-detection, set to nullptr, "" or "auto"
  external ffi.Pointer<ffi.Char> language;

  @ffi.Bool()
  external bool detect_language;

  /// ref: https://github.com/openai/whisper/blob/f82bc59f5ea234d4b97fb2860842ed38519f7e65/whisper/decoding.py#L89
  @ffi.Bool()
  external bool suppress_blank;

  /// non-speech tokens, ref: https://github.com/openai/whisper/blob/7858aa9c08d98f75575035ecd6481f462d66ca27/whisper/tokenizer.py#L224-L253
  @ffi.Bool()
  external bool suppress_nst;

  /// initial decoding temperature, ref: https://ai.stackexchange.com/a/32478
  @ffi.Float()
  external double temperature;

  /// ref: https://github.com/openai/whisper/blob/f82bc59f5ea234d4b97fb2860842ed38519f7e65/whisper/decoding.py#L97
  @ffi.Float()
  external double max_initial_ts;

  /// ref: https://github.com/openai/whisper/blob/f82bc59f5ea234d4b97fb2860842ed38519f7e65/whisper/transcribe.py#L267
  @ffi.Float()
  external double length_penalty;

  /// fallback parameters
  /// ref: https://github.com/openai/whisper/blob/f82bc59f5ea234d4b97fb2860842ed38519f7e65/whisper/transcribe.py#L274-L278
  @ffi.Float()
  external double temperature_inc;

  /// similar to OpenAI's "compression_ratio_threshold"
  @ffi.Float()
  external double entropy_thold;

  @ffi.Float()
  external double logprob_thold;

  @ffi.Float()
  external double no_speech_thold;

  external UnnamedStruct1 greedy;

  external UnnamedStruct2 beam_search;

  /// called for every newly generated text segment
  external whisper_new_segment_callback new_segment_callback;

  external ffi.Pointer<ffi.Void> new_segment_callback_user_data;

  /// called on each progress update
  external whisper_progress_callback progress_callback;

  external ffi.Pointer<ffi.Void> progress_callback_user_data;

  /// called each time before the encoder starts
  external whisper_encoder_begin_callback encoder_begin_callback;

  external ffi.Pointer<ffi.Void> encoder_begin_callback_user_data;

  /// called each time before ggml computation starts
  @ffi.Int()
  external int abort_callback;

  external ffi.Pointer<ffi.Void> abort_callback_user_data;

  /// called by each decoder to filter obtained logits
  external whisper_logits_filter_callback logits_filter_callback;

  external ffi.Pointer<ffi.Void> logits_filter_callback_user_data;

  external ffi.Pointer<ffi.Pointer<whisper_grammar_element>> grammar_rules;

  @ffi.Size()
  external int n_grammar_rules;

  @ffi.Size()
  external int i_start_rule;

  @ffi.Float()
  external double grammar_penalty;
}

/// Available sampling strategies
abstract class whisper_sampling_strategy {
  /// similar to OpenAI's GreedyDecoder
  static const int WHISPER_SAMPLING_GREEDY = 0;

  /// similar to OpenAI's BeamSearchDecoder
  static const int WHISPER_SAMPLING_BEAM_SEARCH = 1;
}

typedef whisper_token = ffi.Int32;

final class UnnamedStruct1 extends ffi.Struct {
  /// ref: https://github.com/openai/whisper/blob/f82bc59f5ea234d4b97fb2860842ed38519f7e65/whisper/transcribe.py#L264
  @ffi.Int()
  external int best_of;
}

final class UnnamedStruct2 extends ffi.Struct {
  /// ref: https://github.com/openai/whisper/blob/f82bc59f5ea234d4b97fb2860842ed38519f7e65/whisper/transcribe.py#L265
  @ffi.Int()
  external int beam_size;

  /// TODO: not implemented, ref: https://arxiv.org/pdf/2204.05424.pdf
  @ffi.Float()
  external double patience;
}

/// Text segment callback
/// Called on every newly generated text segment
/// Use the whisper_full_...() functions to obtain the text segments
typedef whisper_new_segment_callback = ffi.Pointer<
    ffi.NativeFunction<
        ffi.Void Function(
            ffi.Pointer<whisper_context> ctx,
            ffi.Pointer<whisper_state> state,
            ffi.Int n_new,
            ffi.Pointer<ffi.Void> user_data)>>;

/// Progress callback
typedef whisper_progress_callback = ffi.Pointer<
    ffi.NativeFunction<
        ffi.Void Function(
            ffi.Pointer<whisper_context> ctx,
            ffi.Pointer<whisper_state> state,
            ffi.Int progress,
            ffi.Pointer<ffi.Void> user_data)>>;

/// Encoder begin callback
/// If not NULL, called before the encoder starts
/// If it returns false, the computation is aborted
typedef whisper_encoder_begin_callback = ffi.Pointer<
    ffi.NativeFunction<
        ffi.Bool Function(
            ffi.Pointer<whisper_context> ctx,
            ffi.Pointer<whisper_state> state,
            ffi.Pointer<ffi.Void> user_data)>>;

/// Logits filter callback
/// Can be used to modify the logits before sampling
/// If not NULL, called after applying temperature to logits
typedef whisper_logits_filter_callback = ffi.Pointer<
    ffi.NativeFunction<
        ffi.Void Function(
            ffi.Pointer<whisper_context> ctx,
            ffi.Pointer<whisper_state> state,
            ffi.Pointer<whisper_token_data> tokens,
            ffi.Int n_tokens,
            ffi.Pointer<ffi.Float> logits,
            ffi.Pointer<ffi.Void> user_data)>>;

final class whisper_token_data extends ffi.Struct {
  /// token id
  @whisper_token()
  external int id;

  /// forced timestamp token id
  @whisper_token()
  external int tid;

  /// probability of the token
  @ffi.Float()
  external double p;

  /// log probability of the token
  @ffi.Float()
  external double plog;

  /// probability of the timestamp token
  @ffi.Float()
  external double pt;

  /// sum of probabilities of all timestamp tokens
  @ffi.Float()
  external double ptsum;

  /// start time of the token
  @ffi.Int64()
  external int t0;

  /// end time of the token
  @ffi.Int64()
  external int t1;

  /// [EXPERIMENTAL] Token-level timestamps with DTW
  /// do not use if you haven't computed token-level timestamps with dtw
  /// Roughly corresponds to the moment in audio in which the token was output
  @ffi.Int64()
  external int t_dtw;

  /// voice length of the token
  @ffi.Float()
  external double vlen;
}

final class whisper_grammar_element extends ffi.Struct {
  @ffi.Int32()
  external int type;

  /// Unicode code point or rule ID
  @ffi.Uint32()
  external int value;
}

/// grammar element type
abstract class whisper_gretype {
  /// end of rule definition
  static const int WHISPER_GRETYPE_END = 0;

  /// start of alternate definition for rule
  static const int WHISPER_GRETYPE_ALT = 1;

  /// non-terminal element: reference to rule
  static const int WHISPER_GRETYPE_RULE_REF = 2;

  /// terminal element: character (code point)
  static const int WHISPER_GRETYPE_CHAR = 3;

  /// inverse char(s) ([^a], [^a-b] [^abc])
  static const int WHISPER_GRETYPE_CHAR_NOT = 4;

  /// modifies a preceding WHISPER_GRETYPE_CHAR or LLAMA_GRETYPE_CHAR_ALT to
  /// be an inclusive range ([a-z])
  static const int WHISPER_GRETYPE_CHAR_RNG_UPPER = 5;

  /// modifies a preceding WHISPER_GRETYPE_CHAR or
  /// WHISPER_GRETYPE_CHAR_RNG_UPPER to add an alternate char to match ([ab], [a-zA])
  static const int WHISPER_GRETYPE_CHAR_ALT = 6;
}

abstract class whisper_alignment_heads_preset {
  static const int WHISPER_AHEADS_NONE = 0;

  /// All heads from the N-top-most text-layers
  static const int WHISPER_AHEADS_N_TOP_MOST = 1;
  static const int WHISPER_AHEADS_CUSTOM = 2;
  static const int WHISPER_AHEADS_TINY_EN = 3;
  static const int WHISPER_AHEADS_TINY = 4;
  static const int WHISPER_AHEADS_BASE_EN = 5;
  static const int WHISPER_AHEADS_BASE = 6;
  static const int WHISPER_AHEADS_SMALL_EN = 7;
  static const int WHISPER_AHEADS_SMALL = 8;
  static const int WHISPER_AHEADS_MEDIUM_EN = 9;
  static const int WHISPER_AHEADS_MEDIUM = 10;
  static const int WHISPER_AHEADS_LARGE_V1 = 11;
  static const int WHISPER_AHEADS_LARGE_V2 = 12;
  static const int WHISPER_AHEADS_LARGE_V3 = 13;
  static const int WHISPER_AHEADS_LARGE_V3_TURBO = 14;
}

final class whisper_ahead extends ffi.Struct {
  @ffi.Int()
  external int n_text_layer;

  @ffi.Int()
  external int n_head;
}

final class whisper_aheads extends ffi.Struct {
  @ffi.Size()
  external int n_heads;

  external ffi.Pointer<whisper_ahead> heads;
}

final class whisper_context_params extends ffi.Struct {
  @ffi.Bool()
  external bool use_gpu;

  @ffi.Bool()
  external bool flash_attn;

  /// CUDA device
  @ffi.Int()
  external int gpu_device;

  /// [EXPERIMENTAL] Token-level timestamps with DTW
  @ffi.Bool()
  external bool dtw_token_timestamps;

  @ffi.Int32()
  external int dtw_aheads_preset;

  @ffi.Int()
  external int dtw_n_top;

  external whisper_aheads dtw_aheads;

  /// TODO: remove
  @ffi.Size()
  external int dtw_mem_size;
}

final class whisper_model_loader extends ffi.Struct {
  external ffi.Pointer<ffi.Void> context;

  external ffi.Pointer<
      ffi.NativeFunction<
          ffi.Size Function(ffi.Pointer<ffi.Void> ctx,
              ffi.Pointer<ffi.Void> output, ffi.Size read_size)>> read;

  external ffi
      .Pointer<ffi.NativeFunction<ffi.Bool Function(ffi.Pointer<ffi.Void> ctx)>>
      eof;

  external ffi
      .Pointer<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void> ctx)>>
      close;
}

/// Performance information from the default state.
final class whisper_timings extends ffi.Struct {
  @ffi.Float()
  external double sample_ms;

  @ffi.Float()
  external double encode_ms;

  @ffi.Float()
  external double decode_ms;

  @ffi.Float()
  external double batchd_ms;

  @ffi.Float()
  external double prompt_ms;
}

abstract class ggml_status {
  static const int GGML_STATUS_ALLOC_FAILED = -2;
  static const int GGML_STATUS_FAILED = -1;
  static const int GGML_STATUS_SUCCESS = 0;
  static const int GGML_STATUS_ABORTED = 1;
}

/// ieee 754-2008 half-precision float16
/// todo: make this not an integral type
typedef ggml_fp16_t = ffi.Uint16;

/// google brain half-precision bfloat16
final class ggml_bf16_t extends ffi.Struct {
  @ffi.Uint16()
  external int bits;
}

final class ggml_object extends ffi.Opaque {}

final class ggml_context extends ffi.Opaque {}

final class ggml_cgraph extends ffi.Opaque {}

/// NOTE: always add types at the end of the enum to keep backward compatibility
abstract class ggml_type {
  static const int GGML_TYPE_F32 = 0;
  static const int GGML_TYPE_F16 = 1;
  static const int GGML_TYPE_Q4_0 = 2;
  static const int GGML_TYPE_Q4_1 = 3;

  /// GGML_TYPE_Q4_2 = 4, support has been removed
  /// GGML_TYPE_Q4_3 = 5, support has been removed
  static const int GGML_TYPE_Q5_0 = 6;
  static const int GGML_TYPE_Q5_1 = 7;
  static const int GGML_TYPE_Q8_0 = 8;
  static const int GGML_TYPE_Q8_1 = 9;
  static const int GGML_TYPE_Q2_K = 10;
  static const int GGML_TYPE_Q3_K = 11;
  static const int GGML_TYPE_Q4_K = 12;
  static const int GGML_TYPE_Q5_K = 13;
  static const int GGML_TYPE_Q6_K = 14;
  static const int GGML_TYPE_Q8_K = 15;
  static const int GGML_TYPE_IQ2_XXS = 16;
  static const int GGML_TYPE_IQ2_XS = 17;
  static const int GGML_TYPE_IQ3_XXS = 18;
  static const int GGML_TYPE_IQ1_S = 19;
  static const int GGML_TYPE_IQ4_NL = 20;
  static const int GGML_TYPE_IQ3_S = 21;
  static const int GGML_TYPE_IQ2_S = 22;
  static const int GGML_TYPE_IQ4_XS = 23;
  static const int GGML_TYPE_I8 = 24;
  static const int GGML_TYPE_I16 = 25;
  static const int GGML_TYPE_I32 = 26;
  static const int GGML_TYPE_I64 = 27;
  static const int GGML_TYPE_F64 = 28;
  static const int GGML_TYPE_IQ1_M = 29;
  static const int GGML_TYPE_BF16 = 30;

  /// GGML_TYPE_Q4_0_4_4 = 31, support has been removed from gguf files
  /// GGML_TYPE_Q4_0_4_8 = 32,
  /// GGML_TYPE_Q4_0_8_8 = 33,
  static const int GGML_TYPE_TQ1_0 = 34;
  static const int GGML_TYPE_TQ2_0 = 35;

  /// GGML_TYPE_IQ4_NL_4_4 = 36,
  /// GGML_TYPE_IQ4_NL_4_8 = 37,
  /// GGML_TYPE_IQ4_NL_8_8 = 38,
  static const int GGML_TYPE_COUNT = 39;
}

/// precision
abstract class ggml_prec {
  static const int GGML_PREC_DEFAULT = 0;
  static const int GGML_PREC_F32 = 1;
}

/// model file types
abstract class ggml_ftype {
  static const int GGML_FTYPE_UNKNOWN = -1;
  static const int GGML_FTYPE_ALL_F32 = 0;

  /// except 1d tensors
  static const int GGML_FTYPE_MOSTLY_F16 = 1;

  /// except 1d tensors
  static const int GGML_FTYPE_MOSTLY_Q4_0 = 2;

  /// except 1d tensors
  static const int GGML_FTYPE_MOSTLY_Q4_1 = 3;

  /// tok_embeddings.weight and output.weight are F16
  static const int GGML_FTYPE_MOSTLY_Q4_1_SOME_F16 = 4;

  /// except 1d tensors
  static const int GGML_FTYPE_MOSTLY_Q8_0 = 7;

  /// except 1d tensors
  static const int GGML_FTYPE_MOSTLY_Q5_0 = 8;

  /// except 1d tensors
  static const int GGML_FTYPE_MOSTLY_Q5_1 = 9;

  /// except 1d tensors
  static const int GGML_FTYPE_MOSTLY_Q2_K = 10;

  /// except 1d tensors
  static const int GGML_FTYPE_MOSTLY_Q3_K = 11;

  /// except 1d tensors
  static const int GGML_FTYPE_MOSTLY_Q4_K = 12;

  /// except 1d tensors
  static const int GGML_FTYPE_MOSTLY_Q5_K = 13;

  /// except 1d tensors
  static const int GGML_FTYPE_MOSTLY_Q6_K = 14;

  /// except 1d tensors
  static const int GGML_FTYPE_MOSTLY_IQ2_XXS = 15;

  /// except 1d tensors
  static const int GGML_FTYPE_MOSTLY_IQ2_XS = 16;

  /// except 1d tensors
  static const int GGML_FTYPE_MOSTLY_IQ3_XXS = 17;

  /// except 1d tensors
  static const int GGML_FTYPE_MOSTLY_IQ1_S = 18;

  /// except 1d tensors
  static const int GGML_FTYPE_MOSTLY_IQ4_NL = 19;

  /// except 1d tensors
  static const int GGML_FTYPE_MOSTLY_IQ3_S = 20;

  /// except 1d tensors
  static const int GGML_FTYPE_MOSTLY_IQ2_S = 21;

  /// except 1d tensors
  static const int GGML_FTYPE_MOSTLY_IQ4_XS = 22;

  /// except 1d tensors
  static const int GGML_FTYPE_MOSTLY_IQ1_M = 23;

  /// except 1d tensors
  static const int GGML_FTYPE_MOSTLY_BF16 = 24;
}

/// available tensor operations:
abstract class ggml_op {
  static const int GGML_OP_NONE = 0;
  static const int GGML_OP_DUP = 1;
  static const int GGML_OP_ADD = 2;
  static const int GGML_OP_ADD1 = 3;
  static const int GGML_OP_ACC = 4;
  static const int GGML_OP_SUB = 5;
  static const int GGML_OP_MUL = 6;
  static const int GGML_OP_DIV = 7;
  static const int GGML_OP_SQR = 8;
  static const int GGML_OP_SQRT = 9;
  static const int GGML_OP_LOG = 10;
  static const int GGML_OP_SIN = 11;
  static const int GGML_OP_COS = 12;
  static const int GGML_OP_SUM = 13;
  static const int GGML_OP_SUM_ROWS = 14;
  static const int GGML_OP_MEAN = 15;
  static const int GGML_OP_ARGMAX = 16;
  static const int GGML_OP_COUNT_EQUAL = 17;
  static const int GGML_OP_REPEAT = 18;
  static const int GGML_OP_REPEAT_BACK = 19;
  static const int GGML_OP_CONCAT = 20;
  static const int GGML_OP_SILU_BACK = 21;

  /// normalize
  static const int GGML_OP_NORM = 22;
  static const int GGML_OP_RMS_NORM = 23;
  static const int GGML_OP_RMS_NORM_BACK = 24;
  static const int GGML_OP_GROUP_NORM = 25;
  static const int GGML_OP_MUL_MAT = 26;
  static const int GGML_OP_MUL_MAT_ID = 27;
  static const int GGML_OP_OUT_PROD = 28;
  static const int GGML_OP_SCALE = 29;
  static const int GGML_OP_SET = 30;
  static const int GGML_OP_CPY = 31;
  static const int GGML_OP_CONT = 32;
  static const int GGML_OP_RESHAPE = 33;
  static const int GGML_OP_VIEW = 34;
  static const int GGML_OP_PERMUTE = 35;
  static const int GGML_OP_TRANSPOSE = 36;
  static const int GGML_OP_GET_ROWS = 37;
  static const int GGML_OP_GET_ROWS_BACK = 38;
  static const int GGML_OP_DIAG = 39;
  static const int GGML_OP_DIAG_MASK_INF = 40;
  static const int GGML_OP_DIAG_MASK_ZERO = 41;
  static const int GGML_OP_SOFT_MAX = 42;
  static const int GGML_OP_SOFT_MAX_BACK = 43;
  static const int GGML_OP_ROPE = 44;
  static const int GGML_OP_ROPE_BACK = 45;
  static const int GGML_OP_CLAMP = 46;
  static const int GGML_OP_CONV_TRANSPOSE_1D = 47;
  static const int GGML_OP_IM2COL = 48;
  static const int GGML_OP_IM2COL_BACK = 49;
  static const int GGML_OP_CONV_TRANSPOSE_2D = 50;
  static const int GGML_OP_POOL_1D = 51;
  static const int GGML_OP_POOL_2D = 52;
  static const int GGML_OP_POOL_2D_BACK = 53;

  /// nearest interpolate
  static const int GGML_OP_UPSCALE = 54;
  static const int GGML_OP_PAD = 55;
  static const int GGML_OP_PAD_REFLECT_1D = 56;
  static const int GGML_OP_ARANGE = 57;
  static const int GGML_OP_TIMESTEP_EMBEDDING = 58;
  static const int GGML_OP_ARGSORT = 59;
  static const int GGML_OP_LEAKY_RELU = 60;
  static const int GGML_OP_FLASH_ATTN_EXT = 61;
  static const int GGML_OP_FLASH_ATTN_BACK = 62;
  static const int GGML_OP_SSM_CONV = 63;
  static const int GGML_OP_SSM_SCAN = 64;
  static const int GGML_OP_WIN_PART = 65;
  static const int GGML_OP_WIN_UNPART = 66;
  static const int GGML_OP_GET_REL_POS = 67;
  static const int GGML_OP_ADD_REL_POS = 68;
  static const int GGML_OP_RWKV_WKV6 = 69;
  static const int GGML_OP_GATED_LINEAR_ATTN = 70;
  static const int GGML_OP_UNARY = 71;
  static const int GGML_OP_MAP_UNARY = 72;
  static const int GGML_OP_MAP_BINARY = 73;
  static const int GGML_OP_MAP_CUSTOM1_F32 = 74;
  static const int GGML_OP_MAP_CUSTOM2_F32 = 75;
  static const int GGML_OP_MAP_CUSTOM3_F32 = 76;
  static const int GGML_OP_MAP_CUSTOM1 = 77;
  static const int GGML_OP_MAP_CUSTOM2 = 78;
  static const int GGML_OP_MAP_CUSTOM3 = 79;
  static const int GGML_OP_CROSS_ENTROPY_LOSS = 80;
  static const int GGML_OP_CROSS_ENTROPY_LOSS_BACK = 81;
  static const int GGML_OP_OPT_STEP_ADAMW = 82;
  static const int GGML_OP_COUNT = 83;
}

abstract class ggml_unary_op {
  static const int GGML_UNARY_OP_ABS = 0;
  static const int GGML_UNARY_OP_SGN = 1;
  static const int GGML_UNARY_OP_NEG = 2;
  static const int GGML_UNARY_OP_STEP = 3;
  static const int GGML_UNARY_OP_TANH = 4;
  static const int GGML_UNARY_OP_ELU = 5;
  static const int GGML_UNARY_OP_RELU = 6;
  static const int GGML_UNARY_OP_SIGMOID = 7;
  static const int GGML_UNARY_OP_GELU = 8;
  static const int GGML_UNARY_OP_GELU_QUICK = 9;
  static const int GGML_UNARY_OP_SILU = 10;
  static const int GGML_UNARY_OP_HARDSWISH = 11;
  static const int GGML_UNARY_OP_HARDSIGMOID = 12;
  static const int GGML_UNARY_OP_EXP = 13;
  static const int GGML_UNARY_OP_COUNT = 14;
}

abstract class ggml_object_type {
  static const int GGML_OBJECT_TYPE_TENSOR = 0;
  static const int GGML_OBJECT_TYPE_GRAPH = 1;
  static const int GGML_OBJECT_TYPE_WORK_BUFFER = 2;
}

abstract class ggml_log_level {
  static const int GGML_LOG_LEVEL_NONE = 0;
  static const int GGML_LOG_LEVEL_DEBUG = 1;
  static const int GGML_LOG_LEVEL_INFO = 2;
  static const int GGML_LOG_LEVEL_WARN = 3;
  static const int GGML_LOG_LEVEL_ERROR = 4;

  /// continue previous log
  static const int GGML_LOG_LEVEL_CONT = 5;
}

/// this tensor...
abstract class ggml_tensor_flag {
  /// ...is an input for the GGML compute graph
  static const int GGML_TENSOR_FLAG_INPUT = 1;

  /// ...is an output for the GGML compute graph
  static const int GGML_TENSOR_FLAG_OUTPUT = 2;

  /// ...contains trainable parameters
  static const int GGML_TENSOR_FLAG_PARAM = 4;

  /// ...defines loss for numerical optimization (multiple loss tensors add up)
  static const int GGML_TENSOR_FLAG_LOSS = 8;
}

final class ggml_init_params extends ffi.Struct {
  /// bytes
  @ffi.Size()
  external int mem_size;

  /// if NULL, memory will be allocated internally
  external ffi.Pointer<ffi.Void> mem_buffer;

  /// don't allocate memory for the tensor data
  @ffi.Bool()
  external bool no_alloc;
}

/// n-dimensional tensor
final class ggml_tensor extends ffi.Struct {
  @ffi.Int32()
  external int type;

  external ffi.Pointer<ggml_backend_buffer> buffer;

  /// number of elements
  @ffi.Array.multi([4])
  external ffi.Array<ffi.Int64> ne;

  /// stride in bytes:
  /// nb[0] = ggml_type_size(type)
  /// nb[1] = nb[0]   * (ne[0] / ggml_blck_size(type)) + padding
  /// nb[i] = nb[i-1] * ne[i-1]
  @ffi.Array.multi([4])
  external ffi.Array<ffi.Size> nb;

  /// compute data
  @ffi.Int32()
  external int op;

  /// op params - allocated as int32_t for alignment
  @ffi.Array.multi([16])
  external ffi.Array<ffi.Int32> op_params;

  @ffi.Int32()
  external int flags;

  @ffi.Array.multi([10])
  external ffi.Array<ffi.Pointer<ggml_tensor>> src;

  /// source tensor and offset for views
  external ffi.Pointer<ggml_tensor> view_src;

  @ffi.Size()
  external int view_offs;

  external ffi.Pointer<ffi.Void> data;

  @ffi.Array.multi([64])
  external ffi.Array<ffi.Char> name;

  /// extra things e.g. for ggml-cuda.cu
  external ffi.Pointer<ffi.Void> extra;

  @ffi.Array.multi([8])
  external ffi.Array<ffi.Char> padding;
}

final class ggml_backend_buffer extends ffi.Opaque {}

typedef ggml_guid_t = ffi.Pointer<ffi.Pointer<ffi.Uint8>>;
typedef FILE = _IO_FILE;

final class _IO_FILE extends ffi.Struct {
  @ffi.Int()
  external int _flags;

  external ffi.Pointer<ffi.Char> _IO_read_ptr;

  external ffi.Pointer<ffi.Char> _IO_read_end;

  external ffi.Pointer<ffi.Char> _IO_read_base;

  external ffi.Pointer<ffi.Char> _IO_write_base;

  external ffi.Pointer<ffi.Char> _IO_write_ptr;

  external ffi.Pointer<ffi.Char> _IO_write_end;

  external ffi.Pointer<ffi.Char> _IO_buf_base;

  external ffi.Pointer<ffi.Char> _IO_buf_end;

  external ffi.Pointer<ffi.Char> _IO_save_base;

  external ffi.Pointer<ffi.Char> _IO_backup_base;

  external ffi.Pointer<ffi.Char> _IO_save_end;

  external ffi.Pointer<_IO_marker> _markers;

  external ffi.Pointer<_IO_FILE> _chain;

  @ffi.Int()
  external int _fileno;

  @ffi.Int()
  external int _flags2;

  @__off_t()
  external int _old_offset;

  @ffi.UnsignedShort()
  external int _cur_column;

  @ffi.SignedChar()
  external int _vtable_offset;

  @ffi.Array.multi([1])
  external ffi.Array<ffi.Char> _shortbuf;

  external ffi.Pointer<_IO_lock_t> _lock;

  @__off64_t()
  external int _offset;

  external ffi.Pointer<_IO_codecvt> _codecvt;

  external ffi.Pointer<_IO_wide_data> _wide_data;

  external ffi.Pointer<_IO_FILE> _freeres_list;

  external ffi.Pointer<ffi.Void> _freeres_buf;

  @ffi.Size()
  external int __pad5;

  @ffi.Int()
  external int _mode;

  @ffi.Array.multi([20])
  external ffi.Array<ffi.Char> _unused2;
}

final class _IO_marker extends ffi.Opaque {}

typedef __off_t = ffi.Long;
typedef _IO_lock_t = ffi.Void;
typedef __off64_t = ffi.Long;

final class _IO_codecvt extends ffi.Opaque {}

final class _IO_wide_data extends ffi.Opaque {}

abstract class ggml_op_pool {
  static const int GGML_OP_POOL_MAX = 0;
  static const int GGML_OP_POOL_AVG = 1;
  static const int GGML_OP_POOL_COUNT = 2;
}

/// sort rows
abstract class ggml_sort_order {
  static const int GGML_SORT_ORDER_ASC = 0;
  static const int GGML_SORT_ORDER_DESC = 1;
}

/// custom operators
typedef ggml_unary_op_f32_t = ffi.Pointer<
    ffi.NativeFunction<
        ffi.Void Function(
            ffi.Int, ffi.Pointer<ffi.Float>, ffi.Pointer<ffi.Float>)>>;
typedef ggml_binary_op_f32_t = ffi.Pointer<
    ffi.NativeFunction<
        ffi.Void Function(ffi.Int, ffi.Pointer<ffi.Float>,
            ffi.Pointer<ffi.Float>, ffi.Pointer<ffi.Float>)>>;
typedef ggml_custom1_op_f32_t = ffi.Pointer<
    ffi.NativeFunction<
        ffi.Void Function(ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>>;
typedef ggml_custom2_op_f32_t = ffi.Pointer<
    ffi.NativeFunction<
        ffi.Void Function(ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>,
            ffi.Pointer<ggml_tensor>)>>;
typedef ggml_custom3_op_f32_t = ffi.Pointer<
    ffi.NativeFunction<
        ffi.Void Function(ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>,
            ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>>;

/// custom operators v2
typedef ggml_custom1_op_t = ffi.Pointer<
    ffi.NativeFunction<
        ffi.Void Function(
            ffi.Pointer<ggml_tensor> dst,
            ffi.Pointer<ggml_tensor> a,
            ffi.Int ith,
            ffi.Int nth,
            ffi.Pointer<ffi.Void> userdata)>>;
typedef ggml_custom2_op_t = ffi.Pointer<
    ffi.NativeFunction<
        ffi.Void Function(
            ffi.Pointer<ggml_tensor> dst,
            ffi.Pointer<ggml_tensor> a,
            ffi.Pointer<ggml_tensor> b,
            ffi.Int ith,
            ffi.Int nth,
            ffi.Pointer<ffi.Void> userdata)>>;
typedef ggml_custom3_op_t = ffi.Pointer<
    ffi.NativeFunction<
        ffi.Void Function(
            ffi.Pointer<ggml_tensor> dst,
            ffi.Pointer<ggml_tensor> a,
            ffi.Pointer<ggml_tensor> b,
            ffi.Pointer<ggml_tensor> c,
            ffi.Int ith,
            ffi.Int nth,
            ffi.Pointer<ffi.Void> userdata)>>;

/// TODO these functions were sandwiched in the old optimization interface, is there a better place for them?
typedef ggml_log_callback = ffi.Pointer<
    ffi.NativeFunction<
        ffi.Void Function(ffi.Int32 level, ffi.Pointer<ffi.Char> text,
            ffi.Pointer<ffi.Void> user_data)>>;

final class ggml_type_traits extends ffi.Struct {
  external ffi.Pointer<ffi.Char> type_name;

  @ffi.Int64()
  external int blck_size;

  /// interleave elements in blocks
  @ffi.Int64()
  external int blck_size_interleave;

  @ffi.Size()
  external int type_size;

  @ffi.Bool()
  external bool is_quantized;

  external ggml_to_float_t to_float;

  external ggml_from_float_t from_float_ref;
}

typedef ggml_to_float_t = ffi.Pointer<
    ffi.NativeFunction<
        ffi.Void Function(
            ffi.Pointer<ffi.Void> x, ffi.Pointer<ffi.Float> y, ffi.Int64 k)>>;
typedef ggml_from_float_t = ffi.Pointer<
    ffi.NativeFunction<
        ffi.Void Function(
            ffi.Pointer<ffi.Float> x, ffi.Pointer<ffi.Void> y, ffi.Int64 k)>>;

/// scheduling priorities
abstract class ggml_sched_priority {
  static const int GGML_SCHED_PRIO_NORMAL = 0;
  static const int GGML_SCHED_PRIO_MEDIUM = 1;
  static const int GGML_SCHED_PRIO_HIGH = 2;
  static const int GGML_SCHED_PRIO_REALTIME = 3;
}

/// threadpool params
/// Use ggml_threadpool_params_default() or ggml_threadpool_params_init() to populate the defaults
final class ggml_threadpool_params extends ffi.Struct {
  /// mask of cpu cores (all-zeros means use default affinity settings)
  @ffi.Array.multi([512])
  external ffi.Array<ffi.Bool> cpumask;

  /// number of threads
  @ffi.Int()
  external int n_threads;

  /// thread priority
  @ffi.Int32()
  external int prio;

  /// polling level (0 - no polling, 100 - aggressive polling)
  @ffi.Uint32()
  external int poll;

  /// strict cpu placement
  @ffi.Bool()
  external bool strict_cpu;

  /// start in paused state
  @ffi.Bool()
  external bool paused;
}

final class ggml_threadpool extends ffi.Opaque {}

final class ggml_backend_event extends ffi.Opaque {}

final class ggml_backend_reg extends ffi.Opaque {}

final class ggml_backend_device extends ffi.Opaque {}

typedef ggml_backend_buffer_type_t = ffi.Pointer<ggml_backend_buffer_type>;

final class ggml_backend_buffer_type extends ffi.Opaque {}

typedef ggml_backend_buffer_t = ffi.Pointer<ggml_backend_buffer>;
typedef ggml_backend_dev_t = ffi.Pointer<ggml_backend_device>;

/// Backend buffer
abstract class ggml_backend_buffer_usage {
  static const int GGML_BACKEND_BUFFER_USAGE_ANY = 0;
  static const int GGML_BACKEND_BUFFER_USAGE_WEIGHTS = 1;
  static const int GGML_BACKEND_BUFFER_USAGE_COMPUTE = 2;
}

typedef ggml_backend_t = ffi.Pointer<ggml_backend>;

final class ggml_backend extends ffi.Opaque {}

typedef ggml_backend_graph_plan_t = ffi.Pointer<ffi.Void>;
typedef ggml_backend_event_t = ffi.Pointer<ggml_backend_event>;

/// Backend device
abstract class ggml_backend_dev_type {
  /// CPU device using system memory
  static const int GGML_BACKEND_DEVICE_TYPE_CPU = 0;

  /// GPU device using dedicated memory
  static const int GGML_BACKEND_DEVICE_TYPE_GPU = 1;

  /// accelerator devices intended to be used together with the CPU backend (e.g. BLAS or AMX)
  static const int GGML_BACKEND_DEVICE_TYPE_ACCEL = 2;
}

/// functionality supported by the device
final class ggml_backend_dev_caps extends ffi.Struct {
  /// asynchronous operations
  @ffi.Bool()
  external bool async1;

  /// pinned host buffer
  @ffi.Bool()
  external bool host_buffer;

  /// creating buffers from host ptr
  @ffi.Bool()
  external bool buffer_from_host_ptr;

  /// event synchronization
  @ffi.Bool()
  external bool events;
}

/// all the device properties
final class ggml_backend_dev_props extends ffi.Struct {
  external ffi.Pointer<ffi.Char> name;

  external ffi.Pointer<ffi.Char> description;

  @ffi.Size()
  external int memory_free;

  @ffi.Size()
  external int memory_total;

  @ffi.Int32()
  external int type;

  external ggml_backend_dev_caps caps;
}

typedef ggml_backend_reg_t = ffi.Pointer<ggml_backend_reg>;

/// Get a list of feature flags supported by the backend (returns a NULL-terminated array)
final class ggml_backend_feature extends ffi.Struct {
  external ffi.Pointer<ffi.Char> name;

  external ffi.Pointer<ffi.Char> value;
}

final class ggml_backend_sched extends ffi.Opaque {}

/// The backend scheduler allows for multiple backend devices to be used together
/// Handles compute buffer allocation, assignment of tensors to backends, and copying of tensors between backends
/// The backends are selected based on:
/// - the backend that supports the operation
/// - the location of the pre-allocated tensors (e.g. the weights)
///     /*
///       Example usage:
///
/// operations that use tensors allocated in a buffer with USAGE_WEIGHTS will be assigned
/// preferrably to run on the same backend as the buffer
///         ggml_backend_buffer_set_usage(buf_weights, GGML_BACKEND_BUFFER_USAGE_WEIGHTS);
///
///         sched = ggml_backend_sched_new({backend_gpu, backend_gpu2, backend_cpu}, NULL, num_backends, GGML_DEFAULT_GRAPH_SIZE, false);
///
/// initialize buffers from a max size graph (optional)
///         reserve_graph = build_graph(sched, max_batch_size);
///
/// manually assign nodes to a backend (optional, should not be needed in most cases)
///         struct ggml_tensor * node = ggml_mul_mat(ctx, ...);
///         ggml_backend_sched_set_tensor_backend(sched, node, backend_gpu);
///
///         ggml_backend_sched_reserve(sched, reserve_graph);
///
/// compute
///         graph = build_graph(sched); // the graph and its tensors are single-use in terms of allocation, multi-use in terms of computation
///         for (int i = 0; i < 10; ++i) {
///             ggml_backend_sched_graph_compute(sched, graph); // on the first iteration the graph is allocated automatically
///         }
///
/// if there are graph inputs:
///         graph = build_graph(sched); // get a new graph that is not allocated (the metadata for the old graph is freed once ggml_free is called)
///         ggml_backend_sched_reset(sched); // clear the allocation of the previous graph
///         ggml_backend_sched_alloc_graph(sched, graph); // explicitly allocate the new graph but do not execute it
///         ggml_backend_tensor_set(input_tensor, ...); // copy data to the newly allocated graph tensors
///         ggml_backend_sched_graph_compute(sched, graph); // execute the graph
///
/// as an alternative to the above it is also possible to assign the inputs to a dedicated context and
/// allocate them statically via ggml_backend_alloc_ctx_tensors
///     }
///     */
typedef ggml_backend_sched_t = ffi.Pointer<ggml_backend_sched>;

/// Evaluation callback for each node in the graph (set with ggml_backend_sched_set_eval_callback)
/// when ask == true, the scheduler wants to know if the user wants to observe this node
/// this allows the scheduler to batch nodes together in order to evaluate them in a single call
///
/// when ask == false, the scheduler is passing the node tensor to the user for observation
/// if the user returns false, the scheduler will cancel the graph compute
typedef ggml_backend_sched_eval_callback = ffi.Pointer<
    ffi.NativeFunction<
        ffi.Bool Function(ffi.Pointer<ggml_tensor> t, ffi.Bool ask,
            ffi.Pointer<ffi.Void> user_data)>>;

/// Utils
final class ggml_backend_graph_copy extends ffi.Struct {
  external ggml_backend_buffer_t buffer;

  external ffi.Pointer<ggml_context> ctx_allocated;

  external ffi.Pointer<ggml_context> ctx_unallocated;

  external ffi.Pointer<ggml_cgraph> graph;
}

typedef ggml_backend_eval_callback = ffi.Pointer<
    ffi.NativeFunction<
        ffi.Bool Function(ffi.Int node_index, ffi.Pointer<ggml_tensor> t1,
            ffi.Pointer<ggml_tensor> t2, ffi.Pointer<ffi.Void> user_data)>>;

/// the compute plan that needs to be prepared for ggml_graph_compute()
/// since https://github.com/ggerganov/ggml/issues/287
final class ggml_cplan extends ffi.Struct {
  /// size of work buffer, calculated by `ggml_graph_plan()`
  @ffi.Size()
  external int work_size;

  /// work buffer, to be allocated by caller before calling to `ggml_graph_compute()`
  external ffi.Pointer<ffi.Uint8> work_data;

  @ffi.Int()
  external int n_threads;

  external ffi.Pointer<ggml_threadpool> threadpool;

  /// abort ggml_graph_compute when true
  external ggml_abort_callback abort_callback;

  external ffi.Pointer<ffi.Void> abort_callback_data;
}

/// Abort callback
/// If not NULL, called before ggml computation
/// If it returns true, the computation is aborted
typedef ggml_abort_callback = ffi
    .Pointer<ffi.NativeFunction<ffi.Bool Function(ffi.Pointer<ffi.Void> data)>>;

/// numa strategies
abstract class ggml_numa_strategy {
  static const int GGML_NUMA_STRATEGY_DISABLED = 0;
  static const int GGML_NUMA_STRATEGY_DISTRIBUTE = 1;
  static const int GGML_NUMA_STRATEGY_ISOLATE = 2;
  static const int GGML_NUMA_STRATEGY_NUMACTL = 3;
  static const int GGML_NUMA_STRATEGY_MIRROR = 4;
  static const int GGML_NUMA_STRATEGY_COUNT = 5;
}

final class ggml_type_traits_cpu extends ffi.Struct {
  external ggml_from_float_t from_float;

  external ggml_vec_dot_t vec_dot;

  @ffi.Int32()
  external int vec_dot_type;

  /// number of rows to process simultaneously
  @ffi.Int64()
  external int nrows;
}

/// Internal types and functions exposed for tests and benchmarks
typedef ggml_vec_dot_t = ffi.Pointer<
    ffi.NativeFunction<
        ffi.Void Function(
            ffi.Int n,
            ffi.Pointer<ffi.Float> s,
            ffi.Size bs,
            ffi.Pointer<ffi.Void> x,
            ffi.Size bx,
            ffi.Pointer<ffi.Void> y,
            ffi.Size by,
            ffi.Int nrc)>>;
typedef ggml_threadpool_t = ffi.Pointer<ggml_threadpool>;

const int WHISPER_SAMPLE_RATE = 16000;

const int WHISPER_N_FFT = 400;

const int WHISPER_HOP_LENGTH = 160;

const int WHISPER_CHUNK_SIZE = 30;

const int GGML_FILE_MAGIC = 1734831468;

const int GGML_FILE_VERSION = 2;

const int GGML_QNT_VERSION = 2;

const int GGML_QNT_VERSION_FACTOR = 1000;

const int GGML_MAX_DIMS = 4;

const int GGML_MAX_PARAMS = 2048;

const int GGML_MAX_SRC = 10;

const int GGML_MAX_N_THREADS = 512;

const int GGML_MAX_OP_PARAMS = 64;

const int GGML_MAX_NAME = 64;

const int GGML_DEFAULT_N_THREADS = 4;

const int GGML_DEFAULT_GRAPH_SIZE = 2048;

const int GGML_MEM_ALIGN = 16;

const int GGML_EXIT_SUCCESS = 0;

const int GGML_EXIT_ABORTED = 1;

const int GGML_ROPE_TYPE_NEOX = 2;

const int GGML_ROPE_TYPE_MROPE = 8;

const int GGML_ROPE_TYPE_VISION = 24;

const int GGML_KQ_MASK_PAD = 64;

const int GGML_N_TASKS_MAX = -1;
